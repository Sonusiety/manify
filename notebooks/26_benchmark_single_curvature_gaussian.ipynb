{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import embedders\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Filter out warnings raised when sampling Wishart distribution in Gaussian mixtures\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda, Sample Device: cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "if device != torch.device(\"cuda\"):\n",
    "    sample_device = torch.device(\"cpu\")\n",
    "else:\n",
    "    sample_device = device\n",
    "\n",
    "print(f\"Device: {device}, Sample Device: {sample_device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24e28f6134934c61801638a11954c5eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 49\u001b[0m\n\u001b[1;32m     46\u001b[0m     pm\u001b[38;5;241m.\u001b[39mP[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mscale \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(torch\u001b[38;5;241m.\u001b[39mtensor(scale))\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     47\u001b[0m     pm\u001b[38;5;241m.\u001b[39mP[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmanifold\u001b[38;5;241m.\u001b[39m_log_scale \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mParameter(torch\u001b[38;5;241m.\u001b[39mtensor(scale))\n\u001b[0;32m---> 49\u001b[0m model_results \u001b[38;5;241m=\u001b[39m \u001b[43membedders\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbenchmarks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbenchmark\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_depth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMAX_DEPTH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTASK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSCORE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_FEATURES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Create a flat dictionary for this run\u001b[39;00m\n\u001b[1;32m     54\u001b[0m run_results \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcurvature\u001b[39m\u001b[38;5;124m\"\u001b[39m: K, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed}\n",
      "File \u001b[0;32m~/embedders/src/embedders/benchmarks.py:399\u001b[0m, in \u001b[0;36mbenchmark\u001b[0;34m(X, y, pm, split, device, score, models, max_depth, n_estimators, min_samples_split, min_samples_leaf, task, seed, use_special_dims, n_features, X_train, X_test, y_train, y_test, batch_size)\u001b[0m\n\u001b[1;32m    397\u001b[0m ambient_gnn \u001b[38;5;241m=\u001b[39m ambient_gnn\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    398\u001b[0m t1 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 399\u001b[0m \u001b[43mambient_gnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    400\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m tangent_gnn\u001b[38;5;241m.\u001b[39mpredict(X, test_idx\u001b[38;5;241m=\u001b[39mtest_idx)\n\u001b[1;32m    401\u001b[0m t2 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/embedders/src/embedders/predictors/gnn.py:110\u001b[0m, in \u001b[0;36mGNN.fit\u001b[0;34m(self, X, y, train_idx, epochs, lr)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m    109\u001b[0m     opt\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 110\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_edges\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(y_pred, y_train)\n\u001b[1;32m    112\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/embedders/src/embedders/predictors/gnn.py:82\u001b[0m, in \u001b[0;36mGNN.forward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(layer, GCNConv):\n\u001b[0;32m---> 82\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     84\u001b[0m         x \u001b[38;5;241m=\u001b[39m layer(x)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch_geometric/nn/conv/gcn_conv.py:263\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    260\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin(x)\n\u001b[1;32m    262\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: Tensor, edge_weight: OptTensor)\u001b[39;00m\n\u001b[0;32m--> 263\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    266\u001b[0m     out \u001b[38;5;241m=\u001b[39m out \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\n",
      "File \u001b[0;32m/tmp/torch_geometric.nn.conv.gcn_conv_GCNConv_propagate_heghcn5s.py:138\u001b[0m, in \u001b[0;36mpropagate\u001b[0;34m(self, edge_index, x, edge_weight, size)\u001b[0m\n\u001b[1;32m    135\u001b[0m             edge_weight \u001b[38;5;241m=\u001b[39m hook_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_weight\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# End Propagate Forward Pre Hook ###########################################\u001b[39;00m\n\u001b[0;32m--> 138\u001b[0m mutable_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;66;03m# Run \"fused\" message and aggregation (if applicable).\u001b[39;00m\n\u001b[1;32m    141\u001b[0m fuse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch_geometric/nn/conv/message_passing.py:237\u001b[0m, in \u001b[0;36mMessagePassing._check_input\u001b[0;34m(self, edge_index, size)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m edge_index\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_index\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to be two-dimensional\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    236\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00medge_index\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dimensions)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_tracing() \u001b[38;5;129;01mand\u001b[39;00m edge_index\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_index\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to have size \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    239\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe first dimension (got \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    240\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00medge_index\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(size) \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "CURVATURES = [-4, -2, -1, -0.5, -0.25, 0, 0.25, 0.5, 1, 2, 4]\n",
    "DIM = 2\n",
    "N_SAMPLES = 100\n",
    "N_POINTS = 1_000\n",
    "N_CLASSES = 8\n",
    "N_CLUSTERS = 32\n",
    "MAX_DEPTH = 3\n",
    "COV_SCALE_MEANS = 1.0\n",
    "COV_SCALE_POINTS = 1.0\n",
    "\n",
    "# TASK = \"regression\"\n",
    "TASK = \"classification\"\n",
    "RESAMPLE_SCALES = False\n",
    "N_FEATURES = \"d_choose_2\"\n",
    "\n",
    "# SCORE = \"f1-micro\" if TASK == \"classification\" else \"rmse\"\n",
    "SCORE = [\"f1-micro\", \"accuracy\"] if TASK == \"classification\" else [\"rmse\"]\n",
    "\n",
    "my_tqdm = tqdm(total=len(CURVATURES) * N_SAMPLES)\n",
    "for i, K in enumerate(CURVATURES):\n",
    "    for seed in range(N_SAMPLES):\n",
    "        # Ensure unique seed per trial\n",
    "        seed = seed + N_SAMPLES * i\n",
    "        pm = embedders.manifolds.ProductManifold(signature=[(K, DIM)]).to(sample_device)\n",
    "\n",
    "        # Get X, y\n",
    "        X, y = embedders.gaussian_mixture.gaussian_mixture(\n",
    "            pm=pm,\n",
    "            seed=seed,\n",
    "            num_points=N_POINTS,\n",
    "            num_classes=N_CLASSES,\n",
    "            num_clusters=N_CLUSTERS,\n",
    "            cov_scale_means=COV_SCALE_MEANS / DIM,\n",
    "            cov_scale_points=COV_SCALE_POINTS / DIM,\n",
    "            task=TASK,\n",
    "        )\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        pm = pm.to(device)\n",
    "\n",
    "        if RESAMPLE_SCALES:\n",
    "            scale = 0.5 - np.random.rand() * 20\n",
    "            pm.P[0].scale = torch.exp(torch.tensor(scale)).item()\n",
    "            pm.P[0].manifold._log_scale = torch.nn.Parameter(torch.tensor(scale))\n",
    "\n",
    "        model_results = embedders.benchmarks.benchmark(\n",
    "            X, y, pm, max_depth=MAX_DEPTH, task=TASK, score=SCORE, seed=seed, n_features=N_FEATURES, device=device\n",
    "        )\n",
    "\n",
    "        # Create a flat dictionary for this run\n",
    "        run_results = {\"curvature\": K, \"seed\": seed}\n",
    "\n",
    "        # Flatten the nested model results\n",
    "        for model, metrics in model_results.items():\n",
    "            for metric, value in metrics.items():\n",
    "                run_results[f\"{model}_{metric}\"] = value\n",
    "\n",
    "        results.append(run_results)\n",
    "        my_tqdm.update(1)\n",
    "\n",
    "# Convert to DataFrame\n",
    "results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(f\"embedders/data/results/{TASK}_single_curvature.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d69f31da191949208b894225c410c4a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 49\u001b[0m\n\u001b[1;32m     46\u001b[0m     pm\u001b[38;5;241m.\u001b[39mP[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mscale \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(torch\u001b[38;5;241m.\u001b[39mtensor(scale))\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     47\u001b[0m     pm\u001b[38;5;241m.\u001b[39mP[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmanifold\u001b[38;5;241m.\u001b[39m_log_scale \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mParameter(torch\u001b[38;5;241m.\u001b[39mtensor(scale))\n\u001b[0;32m---> 49\u001b[0m model_results \u001b[38;5;241m=\u001b[39m \u001b[43membedders\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbenchmarks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbenchmark\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_depth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMAX_DEPTH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTASK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSCORE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_FEATURES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Create a flat dictionary for this run\u001b[39;00m\n\u001b[1;32m     54\u001b[0m run_results \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcurvature\u001b[39m\u001b[38;5;124m\"\u001b[39m: K, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed}\n",
      "File \u001b[0;32m~/embedders/src/embedders/benchmarks.py:379\u001b[0m, in \u001b[0;36mbenchmark\u001b[0;34m(X, y, pm, split, device, score, models, max_depth, n_estimators, min_samples_split, min_samples_leaf, task, seed, use_special_dims, n_features, X_train, X_test, y_train, y_test, batch_size)\u001b[0m\n\u001b[1;32m    377\u001b[0m ambient_mlp \u001b[38;5;241m=\u001b[39m ambient_mlp\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    378\u001b[0m t1 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 379\u001b[0m \u001b[43mambient_mlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m t2 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    381\u001b[0m accs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mambient_mlp\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m _score(X_test, y_test_np, ambient_mlp, torch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/embedders/src/embedders/predictors/mlp.py:53\u001b[0m, in \u001b[0;36mMLP.fit\u001b[0;34m(self, X, y, epochs, lr)\u001b[0m\n\u001b[1;32m     51\u001b[0m opt\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     52\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(X)\n\u001b[0;32m---> 53\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     55\u001b[0m opt\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/modules/loss.py:535\u001b[0m, in \u001b[0;36mMSELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 535\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/functional.py:3330\u001b[0m, in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   3326\u001b[0m         mse_loss, (\u001b[38;5;28minput\u001b[39m, target), \u001b[38;5;28minput\u001b[39m, target, size_average\u001b[38;5;241m=\u001b[39msize_average, reduce\u001b[38;5;241m=\u001b[39mreduce, reduction\u001b[38;5;241m=\u001b[39mreduction\n\u001b[1;32m   3327\u001b[0m     )\n\u001b[1;32m   3328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (target\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m==\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()):\n\u001b[1;32m   3329\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m-> 3330\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing a target size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) that is different to the input size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis will likely lead to incorrect results due to broadcasting. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3332\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure they have the same size.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3333\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m   3334\u001b[0m     )\n\u001b[1;32m   3335\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3336\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "TASK = \"regression\"\n",
    "SCORE = [\"f1-micro\", \"accuracy\"] if TASK == \"classification\" else [\"rmse\"]\n",
    "\n",
    "my_tqdm = tqdm(total=len(CURVATURES) * N_SAMPLES)\n",
    "for i, K in enumerate(CURVATURES):\n",
    "    for seed in range(N_SAMPLES):\n",
    "        # Ensure unique seed per trial\n",
    "        seed = seed + N_SAMPLES * i\n",
    "        pm = embedders.manifolds.ProductManifold(signature=[(K, DIM)]).to(sample_device)\n",
    "\n",
    "        # Get X, y\n",
    "        X, y = embedders.gaussian_mixture.gaussian_mixture(\n",
    "            pm=pm,\n",
    "            seed=seed,\n",
    "            num_points=N_POINTS,\n",
    "            num_classes=N_CLASSES,\n",
    "            num_clusters=N_CLUSTERS,\n",
    "            cov_scale_means=COV_SCALE_MEANS / DIM,\n",
    "            cov_scale_points=COV_SCALE_POINTS / DIM,\n",
    "            task=TASK,\n",
    "        )\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        pm = pm.to(device)\n",
    "\n",
    "        if RESAMPLE_SCALES:\n",
    "            scale = 0.5 - np.random.rand() * 20\n",
    "            pm.P[0].scale = torch.exp(torch.tensor(scale)).item()\n",
    "            pm.P[0].manifold._log_scale = torch.nn.Parameter(torch.tensor(scale))\n",
    "\n",
    "        model_results = embedders.benchmarks.benchmark(\n",
    "            X, y, pm, max_depth=MAX_DEPTH, task=TASK, score=SCORE, seed=seed, n_features=N_FEATURES, device=device\n",
    "        )\n",
    "\n",
    "        # Create a flat dictionary for this run\n",
    "        run_results = {\"curvature\": K, \"seed\": seed}\n",
    "\n",
    "        # Flatten the nested model results\n",
    "        for model, metrics in model_results.items():\n",
    "            for metric, value in metrics.items():\n",
    "                run_results[f\"{model}_{metric}\"] = value\n",
    "\n",
    "        results.append(run_results)\n",
    "        my_tqdm.update(1)\n",
    "\n",
    "# Convert to DataFrame\n",
    "results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(f\"embedders//data/results/{TASK}_single_curvature.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the values: barplot with statistical significance annotations\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import wilcoxon\n",
    "import matplotlib as mpl\n",
    "\n",
    "# Set font to LaTeX times font\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "plt.rcParams[\"font.serif\"] = [\"Times New Roman\"] + plt.rcParams[\"font.serif\"]\n",
    "plt.rcParams[\"mathtext.fontset\"] = \"cm\"\n",
    "# plt.rcParams[\"text.usetex\"] = True\n",
    "# plt.rcParams[\"text.latex.preamble\"] = r\"\\usepackage{amsmath}\"\n",
    "# plt.rcParams[\"font.size\"] = 10\n",
    "\n",
    "# TASK = \"regression\"\n",
    "TASK = \"classification\"\n",
    "SIGNIFICANCE = \"sig\"\n",
    "# SIGNIFICANCE = \"ns\"\n",
    "CORRECTION = \"bonferroni\"\n",
    "# CORRECTION = \"none\"\n",
    "\n",
    "Y_LABEL = \"$F_1$ Score\" if TASK == \"classification\" else \"RMSE\"\n",
    "\n",
    "results = pd.read_csv(f\"../data/results/{TASK}_single_curvature.tsv\", sep=\"\\t\")\n",
    "CURVATURES = [-4, -2, -1, -0.5, -0.25, 0, 0.25, 0.5, 1, 2, 4]\n",
    "\n",
    "AST_SPACING = 0.1\n",
    "LW = 1\n",
    "FONTSIZE = 10\n",
    "\n",
    "\n",
    "def test(x, y):\n",
    "    # Check x and y are identical\n",
    "    all_same = True\n",
    "    for a, b in zip(x, y):\n",
    "        if a != b:\n",
    "            all_same = False\n",
    "            break\n",
    "    if all_same:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return wilcoxon(x, y).pvalue\n",
    "\n",
    "\n",
    "# All the spec happens up here\n",
    "models1 = [\"product_dt\", \"sklearn_dt\", \"tangent_dt\"]\n",
    "model_names1 = [\"Product DT\", \"Euclidean DT\\n(ambient)\", \"Euclidean DT\\n(tangent plane)\"]\n",
    "models2 = [\"product_rf\", \"sklearn_rf\", \"tangent_rf\"]\n",
    "model_names2 = [\"Product RF\", \"Euclidean RF\\n(ambient)\", \"Euclidean RF\\n(tangent plane)\"]\n",
    "# models3 = [\"knn\", \"perceptron\", \"svm\"]\n",
    "# model_names3 = [\"k-Nearest Neighbors\", \"Perceptron\", \"Support Vector Classifier\"]\n",
    "models3 = [\"knn\"]\n",
    "model_names3 = [\"$k$-Nearest\\nNeighbors\"]\n",
    "colors = [f\"C{i}\" for i in range(len(models1 + models3))]\n",
    "\n",
    "# Critical p-value depends on false discovery correction\n",
    "CRITICAL_VAL = 0.05\n",
    "if CORRECTION == \"bonferroni\":\n",
    "    CRITICAL_VAL /= len(models1 + models3) * (len(models1 + models3) - 1) / 2\n",
    "\n",
    "# Initialize plot\n",
    "# fig, axs = plt.subplots(2, 1, figsize=(15, 10), sharex=True)\n",
    "# fig, axs = plt.subplots(2, 1, figsize=(14, 7), sharex=True)\n",
    "fig, axs = plt.subplots(2, 1, figsize=(6.5, 4), sharex=True)\n",
    "x_vals = np.arange(len(CURVATURES)) * (len(models1 + models3) + 1)\n",
    "\n",
    "for ax, models, model_names in zip(\n",
    "    axs, [models1 + models3, models2 + models3], [model_names1 + model_names3, model_names2 + model_names3]\n",
    "):\n",
    "    bps = []\n",
    "    for i, (model, color) in enumerate(zip(models, colors)):\n",
    "        # Initial boxplot\n",
    "        bp = ax.boxplot(\n",
    "            [results[results[\"curvature\"] == K][model] for K in CURVATURES],\n",
    "            positions=x_vals + i,\n",
    "            widths=0.8,\n",
    "            boxprops=dict(color=color, linewidth=LW),\n",
    "        )\n",
    "\n",
    "        # Fix colors\n",
    "        for element in [\"boxes\", \"whiskers\", \"fliers\", \"means\", \"caps\"]:\n",
    "            plt.setp(bp[element], color=color, linewidth=LW)\n",
    "        plt.setp(bp[\"medians\"], color=\"black\", linewidth=LW)\n",
    "        plt.setp(bp[\"fliers\"], marker=\"o\", markersize=1, markeredgecolor=color, markeredgewidth=LW)\n",
    "\n",
    "        bps.append(bp)\n",
    "\n",
    "    # # Flip y-axis for RMSE\n",
    "    # if TASK == \"regression\":\n",
    "    #     ax.invert_yaxis()\n",
    "    ymin, ymax = ax.get_ylim()\n",
    "\n",
    "    # Add p-value annotations. All start at x_vals, and end at x_vals + i\n",
    "    heights = [0] * len(CURVATURES)  # How many annotations per curvature\n",
    "    # for i, j in [(0, 1), (1, 2), (0, 2), (0, 3), (1, 3), (2, 3)]:\n",
    "    for i in range(len(models)):\n",
    "        for j in range(i + 1, len(models)):\n",
    "            results_K = [results[results[\"curvature\"] == K] for K in CURVATURES]\n",
    "            p_vals = [test(res[models[i]], res[models[j]]) for res in results_K]\n",
    "            em = ymax - ymin\n",
    "\n",
    "            for k, p_val in enumerate(p_vals):\n",
    "                if (SIGNIFICANCE == \"ns\" and p_val > CRITICAL_VAL) or (SIGNIFICANCE == \"sig\" and p_val < CRITICAL_VAL):\n",
    "                    x1, x2 = x_vals[k] + i, x_vals[k] + j\n",
    "                    height = results[results[\"curvature\"] == CURVATURES[k]][models].max().max() + AST_SPACING * em * (\n",
    "                        heights[k] + 1\n",
    "                    )\n",
    "                    annotation = \"*\" if SIGNIFICANCE == \"sig\" else \"ns\"\n",
    "                    ax.text(\n",
    "                        s=annotation,\n",
    "                        x=(x1 + x2) / 2,\n",
    "                        y=height,\n",
    "                        ha=\"center\",\n",
    "                        va=\"center\",\n",
    "                        color=\"black\",\n",
    "                        fontdict={\"weight\": \"bold\", \"size\": FONTSIZE},\n",
    "                    )\n",
    "                    ax.plot(\n",
    "                        [x1, x1, x2, x2],\n",
    "                        [height - 0.03 * em, height - 0.02 * em, height - 0.02 * em, height - 0.03 * em],\n",
    "                        lw=LW,\n",
    "                        color=\"black\",\n",
    "                    )\n",
    "                    heights[k] += 1\n",
    "\n",
    "    # Fix y-lim and remove top/right spines; make background transparent\n",
    "    ax.patch.set_alpha(0)\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.spines[\"left\"].set_linewidth(LW)\n",
    "    ax.spines[\"bottom\"].set_linewidth(LW)\n",
    "    ax.set_xlim(-1, len(CURVATURES) * (len(models1 + models3) + 1))\n",
    "\n",
    "    # Set x-ticks\n",
    "    ax.set_ylabel(Y_LABEL, fontsize=FONTSIZE)\n",
    "    ax.set_xticks(x_vals + 1.5, CURVATURES, fontsize=FONTSIZE)\n",
    "    # ax.legend([bp[\"boxes\"][0] for bp in bps], model_names, fontsize=14, frameon=False, title=\"Model\")\n",
    "    # Make legend to the right of the plot\n",
    "    # ax.legend(\n",
    "    #     [bp[\"boxes\"][0] for bp in bps],\n",
    "    #     model_names,\n",
    "    #     fontsize=16,\n",
    "    #     frameon=False,\n",
    "    #     title=\"Model\",\n",
    "    #     title_fontsize=18,\n",
    "    #     loc=\"center left\",\n",
    "    #     bbox_to_anchor=(1, 0.5),\n",
    "    # )\n",
    "    ax.tick_params(axis=\"y\", labelsize=FONTSIZE)\n",
    "    # ax.set_yscale(\"log\") if TASK == \"regression\" else None\n",
    "\n",
    "    # Move title down\n",
    "    # ax.title.set_position([.5, .9])\n",
    "\n",
    "# axs[0].set_title(\"Decision Trees\", fontsize=18, position=(0.5, 0.9))\n",
    "# axs[1].set_title(\"Random Forests\", fontsize=18, position=(0.5, 0.9))\n",
    "axs[0].text(s=\"Decision Trees\", fontsize=FONTSIZE, x=0.5, y=0.95, ha=\"center\", va=\"center\", transform=axs[0].transAxes)\n",
    "axs[1].text(s=\"Random Forests\", fontsize=FONTSIZE, x=0.5, y=0.95, ha=\"center\", va=\"center\", transform=axs[1].transAxes)\n",
    "axs[1].set_xlabel(\"Curvature\", fontsize=FONTSIZE)\n",
    "\n",
    "# Legend in a new subplot end\n",
    "# ax = fig.add_subplot(111, frameon=False)\n",
    "# ax.legend(\n",
    "#     [bp[\"boxes\"][0] for bp in bps],\n",
    "#     [\"Product\", \"Ambient\", \"Tangent\", \"$k$-NN\"],\n",
    "#     fontsize=16,\n",
    "#     frameon=False,\n",
    "#     title=\"Model\",\n",
    "#     title_fontsize=18,\n",
    "#     loc=\"lower left\",\n",
    "#     bbox_to_anchor=(1, 1),\n",
    "# )\n",
    "# fig.subplots_adjust(right=1.1)\n",
    "legend_ax = fig.add_axes([1.0, 0.15, 0.02, 0.7])\n",
    "legend_ax.axis(\"off\")\n",
    "legend_ax.legend(\n",
    "    # [bp[\"boxes\"][0] for bp in bps],\n",
    "    [mpl.lines.Line2D([0], [0], color=color, lw=LW * 4) for color in colors],\n",
    "    [\"Product\", \"Ambient\", \"Tangent\", \"$k$-NN\"],\n",
    "    fontsize=FONTSIZE,\n",
    "    frameon=False,\n",
    "    title=\"Model\",\n",
    "    loc=\"center\",\n",
    "    title_fontproperties={\"weight\": \"bold\", \"size\": FONTSIZE},\n",
    ")\n",
    "\n",
    "# Move label for x-axis to the right of the plot\n",
    "axs[1].xaxis.set_label_coords(1.06, 0.07)\n",
    "\n",
    "# plt.xlim(-1, len(CURVATURES) * (len(models1 + models3) + 1))\n",
    "plt.suptitle(\n",
    "    f\"{TASK.capitalize()} benchmark: Synthetic (single $K$)\", fontsize=FONTSIZE, fontweight=\"bold\", position=(0.5, 0.93)\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save as pdf\n",
    "plt.savefig(\n",
    "    f\"../figures/single_curvature_{TASK}.pdf\",\n",
    "    bbox_inches=\"tight\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
