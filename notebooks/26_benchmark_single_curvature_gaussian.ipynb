{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import embedders\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Filter out warnings raised when sampling Wishart distribution in Gaussian mixtures\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda, Sample Device: cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "if device != torch.device(\"cuda\"):\n",
    "    sample_device = torch.device(\"cpu\")\n",
    "else:\n",
    "    sample_device = device\n",
    "\n",
    "print(f\"Device: {device}, Sample Device: {sample_device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cdde1c245be4bb1b3f34b967350d4d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/110 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "CURVATURES = [-4, -2, -1, -0.5, -0.25, 0, 0.25, 0.5, 1, 2, 4]\n",
    "DIM = 2\n",
    "N_SAMPLES = 10\n",
    "N_POINTS = 1_000\n",
    "N_CLASSES = 8\n",
    "N_CLUSTERS = 32\n",
    "MAX_DEPTH = 5\n",
    "COV_SCALE_MEANS = 1.0\n",
    "COV_SCALE_POINTS = 1.0\n",
    "\n",
    "# TASK = \"regression\"\n",
    "TASK = \"classification\"\n",
    "RESAMPLE_SCALES = False\n",
    "N_FEATURES = \"d_choose_2\"\n",
    "\n",
    "# SCORE = \"f1-micro\" if TASK == \"classification\" else \"rmse\"\n",
    "SCORE = [\"f1-micro\", \"accuracy\"] if TASK == \"classification\" else [\"rmse\"]\n",
    "\n",
    "my_tqdm = tqdm(total=len(CURVATURES) * N_SAMPLES)\n",
    "for i, K in enumerate(CURVATURES):\n",
    "    for seed in range(N_SAMPLES):\n",
    "        # Ensure unique seed per trial\n",
    "        seed = seed + N_SAMPLES * i\n",
    "        pm = embedders.manifolds.ProductManifold(signature=[(K, DIM)]).to(sample_device)\n",
    "\n",
    "        # Get X, y\n",
    "        X, y = embedders.gaussian_mixture.gaussian_mixture(\n",
    "            pm=pm,\n",
    "            seed=seed,\n",
    "            num_points=N_POINTS,\n",
    "            num_classes=N_CLASSES,\n",
    "            num_clusters=N_CLUSTERS,\n",
    "            cov_scale_means=COV_SCALE_MEANS / DIM,\n",
    "            cov_scale_points=COV_SCALE_POINTS / DIM,\n",
    "            task=TASK,\n",
    "        )\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        pm = pm.to(device)\n",
    "\n",
    "        if RESAMPLE_SCALES:\n",
    "            scale = 0.5 - np.random.rand() * 20\n",
    "            pm.P[0].scale = torch.exp(torch.tensor(scale)).item()\n",
    "            pm.P[0].manifold._log_scale = torch.nn.Parameter(torch.tensor(scale))\n",
    "\n",
    "        model_results = embedders.benchmarks.benchmark(\n",
    "            X, y, pm, max_depth=MAX_DEPTH, task=TASK, score=SCORE, seed=seed, n_features=N_FEATURES, device=device\n",
    "        )\n",
    "\n",
    "        # Create a flat dictionary for this run\n",
    "        # run_results = {\"curvature\": K, \"seed\": seed}\n",
    "        model_results[\"curvature\"] = K\n",
    "        model_results[\"seed\"] = seed\n",
    "\n",
    "        # # Flatten the nested model results\n",
    "        # for model, metrics in model_results.items():\n",
    "        #     for metric, value in metrics.items():\n",
    "        #         run_results[f\"{model}_{metric}\"] = value\n",
    "\n",
    "        # results.append(run_results)\n",
    "        results.append(model_results)\n",
    "        my_tqdm.update(1)\n",
    "\n",
    "# Convert to DataFrame\n",
    "results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(f\"../data/results_icml/{TASK}_single_curvature.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "900de524a76b4776955b7894c814a106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/110 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 33\u001b[0m\n\u001b[1;32m     30\u001b[0m     pm\u001b[38;5;241m.\u001b[39mP[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mscale \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(torch\u001b[38;5;241m.\u001b[39mtensor(scale))\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     31\u001b[0m     pm\u001b[38;5;241m.\u001b[39mP[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmanifold\u001b[38;5;241m.\u001b[39m_log_scale \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mParameter(torch\u001b[38;5;241m.\u001b[39mtensor(scale))\n\u001b[0;32m---> 33\u001b[0m model_results \u001b[38;5;241m=\u001b[39m \u001b[43membedders\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbenchmarks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbenchmark\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_depth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMAX_DEPTH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTASK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSCORE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_FEATURES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Create a flat dictionary for this run\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# run_results = {\"curvature\": K, \"seed\": seed}\u001b[39;00m\n\u001b[1;32m     39\u001b[0m model_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcurvature\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m K\n",
      "File \u001b[0;32m~/embedders/embedders/benchmarks.py:443\u001b[0m, in \u001b[0;36mbenchmark\u001b[0;34m(X, y, pm, device, score, models, max_depth, n_estimators, min_samples_split, min_samples_leaf, task, seed, use_special_dims, n_features, X_train, X_test, y_train, y_test, batch_size, adj, hidden_dims, epochs, lr)\u001b[0m\n\u001b[1;32m    441\u001b[0m     t2 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    442\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m kappa_gcn\u001b[38;5;241m.\u001b[39mpredict(X_test_stereo, A\u001b[38;5;241m=\u001b[39mA_test)\n\u001b[0;32m--> 443\u001b[0m     accs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkappa_gcn\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43m_score\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred_override\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    444\u001b[0m     accs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkappa_gcn\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m t2 \u001b[38;5;241m-\u001b[39m t1\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproduct_mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m models:\n",
      "File \u001b[0;32m~/embedders/embedders/benchmarks.py:211\u001b[0m, in \u001b[0;36mbenchmark.<locals>._score\u001b[0;34m(_X, _y, model, y_pred_override, torch)\u001b[0m\n\u001b[1;32m    209\u001b[0m     out[s] \u001b[38;5;241m=\u001b[39m mean_squared_error(_y, y_pred)\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m s \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrmse\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 211\u001b[0m     out[s] \u001b[38;5;241m=\u001b[39m \u001b[43mroot_mean_squared_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m s \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpercent_rmse\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    213\u001b[0m     out[s] \u001b[38;5;241m=\u001b[39m (root_mean_squared_error(_y, y_pred, multioutput\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_values\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(_y))\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[0;32m~/miniconda3/envs/embedders/lib/python3.9/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/embedders/lib/python3.9/site-packages/sklearn/metrics/_regression.py:581\u001b[0m, in \u001b[0;36mroot_mean_squared_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m    523\u001b[0m     {\n\u001b[1;32m    524\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    532\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, multioutput\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform_average\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    533\u001b[0m ):\n\u001b[1;32m    534\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Root mean squared error regression loss.\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \n\u001b[1;32m    536\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <mean_squared_error>`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[38;5;124;03m    0.822...\u001b[39;00m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    580\u001b[0m     output_errors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(\n\u001b[0;32m--> 581\u001b[0m         \u001b[43mmean_squared_error\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m            \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mraw_values\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    583\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    584\u001b[0m     )\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(multioutput, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    587\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m multioutput \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_values\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/embedders/lib/python3.9/site-packages/sklearn/utils/_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/embedders/lib/python3.9/site-packages/sklearn/metrics/_regression.py:506\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m squared:\n\u001b[1;32m    502\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m root_mean_squared_error(\n\u001b[1;32m    503\u001b[0m             y_true, y_pred, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, multioutput\u001b[38;5;241m=\u001b[39mmultioutput\n\u001b[1;32m    504\u001b[0m         )\n\u001b[0;32m--> 506\u001b[0m y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    509\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    510\u001b[0m output_errors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage((y_true \u001b[38;5;241m-\u001b[39m y_pred) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, weights\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[0;32m~/miniconda3/envs/embedders/lib/python3.9/site-packages/sklearn/metrics/_regression.py:113\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype, xp)\u001b[0m\n\u001b[1;32m    111\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[1;32m    112\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m--> 113\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_true\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    116\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mreshape(y_true, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/embedders/lib/python3.9/site-packages/sklearn/utils/validation.py:1064\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1058\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1059\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1060\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m   1061\u001b[0m     )\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m-> 1064\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1065\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1066\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1067\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1068\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1069\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[1;32m   1072\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[1;32m   1073\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/embedders/lib/python3.9/site-packages/sklearn/utils/validation.py:123\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/embedders/lib/python3.9/site-packages/sklearn/utils/validation.py:172\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    171\u001b[0m     )\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN."
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "TASK = \"regression\"\n",
    "SCORE = [\"f1-micro\", \"accuracy\"] if TASK == \"classification\" else [\"rmse\"]\n",
    "\n",
    "my_tqdm = tqdm(total=len(CURVATURES) * N_SAMPLES)\n",
    "for i, K in enumerate(CURVATURES):\n",
    "    for seed in range(N_SAMPLES):\n",
    "        # Ensure unique seed per trial\n",
    "        seed = seed + N_SAMPLES * i\n",
    "        pm = embedders.manifolds.ProductManifold(signature=[(K, DIM)]).to(sample_device)\n",
    "\n",
    "        # Get X, y\n",
    "        X, y = embedders.gaussian_mixture.gaussian_mixture(\n",
    "            pm=pm,\n",
    "            seed=seed,\n",
    "            num_points=N_POINTS,\n",
    "            num_classes=N_CLASSES,\n",
    "            num_clusters=N_CLUSTERS,\n",
    "            cov_scale_means=COV_SCALE_MEANS / DIM,\n",
    "            cov_scale_points=COV_SCALE_POINTS / DIM,\n",
    "            task=TASK,\n",
    "        )\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        pm = pm.to(device)\n",
    "\n",
    "        if RESAMPLE_SCALES:\n",
    "            scale = 0.5 - np.random.rand() * 20\n",
    "            pm.P[0].scale = torch.exp(torch.tensor(scale)).item()\n",
    "            pm.P[0].manifold._log_scale = torch.nn.Parameter(torch.tensor(scale))\n",
    "\n",
    "        model_results = embedders.benchmarks.benchmark(\n",
    "            X, y, pm, max_depth=MAX_DEPTH, task=TASK, score=SCORE, seed=seed, n_features=N_FEATURES, device=device\n",
    "        )\n",
    "\n",
    "        # Create a flat dictionary for this run\n",
    "        # run_results = {\"curvature\": K, \"seed\": seed}\n",
    "        model_results[\"curvature\"] = K\n",
    "        model_results[\"seed\"] = seed\n",
    "\n",
    "        # # Flatten the nested model results\n",
    "        # for model, metrics in model_results.items():\n",
    "        #     for metric, value in metrics.items():\n",
    "        #         run_results[f\"{model}_{metric}\"] = value\n",
    "\n",
    "        # results.append(run_results)\n",
    "        results.append(model_results)\n",
    "        my_tqdm.update(1)\n",
    "\n",
    "# Convert to DataFrame\n",
    "results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(f\"embedders/data/results_icml/{TASK}_single_curvature.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the values: barplot with statistical significance annotations\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import wilcoxon\n",
    "import matplotlib as mpl\n",
    "\n",
    "# Set font to LaTeX times font\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "plt.rcParams[\"font.serif\"] = [\"Times New Roman\"] + plt.rcParams[\"font.serif\"]\n",
    "plt.rcParams[\"mathtext.fontset\"] = \"cm\"\n",
    "# plt.rcParams[\"text.usetex\"] = True\n",
    "# plt.rcParams[\"text.latex.preamble\"] = r\"\\usepackage{amsmath}\"\n",
    "# plt.rcParams[\"font.size\"] = 10\n",
    "\n",
    "# TASK = \"regression\"\n",
    "TASK = \"classification\"\n",
    "SIGNIFICANCE = \"sig\"\n",
    "# SIGNIFICANCE = \"ns\"\n",
    "CORRECTION = \"bonferroni\"\n",
    "# CORRECTION = \"none\"\n",
    "\n",
    "Y_LABEL = \"$F_1$ Score\" if TASK == \"classification\" else \"RMSE\"\n",
    "\n",
    "results = pd.read_csv(f\"../data/results/{TASK}_single_curvature.tsv\", sep=\"\\t\")\n",
    "CURVATURES = [-4, -2, -1, -0.5, -0.25, 0, 0.25, 0.5, 1, 2, 4]\n",
    "\n",
    "AST_SPACING = 0.1\n",
    "LW = 1\n",
    "FONTSIZE = 10\n",
    "\n",
    "\n",
    "def test(x, y):\n",
    "    # Check x and y are identical\n",
    "    all_same = True\n",
    "    for a, b in zip(x, y):\n",
    "        if a != b:\n",
    "            all_same = False\n",
    "            break\n",
    "    if all_same:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return wilcoxon(x, y).pvalue\n",
    "\n",
    "\n",
    "# All the spec happens up here\n",
    "models1 = [\"product_dt\", \"sklearn_dt\", \"tangent_dt\"]\n",
    "model_names1 = [\"Product DT\", \"Euclidean DT\\n(ambient)\", \"Euclidean DT\\n(tangent plane)\"]\n",
    "models2 = [\"product_rf\", \"sklearn_rf\", \"tangent_rf\"]\n",
    "model_names2 = [\"Product RF\", \"Euclidean RF\\n(ambient)\", \"Euclidean RF\\n(tangent plane)\"]\n",
    "# models3 = [\"knn\", \"perceptron\", \"svm\"]\n",
    "# model_names3 = [\"k-Nearest Neighbors\", \"Perceptron\", \"Support Vector Classifier\"]\n",
    "models3 = [\"knn\"]\n",
    "model_names3 = [\"$k$-Nearest\\nNeighbors\"]\n",
    "colors = [f\"C{i}\" for i in range(len(models1 + models3))]\n",
    "\n",
    "# Critical p-value depends on false discovery correction\n",
    "CRITICAL_VAL = 0.05\n",
    "if CORRECTION == \"bonferroni\":\n",
    "    CRITICAL_VAL /= len(models1 + models3) * (len(models1 + models3) - 1) / 2\n",
    "\n",
    "# Initialize plot\n",
    "# fig, axs = plt.subplots(2, 1, figsize=(15, 10), sharex=True)\n",
    "# fig, axs = plt.subplots(2, 1, figsize=(14, 7), sharex=True)\n",
    "fig, axs = plt.subplots(2, 1, figsize=(6.5, 4), sharex=True)\n",
    "x_vals = np.arange(len(CURVATURES)) * (len(models1 + models3) + 1)\n",
    "\n",
    "for ax, models, model_names in zip(\n",
    "    axs, [models1 + models3, models2 + models3], [model_names1 + model_names3, model_names2 + model_names3]\n",
    "):\n",
    "    bps = []\n",
    "    for i, (model, color) in enumerate(zip(models, colors)):\n",
    "        # Initial boxplot\n",
    "        bp = ax.boxplot(\n",
    "            [results[results[\"curvature\"] == K][model] for K in CURVATURES],\n",
    "            positions=x_vals + i,\n",
    "            widths=0.8,\n",
    "            boxprops=dict(color=color, linewidth=LW),\n",
    "        )\n",
    "\n",
    "        # Fix colors\n",
    "        for element in [\"boxes\", \"whiskers\", \"fliers\", \"means\", \"caps\"]:\n",
    "            plt.setp(bp[element], color=color, linewidth=LW)\n",
    "        plt.setp(bp[\"medians\"], color=\"black\", linewidth=LW)\n",
    "        plt.setp(bp[\"fliers\"], marker=\"o\", markersize=1, markeredgecolor=color, markeredgewidth=LW)\n",
    "\n",
    "        bps.append(bp)\n",
    "\n",
    "    # # Flip y-axis for RMSE\n",
    "    # if TASK == \"regression\":\n",
    "    #     ax.invert_yaxis()\n",
    "    ymin, ymax = ax.get_ylim()\n",
    "\n",
    "    # Add p-value annotations. All start at x_vals, and end at x_vals + i\n",
    "    heights = [0] * len(CURVATURES)  # How many annotations per curvature\n",
    "    # for i, j in [(0, 1), (1, 2), (0, 2), (0, 3), (1, 3), (2, 3)]:\n",
    "    for i in range(len(models)):\n",
    "        for j in range(i + 1, len(models)):\n",
    "            results_K = [results[results[\"curvature\"] == K] for K in CURVATURES]\n",
    "            p_vals = [test(res[models[i]], res[models[j]]) for res in results_K]\n",
    "            em = ymax - ymin\n",
    "\n",
    "            for k, p_val in enumerate(p_vals):\n",
    "                if (SIGNIFICANCE == \"ns\" and p_val > CRITICAL_VAL) or (SIGNIFICANCE == \"sig\" and p_val < CRITICAL_VAL):\n",
    "                    x1, x2 = x_vals[k] + i, x_vals[k] + j\n",
    "                    height = results[results[\"curvature\"] == CURVATURES[k]][models].max().max() + AST_SPACING * em * (\n",
    "                        heights[k] + 1\n",
    "                    )\n",
    "                    annotation = \"*\" if SIGNIFICANCE == \"sig\" else \"ns\"\n",
    "                    ax.text(\n",
    "                        s=annotation,\n",
    "                        x=(x1 + x2) / 2,\n",
    "                        y=height,\n",
    "                        ha=\"center\",\n",
    "                        va=\"center\",\n",
    "                        color=\"black\",\n",
    "                        fontdict={\"weight\": \"bold\", \"size\": FONTSIZE},\n",
    "                    )\n",
    "                    ax.plot(\n",
    "                        [x1, x1, x2, x2],\n",
    "                        [height - 0.03 * em, height - 0.02 * em, height - 0.02 * em, height - 0.03 * em],\n",
    "                        lw=LW,\n",
    "                        color=\"black\",\n",
    "                    )\n",
    "                    heights[k] += 1\n",
    "\n",
    "    # Fix y-lim and remove top/right spines; make background transparent\n",
    "    ax.patch.set_alpha(0)\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.spines[\"left\"].set_linewidth(LW)\n",
    "    ax.spines[\"bottom\"].set_linewidth(LW)\n",
    "    ax.set_xlim(-1, len(CURVATURES) * (len(models1 + models3) + 1))\n",
    "\n",
    "    # Set x-ticks\n",
    "    ax.set_ylabel(Y_LABEL, fontsize=FONTSIZE)\n",
    "    ax.set_xticks(x_vals + 1.5, CURVATURES, fontsize=FONTSIZE)\n",
    "    # ax.legend([bp[\"boxes\"][0] for bp in bps], model_names, fontsize=14, frameon=False, title=\"Model\")\n",
    "    # Make legend to the right of the plot\n",
    "    # ax.legend(\n",
    "    #     [bp[\"boxes\"][0] for bp in bps],\n",
    "    #     model_names,\n",
    "    #     fontsize=16,\n",
    "    #     frameon=False,\n",
    "    #     title=\"Model\",\n",
    "    #     title_fontsize=18,\n",
    "    #     loc=\"center left\",\n",
    "    #     bbox_to_anchor=(1, 0.5),\n",
    "    # )\n",
    "    ax.tick_params(axis=\"y\", labelsize=FONTSIZE)\n",
    "    # ax.set_yscale(\"log\") if TASK == \"regression\" else None\n",
    "\n",
    "    # Move title down\n",
    "    # ax.title.set_position([.5, .9])\n",
    "\n",
    "# axs[0].set_title(\"Decision Trees\", fontsize=18, position=(0.5, 0.9))\n",
    "# axs[1].set_title(\"Random Forests\", fontsize=18, position=(0.5, 0.9))\n",
    "axs[0].text(s=\"Decision Trees\", fontsize=FONTSIZE, x=0.5, y=0.95, ha=\"center\", va=\"center\", transform=axs[0].transAxes)\n",
    "axs[1].text(s=\"Random Forests\", fontsize=FONTSIZE, x=0.5, y=0.95, ha=\"center\", va=\"center\", transform=axs[1].transAxes)\n",
    "axs[1].set_xlabel(\"Curvature\", fontsize=FONTSIZE)\n",
    "\n",
    "# Legend in a new subplot end\n",
    "# ax = fig.add_subplot(111, frameon=False)\n",
    "# ax.legend(\n",
    "#     [bp[\"boxes\"][0] for bp in bps],\n",
    "#     [\"Product\", \"Ambient\", \"Tangent\", \"$k$-NN\"],\n",
    "#     fontsize=16,\n",
    "#     frameon=False,\n",
    "#     title=\"Model\",\n",
    "#     title_fontsize=18,\n",
    "#     loc=\"lower left\",\n",
    "#     bbox_to_anchor=(1, 1),\n",
    "# )\n",
    "# fig.subplots_adjust(right=1.1)\n",
    "legend_ax = fig.add_axes([1.0, 0.15, 0.02, 0.7])\n",
    "legend_ax.axis(\"off\")\n",
    "legend_ax.legend(\n",
    "    # [bp[\"boxes\"][0] for bp in bps],\n",
    "    [mpl.lines.Line2D([0], [0], color=color, lw=LW * 4) for color in colors],\n",
    "    [\"Product\", \"Ambient\", \"Tangent\", \"$k$-NN\"],\n",
    "    fontsize=FONTSIZE,\n",
    "    frameon=False,\n",
    "    title=\"Model\",\n",
    "    loc=\"center\",\n",
    "    title_fontproperties={\"weight\": \"bold\", \"size\": FONTSIZE},\n",
    ")\n",
    "\n",
    "# Move label for x-axis to the right of the plot\n",
    "axs[1].xaxis.set_label_coords(1.06, 0.07)\n",
    "\n",
    "# plt.xlim(-1, len(CURVATURES) * (len(models1 + models3) + 1))\n",
    "plt.suptitle(\n",
    "    f\"{TASK.capitalize()} benchmark: Synthetic (single $K$)\", fontsize=FONTSIZE, fontweight=\"bold\", position=(0.5, 0.93)\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save as pdf\n",
    "plt.savefig(\n",
    "    f\"../figures/single_curvature_{TASK}.pdf\",\n",
    "    bbox_inches=\"tight\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embedders",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
