{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some installs we need\n",
    "# !pip install cvxpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import embedders\n",
    "\n",
    "from hyperdt.product_space_svm import mix_curv_svm\n",
    "from hyperdt.product_space_perceptron import mix_curv_perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabaghi code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quentin's code for signature conversion, slightly rewritten for the new class\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def get_signature_str(pm):\n",
    "    return \",\".join([f\"{M.type.lower()}{M.dim}\" for M in pm.P])\n",
    "\n",
    "\n",
    "def get_embed_data(pm, X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    return {\n",
    "        \"X_train\": X_train.detach().cpu().numpy(),\n",
    "        \"X_test\": X_test.detach().cpu().numpy(),\n",
    "        \"y_train\": y_train.detach().cpu().numpy(),\n",
    "        \"y_test\": y_test.detach().cpu().numpy(),\n",
    "        \"max_norm\": [M.manifold.inner(x, x).max().item() for M, x in zip(pm.P, pm.factorize(X))],\n",
    "        \"curv_value\": [abs(M.curvature) for M in pm.P],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedders part: generate data\n",
    "\n",
    "pm = embedders.manifolds.ProductManifold([(-1, 2), (0, 2), (1, 2)])\n",
    "X, y = embedders.gaussian_mixture.gaussian_mixture(pm)\n",
    "y_relabeled = y * 2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:00<00:00, 1350.90it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 1329.90it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 3786.86it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 4975.43it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 4964.47it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 6268.80it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 6444.50it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 9156.04it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 14060.22it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 9772.66it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 10330.03it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 9588.05it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 9091.81it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 13448.78it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 11560.53it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 12355.81it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 9422.09it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 10732.34it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 8133.88it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 13036.11it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 6936.86it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 10340.73it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 7368.11it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 9840.70it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 9959.41it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 8671.99it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 12715.98it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 13903.10it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 10216.58it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 11782.25it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 10307.19it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 13383.34it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 9438.45it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 12073.63it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 10153.06it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 7663.21it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 11009.72it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 9755.84it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 13723.08it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 11999.58it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 13016.59it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 12397.86it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 12515.59it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 13604.95it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 11215.50it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 10889.38it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 13515.79it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 12090.77it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 10124.29it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 9273.64it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 10837.89it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 9040.37it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 11369.91it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 13218.52it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 12807.92it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 7564.65it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 12673.67it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 13441.07it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 13314.46it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 13281.57it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 13440.43it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 13365.85it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 13480.93it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 13286.20it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 13386.01it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 13466.43it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 11916.31it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 12157.31it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 11980.90it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 10096.93it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 11104.05it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 13212.02it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 13171.51it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 13210.25it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 12905.70it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 9057.90it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 11466.94it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 12969.35it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 11374.00it/s]\n",
      " 45%|████▌     | 361/800 [00:00<00:00, 12067.20it/s]\n",
      "100%|██████████| 200/200 [00:00<00:00, 323.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  1  1  1  1  1 -1  1 -1  1  1  1  1  1  1 -1  1  1  1  1  1 -1  1 -1\n",
      "  1  1  1 -1  1  1 -1 -1  1  1  1  1  1 -1 -1  1  1  1 -1  1  1  1  1  1\n",
      " -1  1  1  1  1  1 -1  1 -1  1  1  1  1 -1  1  1  1  1 -1  1  1 -1 -1  1\n",
      " -1  1  1 -1 -1 -1  1  1 -1  1 -1  1 -1  1  1 -1 -1  1  1 -1 -1 -1  1  1\n",
      "  1 -1  1  1  1  1  1  1  1  1  1  1 -1  1  1  1  1  1  1 -1 -1  1 -1  1\n",
      " -1  1  1 -1 -1  1  1  1 -1  1  1  1  1  1  1  1  1  1  1  1 -1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1 -1  1  1 -1 -1 -1  1  1 -1  1 -1  1  1  1\n",
      "  1  1  1  1  1  1  1  1 -1  1  1 -1  1 -1  1  1  1  1 -1  1 -1 -1  1  1\n",
      "  1  1  1  1  1  1  1 -1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mix_component = get_signature_str(pm)\n",
    "embed_data = get_embed_data(pm, X, y_relabeled)\n",
    "# Convert to (1, -1) labels:\n",
    "\n",
    "ps_perceptron = mix_curv_perceptron(\n",
    "    mix_component=mix_component,\n",
    "    embed_data=embed_data,\n",
    "    multiclass=False,  # for now, just do binary\n",
    "    max_round=10_000,\n",
    "    max_update=10_000,\n",
    ")\n",
    "y_pred = ps_perceptron.process_data()\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 0 1 1 0 1 0 0 1 1 0 0 1\n",
      " 0 0 0 1 0 0 1 1 1 0 0 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0\n",
      " 1 1 0 0 1 1 0 0 0 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 0 1\n",
      " 1 1 1 0 0 1 0 0 0 1 1 1 1 0 0 0 0 0 1 0 1 1 0 0 0 0 1 1 0 0 0 0 1 0 0 1 0\n",
      " 1 0 1 0 0 1 0 0 1 1 0 1 0 0 1 0 1 1 1 0 0 0 0 0 1 1 0 0 0 0 1 1 1 0 0 1 1\n",
      " 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "# What about multiclass?\n",
    "\n",
    "# Embedders part: generate data\n",
    "\n",
    "pm = embedders.manifolds.ProductManifold([(-1, 2), (0, 2), (1, 2)])\n",
    "X, y = embedders.gaussian_mixture.gaussian_mixture(pm, num_classes=2)\n",
    "\n",
    "mix_component = get_signature_str(pm)\n",
    "embed_data = get_embed_data(pm, X, y)\n",
    "# Convert to (1, -1) labels:\n",
    "\n",
    "ps_perceptron = mix_curv_perceptron(\n",
    "    mix_component=mix_component, embed_data=embed_data, multiclass=True, max_round=10_000, max_update=10_000\n",
    ")\n",
    "y_pred = ps_perceptron.process_data()\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1,\n",
       "       0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1,\n",
       "       1, 1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_data[\"y_test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ok, I'm not happy with how their code doesn't return predictions. Let's rewrite this a bit\n",
    "import numpy as np\n",
    "from hyperdt.platt import SigmoidTrain, SigmoidPredict\n",
    "\n",
    "\n",
    "def perceptron_predict(perceptron):\n",
    "    tmp_error_record = {0: 1}\n",
    "    test_probability = np.zeros((perceptron.n_test_samples, perceptron.n_class), dtype=float)\n",
    "    for class_val in perceptron.class_labels:\n",
    "        y_bin_train = np.array([1 if val == class_val else -1 for val in perceptron.y_train])\n",
    "\n",
    "        # Train part\n",
    "        decision_vals = [0] * perceptron.n_train_samples\n",
    "        for idx in range(perceptron.n_train_samples):\n",
    "            decision_vals[idx] = perceptron.mix_classifier_train(idx, tmp_error_record, y_bin_train)\n",
    "            tmp_ab = SigmoidTrain(deci=decision_vals, label=y_bin_train, prior1=None, prior0=None)\n",
    "\n",
    "        # Test part\n",
    "        for idx in range(perceptron.n_test_samples):\n",
    "            yn = perceptron.mix_classifier_test(idx, tmp_error_record, y_bin_train)\n",
    "            test_probability[idx, perceptron.class_labels.index(class_val)] = SigmoidPredict(deci=yn, AB=tmp_ab)\n",
    "\n",
    "    # Get predictions\n",
    "    return test_probability\n",
    "\n",
    "\n",
    "perceptron_predict(ps_perceptron).argmax(axis=1)\n",
    "\n",
    "# Now we start to see the issue: all predictions are 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 0 1 1 0 1 0 0 1 1 0 0 1\n",
      " 0 0 0 1 0 0 1 1 1 0 0 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0\n",
      " 1 1 0 0 1 1 0 0 0 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 0 1\n",
      " 1 1 1 0 0 1 0 0 0 1 1 1 1 0 0 0 0 0 1 0 1 1 0 0 0 0 1 1 0 0 0 0 1 0 0 1 0\n",
      " 1 0 1 0 0 1 0 0 1 1 0 1 0 0 1 0 1 1 1 0 0 0 0 0 1 1 0 0 0 0 1 1 1 0 0 1 1\n",
      " 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "ps_perceptron_more_epochs = mix_curv_perceptron(\n",
    "    mix_component=mix_component,\n",
    "    embed_data=embed_data,\n",
    "    multiclass=False,  # for now, just do binary\n",
    "    max_round=1,\n",
    "    max_update=100,\n",
    ")\n",
    "score = ps_perceptron.process_data()\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.64592858, 0.69015549],\n",
       "       [0.59545233, 0.64249456],\n",
       "       [0.20436469, 0.23874382],\n",
       "       [0.33006785, 0.37561037],\n",
       "       [0.3794162 , 0.42742353],\n",
       "       [0.75062549, 0.78610532],\n",
       "       [0.7002529 , 0.74042111],\n",
       "       [0.4437521 , 0.49342738],\n",
       "       [0.41373555, 0.46284661],\n",
       "       [0.62736935, 0.67273995],\n",
       "       [0.44408791, 0.49376741],\n",
       "       [0.63791642, 0.68265242],\n",
       "       [0.43520183, 0.48475409],\n",
       "       [0.31560773, 0.36022789],\n",
       "       [0.3059968 , 0.34995297],\n",
       "       [0.30616528, 0.35013345],\n",
       "       [0.84869997, 0.87259459],\n",
       "       [0.39698415, 0.44561819],\n",
       "       [0.62015168, 0.66593313],\n",
       "       [0.61513658, 0.66119225],\n",
       "       [0.46922468, 0.51909045],\n",
       "       [0.59065267, 0.63791363],\n",
       "       [0.80847747, 0.83750818],\n",
       "       [0.41215829, 0.46122943],\n",
       "       [0.51230572, 0.56190298],\n",
       "       [0.42210602, 0.47141173],\n",
       "       [0.57250984, 0.6205197 ],\n",
       "       [0.44227191, 0.49192803],\n",
       "       [0.34905478, 0.39566982],\n",
       "       [0.60352511, 0.65018009],\n",
       "       [0.51303721, 0.56262359],\n",
       "       [0.49612055, 0.54590483],\n",
       "       [0.58521898, 0.63271719],\n",
       "       [0.45644983, 0.50625286],\n",
       "       [0.4858998 , 0.53574896],\n",
       "       [0.37069322, 0.41834086],\n",
       "       [0.5267403 , 0.57608429],\n",
       "       [0.52869733, 0.57800074],\n",
       "       [0.59075698, 0.63801328],\n",
       "       [0.29724608, 0.34056208],\n",
       "       [0.6862542 , 0.72756851],\n",
       "       [0.33300824, 0.37872712],\n",
       "       [0.53433957, 0.58351771],\n",
       "       [0.65116602, 0.69504758],\n",
       "       [0.42167382, 0.4709702 ],\n",
       "       [0.38020996, 0.42824842],\n",
       "       [0.5527969 , 0.60147957],\n",
       "       [0.42196293, 0.47126557],\n",
       "       [0.48697577, 0.53682005],\n",
       "       [0.43067742, 0.48015247],\n",
       "       [0.40865349, 0.4576322 ],\n",
       "       [0.3109644 , 0.35526887],\n",
       "       [0.6199089 , 0.66570384],\n",
       "       [0.29064878, 0.33345957],\n",
       "       [0.47365821, 0.52353041],\n",
       "       [0.4940736 , 0.54387419],\n",
       "       [0.3377549 , 0.38375051],\n",
       "       [0.63427131, 0.67923121],\n",
       "       [0.43282714, 0.48233992],\n",
       "       [0.45743093, 0.50724112],\n",
       "       [0.32613355, 0.3714342 ],\n",
       "       [0.75466953, 0.78973516],\n",
       "       [0.32792481, 0.37333642],\n",
       "       [0.26887713, 0.309882  ],\n",
       "       [0.31952679, 0.36440601],\n",
       "       [0.57715129, 0.62498133],\n",
       "       [0.45448735, 0.50427491],\n",
       "       [0.40596896, 0.45487341],\n",
       "       [0.43347629, 0.48300009],\n",
       "       [0.20153814, 0.23558257],\n",
       "       [0.35390451, 0.40076847],\n",
       "       [0.32836515, 0.37380382],\n",
       "       [0.40543204, 0.45432128],\n",
       "       [0.37551723, 0.42336779],\n",
       "       [0.34687057, 0.39337019],\n",
       "       [0.4710857 , 0.52095512],\n",
       "       [0.37402082, 0.42180949],\n",
       "       [0.51741602, 0.5669329 ],\n",
       "       [0.59290282, 0.64006231],\n",
       "       [0.32414557, 0.36932142],\n",
       "       [0.28383381, 0.32610226],\n",
       "       [0.40736672, 0.45631021],\n",
       "       [0.45518799, 0.50498126],\n",
       "       [0.55812815, 0.60664343],\n",
       "       [0.55509841, 0.60371014],\n",
       "       [0.68359056, 0.72511513],\n",
       "       [0.38963521, 0.43802292],\n",
       "       [0.70505067, 0.74481024],\n",
       "       [0.56341787, 0.61175637],\n",
       "       [0.8398204 , 0.86489412],\n",
       "       [0.59594675, 0.64296595],\n",
       "       [0.35867907, 0.40577819],\n",
       "       [0.52758314, 0.57690984],\n",
       "       [0.54171358, 0.59070947],\n",
       "       [0.49715945, 0.54693483],\n",
       "       [0.50583428, 0.55551867],\n",
       "       [0.40172262, 0.45050348],\n",
       "       [0.56348082, 0.61181715],\n",
       "       [0.6849862 , 0.72640092],\n",
       "       [0.50947885, 0.55911619],\n",
       "       [0.54852915, 0.597338  ],\n",
       "       [0.30316871, 0.34692171],\n",
       "       [0.57585068, 0.62373193],\n",
       "       [0.46849889, 0.51836284],\n",
       "       [0.37767031, 0.42560824],\n",
       "       [0.49743541, 0.54720835],\n",
       "       [0.6962804 , 0.73678085],\n",
       "       [0.63425978, 0.67922039],\n",
       "       [0.48178379, 0.53164736],\n",
       "       [0.49055519, 0.54037993],\n",
       "       [0.4224169 , 0.47172928],\n",
       "       [0.67171645, 0.71414771],\n",
       "       [0.50795631, 0.55761394],\n",
       "       [0.34032258, 0.38646381],\n",
       "       [0.64494153, 0.68923241],\n",
       "       [0.37277324, 0.42050959],\n",
       "       [0.63069227, 0.67586731],\n",
       "       [0.57012362, 0.61822275],\n",
       "       [0.45042075, 0.50017129],\n",
       "       [0.25520763, 0.29496889],\n",
       "       [0.39908543, 0.44778574],\n",
       "       [0.65964905, 0.70295029],\n",
       "       [0.40387564, 0.4527201 ],\n",
       "       [0.33319812, 0.37892826],\n",
       "       [0.49482209, 0.54461691],\n",
       "       [0.21826695, 0.25423747],\n",
       "       [0.64612761, 0.69034157],\n",
       "       [0.41877487, 0.4680066 ],\n",
       "       [0.59807589, 0.64499493],\n",
       "       [0.62027706, 0.66605153],\n",
       "       [0.50737451, 0.55703966],\n",
       "       [0.49462101, 0.5444174 ],\n",
       "       [0.54285799, 0.59182371],\n",
       "       [0.5044317 , 0.55413281],\n",
       "       [0.49010833, 0.53993579],\n",
       "       [0.24719356, 0.286186  ],\n",
       "       [0.28694192, 0.3294603 ],\n",
       "       [0.55067635, 0.59942258],\n",
       "       [0.73652551, 0.77340583],\n",
       "       [0.29623022, 0.33946969],\n",
       "       [0.34014902, 0.38628049],\n",
       "       [0.27310789, 0.31448044],\n",
       "       [0.54815247, 0.59697212],\n",
       "       [0.55949128, 0.60796202],\n",
       "       [0.36550424, 0.41292254],\n",
       "       [0.42395906, 0.47330395],\n",
       "       [0.44697265, 0.49668653],\n",
       "       [0.65337776, 0.69711051],\n",
       "       [0.67766417, 0.71964752],\n",
       "       [0.65996323, 0.70324248],\n",
       "       [0.69220588, 0.73304135],\n",
       "       [0.25127511, 0.29066279],\n",
       "       [0.38952407, 0.43790787],\n",
       "       [0.52734893, 0.57668046],\n",
       "       [0.5682347 , 0.61640299],\n",
       "       [0.30232128, 0.3460127 ],\n",
       "       [0.67599109, 0.7181017 ],\n",
       "       [0.57843408, 0.62621299],\n",
       "       [0.52899879, 0.57829582],\n",
       "       [0.35416072, 0.40103755],\n",
       "       [0.3805869 , 0.42864004],\n",
       "       [0.55390604, 0.60255478],\n",
       "       [0.57701049, 0.62484611],\n",
       "       [0.60759184, 0.65404259],\n",
       "       [0.62021602, 0.66599389],\n",
       "       [0.608891  , 0.65527522],\n",
       "       [0.31713497, 0.36185689],\n",
       "       [0.59092884, 0.63817745],\n",
       "       [0.19670713, 0.23017073],\n",
       "       [0.33760621, 0.38359331],\n",
       "       [0.56613267, 0.61437631],\n",
       "       [0.27503417, 0.31657144],\n",
       "       [0.67313538, 0.71546093],\n",
       "       [0.70860479, 0.74805647],\n",
       "       [0.44243879, 0.49209712],\n",
       "       [0.31524336, 0.35983909],\n",
       "       [0.33438462, 0.38018476],\n",
       "       [0.40144396, 0.45021644],\n",
       "       [0.55178175, 0.60049506],\n",
       "       [0.69513067, 0.73572625],\n",
       "       [0.51209913, 0.56169943],\n",
       "       [0.36095518, 0.40816296],\n",
       "       [0.3720041 , 0.41970786],\n",
       "       [0.59761907, 0.64455974],\n",
       "       [0.65406709, 0.6977531 ],\n",
       "       [0.47131695, 0.52118673],\n",
       "       [0.5369015 , 0.58601869],\n",
       "       [0.48967363, 0.53950365],\n",
       "       [0.44647604, 0.49618425],\n",
       "       [0.63749491, 0.68225705],\n",
       "       [0.55631072, 0.60488428],\n",
       "       [0.47488442, 0.524757  ],\n",
       "       [0.28716927, 0.32970576],\n",
       "       [0.68872563, 0.72984261],\n",
       "       [0.59504204, 0.6421033 ],\n",
       "       [0.59093753, 0.63818575],\n",
       "       [0.31949111, 0.36436799],\n",
       "       [0.48742819, 0.53727028],\n",
       "       [0.2435962 , 0.28223394],\n",
       "       [0.23264484, 0.27016596]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron_predict(ps_perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 106/4568 [00:00<00:01, 2556.86it/s]\n",
      "100%|██████████| 1142/1142 [00:00<00:00, 1390.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1 -1  1 ...  1 -1  1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Can we force the perceptron to predict 0s?\n",
    "import torch\n",
    "\n",
    "X_0_bias = torch.cat([X[y == 0]] * 10 + [X], dim=0)\n",
    "y_0_bias = torch.cat([torch.zeros_like(y[y == 0])] * 10 + [y], dim=0)\n",
    "\n",
    "embed_data_0_bias = get_embed_data(pm, X_0_bias, y_0_bias)\n",
    "\n",
    "ps_perceptron_0_bias = mix_curv_perceptron(\n",
    "    mix_component=mix_component,\n",
    "    embed_data=embed_data_0_bias,\n",
    "    multiclass=False,  # for now, just do binary\n",
    "    max_round=1000,\n",
    "    max_update=100,\n",
    ")\n",
    "score = ps_perceptron_0_bias.process_data()\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mperceptron_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mps_perceptron_0_bias\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39margmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[40], line 15\u001b[0m, in \u001b[0;36mperceptron_predict\u001b[0;34m(perceptron)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(perceptron\u001b[38;5;241m.\u001b[39mn_train_samples):\n\u001b[1;32m     14\u001b[0m     decision_vals[idx] \u001b[38;5;241m=\u001b[39m perceptron\u001b[38;5;241m.\u001b[39mmix_classifier_train(idx, tmp_error_record, y_bin_train)\n\u001b[0;32m---> 15\u001b[0m     tmp_ab \u001b[38;5;241m=\u001b[39m \u001b[43mSigmoidTrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeci\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecision_vals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_bin_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprior1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprior0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Test part\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(perceptron\u001b[38;5;241m.\u001b[39mn_test_samples):\n",
      "File \u001b[0;32m~/hyperDT_with_submodules/src/hyperdt/platt.py:43\u001b[0m, in \u001b[0;36mSigmoidTrain\u001b[0;34m(deci, label, prior1, prior0)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(length):\n\u001b[1;32m     42\u001b[0m \t\u001b[38;5;28;01mif\u001b[39;00m label[i] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 43\u001b[0m \t\t\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhiTarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \t\u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     45\u001b[0m \t\tt\u001b[38;5;241m.\u001b[39mappend(loTarget)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "perceptron_predict(ps_perceptron_0_bias).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedders part: generate data\n",
    "import embedders\n",
    "\n",
    "pm = embedders.manifolds.ProductManifold([(-1, 2), (0, 2), (1, 2)])\n",
    "X, y = embedders.gaussian_mixture.gaussian_mixture(pm)\n",
    "y_relabeled = y * 2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training perceptron for class 0 vs. rest\n",
      "Converged for class 0 after 7 epochs (no improvement).\n",
      "tensor([[ 514.1910, -514.1910],\n",
      "        [ 150.3096, -150.3096],\n",
      "        [  95.0430,  -95.0430],\n",
      "        ...,\n",
      "        [ 229.6605, -229.6605],\n",
      "        [  31.0748,  -31.0748],\n",
      "        [  20.6654,  -20.6654]], grad_fn=<CopySlices>)\n",
      "tensor(0.9810)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "\n",
    "class ProductSpacePerceptron(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, pm, max_epochs=1000, patience=5):\n",
    "        self.pm = pm  # ProductManifold instance\n",
    "        self.max_epochs = max_epochs\n",
    "        self.patience = patience  # Number of consecutive epochs without improvement to consider convergence\n",
    "        self.classes_ = None\n",
    "        self.classifiers_ = {}  # Dictionary to store classifiers for one-vs-rest approach\n",
    "        self.R = []  # To store maximum radius for each hyperbolic manifold\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Identify unique classes for multiclass classification\n",
    "        self.classes_ = torch.unique(y).tolist()\n",
    "\n",
    "        # Compute maximum hyperbolic radii for each hyperbolic manifold\n",
    "        self.R = [0] * len(self.pm.P)\n",
    "        for i, (M, x) in enumerate(zip(self.pm.P, self.pm.factorize(X))):\n",
    "            if M.type == \"H\":\n",
    "                self.R[i] = torch.sqrt(\n",
    "                    torch.abs(M.manifold.inner(x, x).max())\n",
    "                ).item()  # Use absolute value for Minkowski norm\n",
    "\n",
    "        # Relabel y to -1 and 1 for binary classification per class\n",
    "        for class_label in self.classes_:\n",
    "            # Binary classification shortcut\n",
    "            if len(self.classes_) == 2 and class_label == self.classes_[1]:\n",
    "                self.classifiers_[class_label] = -1 * self.classifiers_[self.classes_[0]]\n",
    "\n",
    "            else:\n",
    "                print(f\"Training perceptron for class {class_label} vs. rest\")\n",
    "                binary_y = torch.where(y == class_label, 1, -1)  # One-vs-rest relabeling\n",
    "\n",
    "                # Initialize decision function g for this binary classifier\n",
    "                g = torch.zeros(X.shape[1], dtype=X.dtype, device=X.device)\n",
    "\n",
    "                n_epochs = 0\n",
    "                epochs_without_improvement = 0  # Track consecutive epochs without improvement\n",
    "                best_error_count = float(\"inf\")  # Best error count seen so far\n",
    "\n",
    "                while n_epochs < self.max_epochs:\n",
    "                    errors = 0\n",
    "                    for n in range(X.shape[0]):\n",
    "                        # Compute the decision function value for the current point\n",
    "                        decision_value = g @ X[n]\n",
    "\n",
    "                        # Check if the point is misclassified\n",
    "                        if torch.sign(decision_value) != binary_y[n]:\n",
    "                            # Calculate the kernel K(x, x_n) for the current point x_n\n",
    "                            K = torch.ones(X.shape[0], dtype=X.dtype, device=X.device)  # Start with the bias term\n",
    "\n",
    "                            for i, (M, x) in enumerate(zip(self.pm.P, self.pm.factorize(X))):\n",
    "                                # Compute kernel matrix between x[n:n+1] and all training points\n",
    "                                if M.type == \"E\":\n",
    "                                    K += M.scale * M.manifold.inner(x[n : n + 1], x)  # Kernel matrix for Euclidean\n",
    "                                elif M.type == \"S\":\n",
    "                                    K += M.scale * torch.asin(\n",
    "                                        torch.clamp(M.manifold.inner(x[n : n + 1], x), -1, 1)\n",
    "                                    )  # Kernel matrix for Spherical\n",
    "                                elif M.type == \"H\":\n",
    "                                    K += M.scale * torch.asin(\n",
    "                                        torch.clamp((self.R[i] ** -2) * M.manifold.inner(x[n : n + 1], x), -1, 1)\n",
    "                                    )  # Kernel matrix for Hyperbolic\n",
    "\n",
    "                            # Update decision function using the computed kernel\n",
    "                            g += binary_y[n] * X[n]  # Update with current point only\n",
    "                            errors += 1  # Track the number of errors in this epoch\n",
    "\n",
    "                    # Convergence check based on error improvement\n",
    "                    if errors < best_error_count:\n",
    "                        best_error_count = errors\n",
    "                        epochs_without_improvement = 0  # Reset the counter if we have an improvement\n",
    "                    else:\n",
    "                        epochs_without_improvement += 1\n",
    "\n",
    "                    if epochs_without_improvement >= self.patience:\n",
    "                        print(f\"Converged for class {class_label} after {n_epochs} epochs (no improvement).\")\n",
    "                        break\n",
    "\n",
    "                    n_epochs += 1\n",
    "\n",
    "                # Store the classifier (decision function) for the current class\n",
    "                self.classifiers_[class_label] = g\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Initialize matrix to store decision values for each class\n",
    "        decision_values = torch.zeros((X.shape[0], len(self.classes_)), dtype=X.dtype, device=X.device)\n",
    "\n",
    "        # Compute decision values for each classifier\n",
    "        for idx, class_label in enumerate(self.classes_):\n",
    "            g = self.classifiers_[class_label]\n",
    "            decision_values[:, idx] = X @ g\n",
    "\n",
    "        # Return the class with the highest decision value\n",
    "        print(decision_values)\n",
    "        argmax_idx = torch.argmax(decision_values, dim=1)\n",
    "        return torch.tensor([self.classes_[i] for i in argmax_idx])\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "ps_perc_pac = ProductSpacePerceptron(pm, max_epochs=100, patience=5)\n",
    "ps_perc_pac.fit(X, y)\n",
    "predictions = ps_perc_pac.predict(X)\n",
    "predictions\n",
    "\n",
    "# Check the accuracy\n",
    "print((predictions == y).float().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0001, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0001, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0001, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -0.9999, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0001,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -0.9999, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -0.9998, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0001, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0001, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0001,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0002, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9990, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9999, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -0.9999, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0001, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9999, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -0.9999, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -0.9999, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0001,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -0.9999, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -0.9998, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "       grad_fn=<DifferentiableGraphBackward>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_x = pm.factorize(X)[0]\n",
    "pm.P[0].manifold._log_scale = torch.nn.Parameter(torch.tensor(10.0))\n",
    "pm.P[0].manifold.inner(_x, _x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New code: kernel check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/phil/miniforge3/envs/embedders2/lib/python3.10/site-packages/torch/distributions/wishart.py:271: UserWarning: Singular sample detected.\n",
      "  warnings.warn(\"Singular sample detected.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor(False), tensor(False), tensor(False)]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import embedders\n",
    "\n",
    "pm = embedders.manifolds.ProductManifold([(-1, 2), (0, 2), (1, 2)])\n",
    "X, y = embedders.gaussian_mixture.gaussian_mixture(pm)\n",
    "\n",
    "[x.isnan().any() for x in product_kernel(pm, X, X)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.5703, -0.1795,  1.0183,  ..., -1.0199,  0.2129, -0.2404],\n",
       "        [-0.1795,  1.5708,  0.2632,  ...,  0.7079, -0.8280, -0.9777],\n",
       "        [ 1.0183,  0.2632,  1.5705,  ..., -0.4905,  0.0947, -0.7749],\n",
       "        ...,\n",
       "        [-1.0199,  0.7079, -0.4905,  ...,  1.5708, -0.4669, -0.3033],\n",
       "        [ 0.2129, -0.8280,  0.0947,  ..., -0.4669,  1.5703,  0.3170],\n",
       "        [-0.2404, -0.9777, -0.7749,  ..., -0.3033,  0.3170,  1.5705]],\n",
       "       grad_fn=<AsinBackward0>)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_kernel(pm, X, X)[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(-4), tensor(1.), tensor(2.)]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_kernel(embedders.manifolds.ProductManifold(signature=[(-4, 2), (0, 2), (4, 2)]), X, X)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000, -0.1786,  0.8512,  ..., -0.8521,  0.2113, -0.2381],\n",
       "        [-0.1786,  1.0000,  0.2602,  ...,  0.6502, -0.7366, -0.8292],\n",
       "        [ 0.8512,  0.2602,  1.0000,  ..., -0.4711,  0.0946, -0.6997],\n",
       "        ...,\n",
       "        [-0.8521,  0.6502, -0.4711,  ...,  1.0000, -0.4501, -0.2986],\n",
       "        [ 0.2113, -0.7366,  0.0946,  ..., -0.4501,  1.0000,  0.3117],\n",
       "        [-0.2381, -0.8292, -0.6997,  ..., -0.2986,  0.3117,  1.0000]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "_x = pm.factorize(X)[-1]\n",
    "pm.P[-1].inner(_x, _x) * pm.P[-1].curvature * pm.P[-1].scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],\n",
       "        [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],\n",
       "        [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],\n",
       "        ...,\n",
       "        [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],\n",
       "        [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],\n",
       "        [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pm.P[-1].inner(_x, _x)pm.P[-1].curvature * pm.P[-1].scale\n",
    "import embedders.manifolds\n",
    "\n",
    "\n",
    "embedders.manifolds.Manifold(curvature=2, dim=2).inner(_x, _x) / embedders.manifolds.Manifold(curvature=1, dim=2).inner(\n",
    "    _x, _x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.asin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1000])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm.P[0].manifold.inner(_x[:, None], _x[None, :]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptron = embedders.perceptron.ProductSpacePerceptron(pm)\n",
    "\n",
    "ptron.fit(X, y)\n",
    "(ptron.predict(X) == y).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5600)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do the same thing with train-test split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = embedders.gaussian_mixture.gaussian_mixture(pm)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "ptron = embedders.perceptron.ProductSpacePerceptron(pm)\n",
    "ptron.fit(X_train, y_train)\n",
    "(ptron.predict(X_test) == y_test).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ks, norms = embedders.kernel.product_kernel(pm, X, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 38.8659, -16.0567,  23.4093,  ...,   4.2112, -14.9139,  -2.0029],\n",
       "        [-16.0567,   7.4579, -11.1123,  ...,  -1.8085,   0.5661,  -0.4191],\n",
       "        [ 23.4093, -11.1123,  18.4601,  ...,   2.8568, -12.1712,  -0.5609],\n",
       "        ...,\n",
       "        [  4.2112,  -1.8085,   2.8568,  ...,   2.1052,  -5.3676,   0.5950],\n",
       "        [-14.9139,   0.5661, -12.1712,  ...,  -5.3676,   4.3270,  -3.2937],\n",
       "        [ -2.0029,  -0.4191,  -0.5609,  ...,   0.5950,  -3.2937,   1.2123]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = torch.ones(X.shape[0], X.shape[0])\n",
    "for mat in Ks:\n",
    "    K += mat\n",
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1202, 0.7269, 0.7182, 0.8251, 0.9668, 0.4298, 0.5931, 0.9310])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = torch.rand(X.shape[1])\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = torch.sign(X @ g) != (y * 2 - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.8569e+10,  5.5664e+09,  1.7664e+10,  1.0065e+06, -3.8445e+05,\n",
       "         2.2273e+05,  9.1254e+04, -1.8895e+05], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(((y * 2 - 1)[err, None] * K[err, :]).sum(dim=1)[:, None] * X[err, :]).sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.8569e+10,  5.5664e+09,  1.7664e+10,  1.0065e+06, -3.8445e+05,\n",
       "         2.2273e+05,  9.1254e+04, -1.8895e+05], grad_fn=<SqueezeBackward4>)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((y * 2 - 1)[err, None] * K[err, :]).sum(dim=1) @ X[err]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (582x8 and 582x1000)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[157], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43merr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43merr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m[\u001b[49m\u001b[43merr\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (582x8 and 582x1000)"
     ]
    }
   ],
   "source": [
    "((y * 2 - 1)[err, None]) * X[err] @ K[err]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 8])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K[:, err] @ X[err]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([582])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((y * 2 - 1)[err, None] * K[err, :]).sum(dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "inconsistent tensor size, expected tensor [1000] and src [8] to have the same number of elements, but got 1000 and 8 elements respectively",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[175], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;66;03m# Should be positive\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: inconsistent tensor size, expected tensor [1000] and src [8] to have the same number of elements, but got 1000 and 8 elements respectively"
     ]
    }
   ],
   "source": [
    "(y[0] * K[0]) @ X[0]  # Should be positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-143785.7812, grad_fn=<DotBackward0>), tensor(0))"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(-1 * K[0] @ X) @ X[0], y[0]  # Should be negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(19303.4414, grad_fn=<DotBackward0>), tensor(0))"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(-1 * K[1] @ X) @ X[1], y[1]  # Should be negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-21385.4707, grad_fn=<DotBackward0>), tensor(1))"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(-1 * K[6] @ X) @ X[6], y[6]  # Should be positive"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embedders2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
