{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import embedders\n",
    "import anndata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.9965,  0.0600,  0.0579, -0.0310, -0.0046,  1.0001,  0.0134,  0.0055,\n",
       "         1.0000,  0.0060,  0.0057,  1.0000, -0.0021, -0.0024])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the scRNA embeddings\n",
    "\n",
    "data = torch.tensor(np.load(\"/teamspace/studios/this_studio/embedders/data/blood_cell_scrna/embeddings_s2_e2_h2_3.npy\"))\n",
    "data.shape\n",
    "idx = np.random.choice(data.shape[0], 10_000, replace=False)\n",
    "data = data[idx]  # Take it easy\n",
    "\n",
    "# Also, let's add that dummy dimension for E2\n",
    "# data = torch.hstack([data[:, :3], torch.ones(data.shape[0], 1), data[:, 3:]])\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = torch.tensor(\n",
    "    [\n",
    "        int(x)\n",
    "        for x in anndata.read_h5ad(\"/teamspace/studios/this_studio/embedders/data/blood_cell_scrna/adata.h5ad\").obs[\n",
    "            \"cell_type\"\n",
    "        ]\n",
    "    ]\n",
    ")\n",
    "classes = classes[idx]  # Take it easy\n",
    "classes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device management\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "data = data.to(device)\n",
    "classes = classes.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the appropriate product manifold, which we'll use for indexing\n",
    "\n",
    "pm = embedders.manifolds.ProductManifold(signature=[(1, 2), (0, 2), (-1, 2), (-1, 2), (-1, 2)], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 10])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, we can compute the angles of all 2-d projections\n",
    "\n",
    "angle_vals = torch.zeros(data.shape[0], pm.dim, device=device)\n",
    "\n",
    "for i, M in enumerate(pm.P):\n",
    "    dims = pm.man2dim[i]\n",
    "    dims_target = pm.man2intrinsic[i]\n",
    "    if M.type in [\"H\", \"S\"]:\n",
    "        angle_vals[:, dims_target] = torch.atan2(data[:, dims[0]].view(-1, 1), data[:, dims[1:]])\n",
    "    elif M.type == \"E\":\n",
    "        angle_vals[:, dims_target] = torch.atan2(torch.tensor(1), data[:, dims])\n",
    "\n",
    "angle_vals.shape  # Note that we have gone from (1000, 14) to (1000, 10), the number of intrinsic dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def circular_greater(angles, threshold):\n",
    "    \"\"\"\n",
    "    Check if angles are in the half-circle (threshold, threshold + pi)\n",
    "    \"\"\"\n",
    "    return ((angles - threshold + torch.pi) % (2 * torch.pi)) - torch.pi > 0\n",
    "\n",
    "\n",
    "def calculate_info_gain(values, labels):\n",
    "    batch_size, n_dim = values.shape\n",
    "    n_classes = labels.max().item() + 1\n",
    "\n",
    "    # Calculate total Gini impurity without bincount\n",
    "    label_one_hot = torch.nn.functional.one_hot(labels, n_classes).float()\n",
    "    class_probs = label_one_hot.mean(dim=0)\n",
    "    total_gini = 1 - (class_probs**2).sum()\n",
    "\n",
    "    # Initialize arrays for left and right counts\n",
    "    left_counts = torch.zeros((batch_size, n_dim, n_classes), device=values.device)\n",
    "    right_counts = torch.zeros((batch_size, n_dim, n_classes), device=values.device)\n",
    "\n",
    "    # Calculate left and right counts for each potential split\n",
    "    for i in range(batch_size):\n",
    "        mask = circular_greater(values, values[i].unsqueeze(0))\n",
    "        for j in range(n_dim):\n",
    "            left_mask = ~mask[:, j]\n",
    "            right_mask = mask[:, j]\n",
    "            left_counts[i, j] = label_one_hot[left_mask].sum(dim=0)\n",
    "            right_counts[i, j] = label_one_hot[right_mask].sum(dim=0)\n",
    "\n",
    "    # Calculate Gini impurities for left and right partitions\n",
    "    left_total = left_counts.sum(dim=-1, keepdim=True).clamp(min=1)\n",
    "    right_total = right_counts.sum(dim=-1, keepdim=True).clamp(min=1)\n",
    "    left_gini = 1 - ((left_counts / left_total) ** 2).sum(dim=-1)\n",
    "    right_gini = 1 - ((right_counts / right_total) ** 2).sum(dim=-1)\n",
    "\n",
    "    # Calculate weighted Gini impurity\n",
    "    left_weight = left_total.squeeze(-1) / batch_size\n",
    "    right_weight = right_total.squeeze(-1) / batch_size\n",
    "    weighted_gini = left_weight * left_gini + right_weight * right_gini\n",
    "\n",
    "    # Calculate information gain\n",
    "    info_gain = total_gini - weighted_gini\n",
    "\n",
    "    return info_gain\n",
    "\n",
    "\n",
    "ig = calculate_info_gain(angle_vals, classes)\n",
    "\n",
    "# What's the index?\n",
    "best_idx = torch.argmax(ig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperdt.torch.product_space_DT import ProductSpaceDT\n",
    "from hyperdt.torch.tree import DecisionNode\n",
    "from hyperdt.torch.hyperbolic_trig import _hyperbolic_midpoint\n",
    "\n",
    "\n",
    "class TorchProductSpaceDT(ProductSpaceDT):\n",
    "    def __init__(self, signature):\n",
    "        sig_r = [(x[1], x[0]) for x in signature]\n",
    "        super().__init__(signature=sig_r)\n",
    "        self.pm = embedders.manifolds.ProductManifold(signature=signature)\n",
    "\n",
    "    def _get_angle_vals(self, X):\n",
    "        angle_vals = torch.zeros((X.shape[0], self.pm.dim), device=X.device)\n",
    "\n",
    "        for i, M in enumerate(self.pm.P):\n",
    "            dims = self.pm.man2dim[i]\n",
    "            dims_target = self.pm.man2intrinsic[i]\n",
    "            if M.type in [\"H\", \"S\"]:\n",
    "                angle_vals[:, dims_target] = torch.atan2(X[:, dims[0]].view(-1, 1), X[:, dims[1:]])\n",
    "            elif M.type == \"E\":\n",
    "                angle_vals[:, dims_target] = torch.atan2(torch.tensor(1), X[:, dims])\n",
    "\n",
    "        return angle_vals\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit a decision tree to the data. Modified from HyperbolicDecisionTreeClassifier\n",
    "        to remove multiple timelike dimensions in product space.\"\"\"\n",
    "        # Find all dimensions in product space (including timelike dimensions)\n",
    "        self.all_dims = list(range(sum([space[0] + 1 for space in self.signature])))\n",
    "\n",
    "        # Find indices of timelike dimensions in product space\n",
    "        self.timelike_dims = [0]\n",
    "        for i in range(len(self.signature) - 1):\n",
    "            self.timelike_dims.append(sum([space[0] + 1 for space in self.signature[: i + 1]]))\n",
    "\n",
    "        # Remove timelike dimensions from list of dimensions\n",
    "        # self.dims_ex_time = list(np.delete(np.array(self.all_dims), self.timelike_dims))\n",
    "        self.dims_ex_time = [dim for dim in self.all_dims if dim not in self.timelike_dims]\n",
    "\n",
    "        # Get array of classes\n",
    "        self.classes_ = torch.unique(y)\n",
    "\n",
    "        # First, we can compute the angles of all 2-d projections\n",
    "        angle_vals = self._get_angle_vals(X)\n",
    "        self.tree = self._fit_node(X=angle_vals, y=y, depth=0)\n",
    "\n",
    "    def _fit_node(self, X, y, depth):\n",
    "        print(f\"Depth {depth} with {X.shape} samples\")\n",
    "        # Base case\n",
    "        if depth == self.max_depth or len(X) < self.min_samples_split or len(torch.unique(y)) == 1:\n",
    "            value, probs = self._leaf_values(y)\n",
    "            return DecisionNode(value=value, probs=probs)\n",
    "\n",
    "        # Recursively find the best split:\n",
    "        ig = calculate_info_gain(X, y)\n",
    "        best_idx = torch.argmax(ig)\n",
    "        best_row, best_dim = best_idx // X.shape[1], best_idx % X.shape[1]\n",
    "        best_ig = ig[best_row, best_dim]\n",
    "\n",
    "        # Since we're evaluating greater than, we need to also find the next-largest value and take the midpoint\n",
    "        next_largest = torch.max(X[~circular_greater(X[:, best_dim], X[best_row, best_dim]), best_dim])\n",
    "\n",
    "        # Midpoint computation will depend on manifold; TODO: actually do this\n",
    "        # best_theta = (X[best_row, best_dim] + next_largest) / 2\n",
    "        best_manifold = self.pm.P[self.pm.intrinsic2man[best_dim.item()]]\n",
    "        if best_manifold.type == \"H\":\n",
    "            best_theta = _hyperbolic_midpoint(X[best_row, best_dim], next_largest)\n",
    "        elif best_manifold.type == \"S\":\n",
    "            best_theta = (X[best_row, best_dim] + next_largest) / 2\n",
    "        else:\n",
    "            best_theta = torch.arctan2(torch.tensor([2.0], device=X.device), X[best_row, best_dim] + next_largest)\n",
    "\n",
    "        # Fallback case:\n",
    "        if best_ig <= 0:\n",
    "            print(f\"Fallback triggered at depth {depth}\")\n",
    "            value, probs = self._leaf_values(y)\n",
    "            return DecisionNode(value=value, probs=probs)\n",
    "\n",
    "        # Populate:\n",
    "        node = DecisionNode(feature=best_dim, theta=best_theta)\n",
    "        node.score = best_ig\n",
    "        left, right = circular_greater(X[:, best_dim], best_theta), ~circular_greater(X[:, best_dim], best_theta)\n",
    "        node.left = self._fit_node(X=X[left], y=y[left], depth=depth + 1)\n",
    "        node.right = self._fit_node(X=X[right], y=y[right], depth=depth + 1)\n",
    "        return node\n",
    "\n",
    "    def predict(self, X):\n",
    "        angle_vals = self._get_angle_vals(X)\n",
    "        return torch.tensor([self._traverse(x).value for x in angle_vals], device=X.device)\n",
    "\n",
    "    def _left(self, x, node):\n",
    "        \"\"\"Boolean: Go left?\"\"\"\n",
    "        return circular_greater(x[node.feature], node.theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth 0 with 10000 samples\n",
      "X shape, torch.Size([10000, 10]), y shape torch.Size([10000])\n",
      "Depth 1 with 7838 samples\n",
      "X shape, torch.Size([7838, 10]), y shape torch.Size([7838])\n",
      "Depth 2 with 5825 samples\n",
      "X shape, torch.Size([5825, 10]), y shape torch.Size([5825])\n",
      "Depth 3 with 1605 samples\n",
      "X shape, torch.Size([1605, 10]), y shape torch.Size([1605])\n",
      "Depth 3 with 4220 samples\n",
      "X shape, torch.Size([4220, 10]), y shape torch.Size([4220])\n",
      "Depth 2 with 2013 samples\n",
      "X shape, torch.Size([2013, 10]), y shape torch.Size([2013])\n",
      "Depth 3 with 2013 samples\n",
      "X shape, torch.Size([2013, 10]), y shape torch.Size([2013])\n",
      "Depth 3 with 0 samples\n",
      "X shape, torch.Size([0, 10]), y shape torch.Size([0])\n",
      "Depth 1 with 2162 samples\n",
      "X shape, torch.Size([2162, 10]), y shape torch.Size([2162])\n",
      "Depth 2 with 2162 samples\n",
      "X shape, torch.Size([2162, 10]), y shape torch.Size([2162])\n",
      "Depth 3 with 2162 samples\n",
      "X shape, torch.Size([2162, 10]), y shape torch.Size([2162])\n",
      "Depth 3 with 0 samples\n",
      "X shape, torch.Size([0, 10]), y shape torch.Size([0])\n",
      "Depth 2 with 0 samples\n",
      "X shape, torch.Size([0, 10]), y shape torch.Size([0])\n"
     ]
    }
   ],
   "source": [
    "# Let's test it out\n",
    "\n",
    "tpsdt = TorchProductSpaceDT(signature=[(1, 2), (0, 2), (-1, 2), (-1, 2), (-1, 2)])\n",
    "tpsdt.pm = tpsdt.pm.to(device)\n",
    "tpsdt.fit(data, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/teamspace/studios/this_studio/hyperDT/src/hyperdt/torch/tree.py:174: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(self.predict(X) == y)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.2224, device='cuda:0')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpsdt.score(data, classes).sum() / data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 4, 7, 9], device='cuda:0')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpsdt.predict(data).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth 0 with 500 samples\n",
      "X shape, torch.Size([500, 10]), y shape torch.Size([500])\n",
      "Depth 1 with 376 samples\n",
      "X shape, torch.Size([376, 10]), y shape torch.Size([376])\n",
      "Depth 2 with 269 samples\n",
      "X shape, torch.Size([269, 10]), y shape torch.Size([269])\n",
      "Depth 3 with 122 samples\n",
      "X shape, torch.Size([122, 10]), y shape torch.Size([122])\n",
      "Depth 3 with 147 samples\n",
      "X shape, torch.Size([147, 10]), y shape torch.Size([147])\n",
      "Depth 2 with 107 samples\n",
      "X shape, torch.Size([107, 10]), y shape torch.Size([107])\n",
      "Depth 3 with 107 samples\n",
      "X shape, torch.Size([107, 10]), y shape torch.Size([107])\n",
      "Depth 3 with 0 samples\n",
      "X shape, torch.Size([0, 10]), y shape torch.Size([0])\n",
      "Depth 1 with 124 samples\n",
      "X shape, torch.Size([124, 10]), y shape torch.Size([124])\n",
      "Depth 2 with 124 samples\n",
      "X shape, torch.Size([124, 10]), y shape torch.Size([124])\n",
      "Depth 3 with 124 samples\n",
      "X shape, torch.Size([124, 10]), y shape torch.Size([124])\n",
      "Depth 3 with 0 samples\n",
      "X shape, torch.Size([0, 10]), y shape torch.Size([0])\n",
      "Depth 2 with 0 samples\n",
      "X shape, torch.Size([0, 10]), y shape torch.Size([0])\n",
      "0.826\n",
      "0.21\n",
      "0.218\n"
     ]
    }
   ],
   "source": [
    "# Confirm this is the same thing we get with the non-torch version\n",
    "# Hmm, not exactly. I wonder why...\n",
    "\n",
    "from hyperdt.product_space_DT import ProductSpaceDT\n",
    "\n",
    "tpsdt = TorchProductSpaceDT(signature=[(1, 2), (0, 2), (-1, 2), (-1, 2), (-1, 2)])\n",
    "tpsdt.fit(data[:500], classes[:500])\n",
    "y_torch = tpsdt.predict(data[500:1000])\n",
    "\n",
    "psdt = ProductSpaceDT(signature=[(2, 1), (2, 0), (2, -1), (2, -1), (2, -1)])\n",
    "data_stacked = np.hstack([data[:, :3].cpu().numpy(), torch.ones(data.shape[0], 1), data[:, 3:].cpu().numpy()])\n",
    "psdt.fit(data_stacked[:500], classes[:500].cpu().numpy())\n",
    "y_numpy = psdt.predict(data_stacked[500:1000])\n",
    "\n",
    "print((y_torch.cpu().numpy() == y_numpy).sum() / y_torch.shape[0])\n",
    "print((y_torch.cpu().numpy() == classes[500:1000].cpu().numpy()).sum() / y_torch.shape[0])\n",
    "print((y_numpy == classes[500:1000].cpu().numpy()).sum() / y_torch.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
