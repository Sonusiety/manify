{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import embedders\n",
    "import anndata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.9942,  0.0777,  0.0749,  1.0000, -0.0303, -0.0044,  1.0001,  0.0133,\n",
       "         0.0052,  1.0000,  0.0060,  0.0045,  1.0000, -0.0023, -0.0032])"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the scRNA embeddings\n",
    "\n",
    "data = torch.tensor(np.load(\"/teamspace/studios/this_studio/embedders/data/blood_cell_scrna/embeddings_s2_e2_h2_3.npy\"))\n",
    "data.shape\n",
    "idx = np.random.choice(data.shape[0], 10_000, replace=False)\n",
    "data = data[idx]  # Take it easy\n",
    "\n",
    "# Also, let's add that dummy dimension for E2\n",
    "data = torch.hstack([data[:, :3], torch.ones(data.shape[0], 1), data[:, 3:]])\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000])"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = torch.tensor(\n",
    "    [\n",
    "        int(x)\n",
    "        for x in anndata.read_h5ad(\"/teamspace/studios/this_studio/embedders/data/blood_cell_scrna/adata.h5ad\").obs[\n",
    "            \"cell_type\"\n",
    "        ]\n",
    "    ]\n",
    ")\n",
    "classes = classes[idx]  # Take it easy\n",
    "classes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the appropriate product manifold, which we'll use for indexing\n",
    "\n",
    "pm = embedders.manifolds.ProductManifold(signature=[(1, 2), (0, 2), (-1, 2), (-1, 2), (-1, 2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M0\tspecial 0\t spacelike [1, 2]\n",
      "M1\tspecial 3\t spacelike [4]\n",
      "M2\tspecial 5\t spacelike [6, 7]\n",
      "M3\tspecial 8\t spacelike [9, 10]\n",
      "M4\tspecial 11\t spacelike [12, 13]\n"
     ]
    }
   ],
   "source": [
    "# What if we expressed everything in terms of angles in a 2-d projection to (timelike_dim, some_spatial_dim)?\n",
    "\n",
    "timelike_dims = [pm.man2dim[i][0] for i in range(pm.n_manifolds)]\n",
    "spacelike_dims = [pm.man2dim[i][1:] for i in range(pm.n_manifolds)]\n",
    "\n",
    "for i in range(pm.n_manifolds):\n",
    "    print(f\"M{i}\\tspecial {timelike_dims[i]}\\t spacelike {spacelike_dims[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 10])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, we can compute the angles of all 2-d projections\n",
    "\n",
    "angle_vals = torch.zeros(data.shape[0], pm.dim)\n",
    "\n",
    "for i, M in enumerate(pm.P):\n",
    "    dims = pm.man2dim[i]\n",
    "    dims_target = pm.man2intrinsic[i]\n",
    "    if M.type in [\"H\", \"S\"]:\n",
    "        angle_vals[:, dims_target] = torch.atan2(data[:, dims[0]].view(-1, 1), data[:, dims[1:]])\n",
    "    elif M.type == \"E\":\n",
    "        angle_vals[:, dims_target] = torch.atan2(torch.tensor(1), data[:, dims])\n",
    "\n",
    "angle_vals.shape  # Note that we have gone from (1000, 14) to (1000, 10), the number of intrinsic dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[242], line 40\u001b[0m\n\u001b[1;32m     35\u001b[0m     info_gain \u001b[38;5;241m=\u001b[39m total_gini \u001b[38;5;241m-\u001b[39m weighted_gini\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m info_gain\n\u001b[0;32m---> 40\u001b[0m ig \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_info_gain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mangle_vals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# What's the index?\u001b[39;00m\n\u001b[1;32m     43\u001b[0m best_idx \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(ig)\n",
      "Cell \u001b[0;32mIn[242], line 25\u001b[0m, in \u001b[0;36mcalculate_info_gain\u001b[0;34m(values, labels)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_dim):\n\u001b[1;32m     24\u001b[0m         left_counts[i, j] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mone_hot(labels[\u001b[38;5;241m~\u001b[39mmask[:, j]], n_classes)\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 25\u001b[0m         right_counts[i, j] \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mone_hot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_classes\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Calculate Gini impurities for left and right partitions\u001b[39;00m\n\u001b[1;32m     28\u001b[0m left_gini \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m ((left_counts \u001b[38;5;241m/\u001b[39m left_counts\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mclamp(\u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def circular_greater(angles, threshold):\n",
    "    \"\"\"\n",
    "    Check if angles are in the half-circle (threshold, threshold + pi)\n",
    "    \"\"\"\n",
    "    return ((angles - threshold + torch.pi) % (2 * torch.pi)) - torch.pi > 0\n",
    "\n",
    "\n",
    "def calculate_info_gain(values, labels):\n",
    "    batch_size, n_dim = values.shape\n",
    "    n_classes = labels.max().item() + 1\n",
    "\n",
    "    # Calculate total Gini impurity\n",
    "    class_counts = torch.bincount(labels, minlength=n_classes).float()\n",
    "    total_gini = 1 - ((class_counts / batch_size) ** 2).sum()\n",
    "\n",
    "    # Initialize arrays for left and right counts\n",
    "    left_counts = torch.zeros((batch_size, n_dim, n_classes), device=values.device)\n",
    "    right_counts = torch.zeros((batch_size, n_dim, n_classes), device=values.device)\n",
    "\n",
    "    # Calculate left and right counts for each potential split\n",
    "    for i in range(batch_size):\n",
    "        mask = circular_greater(values, values[i].unsqueeze(0))\n",
    "        for j in range(n_dim):\n",
    "            left_counts[i, j] = torch.nn.functional.one_hot(labels[~mask[:, j]], n_classes).sum(dim=0)\n",
    "            right_counts[i, j] = torch.nn.functional.one_hot(labels[mask[:, j]], n_classes).sum(dim=0)\n",
    "\n",
    "    # Calculate Gini impurities for left and right partitions\n",
    "    left_gini = 1 - ((left_counts / left_counts.sum(dim=-1, keepdim=True).clamp(min=1)) ** 2).sum(dim=-1)\n",
    "    right_gini = 1 - ((right_counts / right_counts.sum(dim=-1, keepdim=True).clamp(min=1)) ** 2).sum(dim=-1)\n",
    "\n",
    "    # Calculate weighted Gini impurity\n",
    "    weighted_gini = (left_counts.sum(dim=-1) * left_gini + right_counts.sum(dim=-1) * right_gini) / batch_size\n",
    "\n",
    "    # Calculate information gain\n",
    "    info_gain = total_gini - weighted_gini\n",
    "\n",
    "    return info_gain\n",
    "\n",
    "\n",
    "ig = calculate_info_gain(angle_vals, classes)\n",
    "\n",
    "# What's the index?\n",
    "best_idx = torch.argmax(ig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperdt.torch.product_space_DT import ProductSpaceDT\n",
    "from hyperdt.torch.tree import DecisionNode\n",
    "from hyperdt.torch.hyperbolic_trig import _hyperbolic_midpoint\n",
    "\n",
    "\n",
    "class TorchProductSpaceDT(ProductSpaceDT):\n",
    "    def __init__(self, signature):\n",
    "        sig_r = [(x[1], x[0]) for x in signature]\n",
    "        super().__init__(signature=sig_r)\n",
    "        self.pm = embedders.manifolds.ProductManifold(signature=signature)\n",
    "\n",
    "    def _get_angle_vals(self, X):\n",
    "        angle_vals = torch.zeros(data.shape[0], pm.dim)\n",
    "\n",
    "        for i, M in enumerate(pm.P):\n",
    "            dims = pm.man2dim[i]\n",
    "            dims_target = pm.man2intrinsic[i]\n",
    "            if M.type in [\"H\", \"S\"]:\n",
    "                angle_vals[:, dims_target] = torch.atan2(data[:, dims[0]].view(-1, 1), data[:, dims[1:]])\n",
    "            elif M.type == \"E\":\n",
    "                angle_vals[:, dims_target] = torch.atan2(torch.tensor(1), data[:, dims])\n",
    "\n",
    "        return angle_vals\n",
    "\n",
    "    def _fit(self, X, y):\n",
    "        \"\"\"Fit a decision tree to the data. Modified from HyperbolicDecisionTreeClassifier\n",
    "        to remove multiple timelike dimensions in product space.\"\"\"\n",
    "        # Find all dimensions in product space (including timelike dimensions)\n",
    "        self.all_dims = list(range(sum([space[0] + 1 for space in self.signature])))\n",
    "\n",
    "        # Find indices of timelike dimensions in product space\n",
    "        self.timelike_dims = [0]\n",
    "        for i in range(len(self.signature) - 1):\n",
    "            self.timelike_dims.append(sum([space[0] + 1 for space in self.signature[: i + 1]]))\n",
    "\n",
    "        # Remove timelike dimensions from list of dimensions\n",
    "        # self.dims_ex_time = list(np.delete(np.array(self.all_dims), self.timelike_dims))\n",
    "        self.dims_ex_time = [dim for dim in self.all_dims if dim not in self.timelike_dims]\n",
    "\n",
    "        # Get array of classes\n",
    "        self.classes_ = torch.unique(y)\n",
    "\n",
    "        # Call recursive fitting function\n",
    "        timelike_dims = [self.pm.man2dim[i][0] for i in range(pm.n_manifolds)]\n",
    "        spacelike_dims = [self.pm.man2dim[i][1:] for i in range(pm.n_manifolds)]\n",
    "\n",
    "        # First, we can compute the angles of all 2-d projections\n",
    "        angle_vals = self._get_angle_vals(X)\n",
    "        self.tree = self._fit_node(X=angle_vals, y=y, depth=0)\n",
    "\n",
    "    def _fit_node(self, X, y, depth):\n",
    "        print(f\"Depth {depth} with {len(X)} samples\")\n",
    "        # Base case\n",
    "        if depth == self.max_depth or len(X) < self.min_samples_split or len(torch.unique(y)) == 1:\n",
    "            value, probs = self._leaf_values(y)\n",
    "            return hyperdt.torch.tree.DecisionNode(value=value, probs=probs)\n",
    "\n",
    "        # Recursively find the best split:\n",
    "        ig = calculate_info_gain(X, y)\n",
    "        best_idx = torch.argmax(ig)\n",
    "        best_row, best_dim = best_idx // X.shape[1], best_idx % X.shape[1]\n",
    "        best_ig = ig[best_row, best_dim]\n",
    "\n",
    "        # Since we're evaluating greater than, we need to also find the next-largest value and take the midpoint\n",
    "        next_largest = torch.max(X[~circular_greater(X[:, best_dim], X[best_row, best_dim]), best_dim])\n",
    "\n",
    "        # Midpoint computation will depend on manifold; TODO: actually do this\n",
    "        # best_theta = (X[best_row, best_dim] + next_largest) / 2\n",
    "        best_manifold = self.pm.P[self.pm.intrinsic2man[best_dim]]\n",
    "        if best_manifold.type == \"H\":\n",
    "            best_theta = _hyperbolic_midpoint(X[best_row, best_dim], next_largest)\n",
    "        elif best_manifold.type == \"S\":\n",
    "            best_theta = (X[best_row, best_dim] + next_largest) / 2\n",
    "        else:\n",
    "            \n",
    "\n",
    "        # Fallback case:\n",
    "        if best_ig <= 0:\n",
    "            print(f\"Fallback triggered at depth {depth}\")\n",
    "            value, probs = self._leaf_values(y)\n",
    "            return DecisionNode(value=value, probs=probs)\n",
    "\n",
    "        # Populate:\n",
    "        node = DecisionNode(feature=best_dim, theta=best_theta)\n",
    "        node.score = best_ig\n",
    "        left, right = circular_greater(X[:, best_dim], best_theta), ~circular_greater(X[:, best_dim], best_theta)\n",
    "        node.left = self._fit_node(X=X[left], y=y[left], depth=depth + 1)\n",
    "        node.right = self._fit_node(X=X[right], y=y[right], depth=depth + 1)\n",
    "        return node\n",
    "\n",
    "    def predict(self, X):\n",
    "        angle_vals = self._get_angle_vals(X)\n",
    "        return torch.Tensor([self._traverse(x).value for x in X])\n",
    "\n",
    "    def _left(self, x, node):\n",
    "        \"\"\"Boolean: Go left?\"\"\"\n",
    "        return circular_greater(x[node.feature], node.theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth 0 with 10000 samples\n",
      "Depth 1 with 2246 samples\n",
      "Depth 2 with 1130 samples\n",
      "Depth 3 with 420 samples\n",
      "tensor(3) tensor([0.0571, 0.1190, 0.0190, 0.2357, 0.1095, 0.0500, 0.0952, 0.0476, 0.0714,\n",
      "        0.1952])\n",
      "Depth 3 with 710 samples\n",
      "tensor(4) tensor([0.0577, 0.0549, 0.0507, 0.1676, 0.2944, 0.0366, 0.0507, 0.0352, 0.0493,\n",
      "        0.2028])\n",
      "Depth 2 with 1116 samples\n",
      "Depth 3 with 110 samples\n",
      "tensor(2) tensor([0.0273, 0.0091, 0.6364, 0.0909, 0.1273, 0.0091, 0.0000, 0.0273, 0.0000,\n",
      "        0.0727])\n",
      "Depth 3 with 1006 samples\n",
      "tensor(4) tensor([0.0358, 0.0139, 0.0765, 0.1889, 0.5318, 0.0189, 0.0149, 0.0169, 0.0119,\n",
      "        0.0905])\n",
      "Depth 1 with 7754 samples\n",
      "Depth 2 with 2953 samples\n",
      "Depth 3 with 1554 samples\n",
      "tensor(9) tensor([0.1094, 0.1023, 0.0225, 0.1351, 0.0611, 0.1004, 0.0920, 0.1042, 0.1075,\n",
      "        0.1654])\n",
      "Depth 3 with 1399 samples\n",
      "tensor(3) tensor([0.1165, 0.1551, 0.0122, 0.1565, 0.0279, 0.1072, 0.1565, 0.0443, 0.1408,\n",
      "        0.0829])\n",
      "Depth 2 with 4801 samples\n",
      "Depth 3 with 1599 samples\n",
      "tensor(7) tensor([0.1176, 0.1151, 0.0188, 0.0519, 0.0075, 0.1501, 0.0694, 0.2664, 0.1345,\n",
      "        0.0688])\n",
      "Depth 3 with 3202 samples\n",
      "tensor(1) tensor([0.1321, 0.1936, 0.0016, 0.0450, 0.0034, 0.1440, 0.1793, 0.1102, 0.1649,\n",
      "        0.0259])\n"
     ]
    }
   ],
   "source": [
    "# Let's test it out\n",
    "\n",
    "tpsdt = TorchProductSpaceDT(signature=[(1, 2), (0, 2), (-1, 2), (-1, 2), (-1, 2)])\n",
    "tpsdt.fit(data, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2435)"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpsdt.score(data, classes).sum() / data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
