{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import embedders\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Filter out warnings raised when sampling Wishart distribution in Gaussian mixtures\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "if device != torch.device(\"cuda\"):\n",
    "    sample_device = torch.device(\"cpu\")\n",
    "else:\n",
    "    sample_device = device\n",
    "\n",
    "print(f\"Device: {device}, Sample Device: {sample_device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shared hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FEATURES = \"d_choose_2\"\n",
    "MAX_DEPTH = 3\n",
    "MODELS = [\"product_dt\", \"product_rf\", \"tangent_mlp\", \"ambient_mlp\", \"tangent_gnn\", \"ambient_gnn\"]\n",
    "N_SAMPLES = 10\n",
    "\n",
    "DOWNSAMPLE = 1000  # Used when number of datapoints per dataset is too large to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick test hyperparameters\n",
    "\n",
    "# N_SAMPLES = 1\n",
    "# DOWNSAMPLE = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single curvature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURVATURES = [-4, -2, -1, -0.5, -0.25, 0, 0.25, 0.5, 1, 2, 4]\n",
    "DIM = 2\n",
    "N_POINTS = 1_000\n",
    "N_CLASSES = 8\n",
    "N_CLUSTERS = 32\n",
    "COV_SCALE_MEANS = 1.0\n",
    "COV_SCALE_POINTS = 1.0\n",
    "\n",
    "RESAMPLE_SCALES = False\n",
    "\n",
    "# SCORE = \"f1-micro\" if TASK == \"classification\" else \"rmse\"\n",
    "\n",
    "for TASK in [\"classification\", \"regression\"]:\n",
    "    results = []\n",
    "    SCORE = [\"f1-micro\", \"accuracy\"] if TASK == \"classification\" else [\"rmse\"]\n",
    "    my_tqdm = tqdm(total=len(CURVATURES) * N_SAMPLES)\n",
    "    for i, K in enumerate(CURVATURES):\n",
    "        for seed in range(N_SAMPLES):\n",
    "            try:\n",
    "                # Ensure unique seed per trial\n",
    "                seed = seed + N_SAMPLES * i\n",
    "                pm = embedders.manifolds.ProductManifold(signature=[(K, DIM)]).to(sample_device)\n",
    "\n",
    "                # Get X, y\n",
    "                X, y = embedders.gaussian_mixture.gaussian_mixture(\n",
    "                    pm=pm,\n",
    "                    seed=seed,\n",
    "                    num_points=N_POINTS,\n",
    "                    num_classes=N_CLASSES,\n",
    "                    num_clusters=N_CLUSTERS,\n",
    "                    cov_scale_means=COV_SCALE_MEANS / DIM,\n",
    "                    cov_scale_points=COV_SCALE_POINTS / DIM,\n",
    "                    task=TASK,\n",
    "                )\n",
    "                X = X.to(device)\n",
    "                y = y.to(device)\n",
    "                pm = pm.to(device)\n",
    "\n",
    "                model_results = embedders.benchmarks.benchmark(\n",
    "                    X,\n",
    "                    y,\n",
    "                    pm,\n",
    "                    max_depth=MAX_DEPTH,\n",
    "                    task=TASK,\n",
    "                    score=SCORE,\n",
    "                    seed=seed,\n",
    "                    n_features=N_FEATURES,\n",
    "                    device=device,\n",
    "                    models=MODELS,\n",
    "                )\n",
    "\n",
    "                model_results[\"curvature\"] = K\n",
    "                model_results[\"seed\"] = seed\n",
    "\n",
    "                # Flatten the nested model results\n",
    "                for model, metrics in model_results.items():\n",
    "                    for metric, value in metrics.items():\n",
    "                        run_results[f\"{model}_{metric}\"] = value\n",
    "\n",
    "                results.append(run_results)\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}\")\n",
    "            my_tqdm.update(1)\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    results = pd.DataFrame(results)\n",
    "\n",
    "    results.to_csv(f\"embedders/data/results/{TASK}_nn_single_curvature.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple curvatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple curvatures\n",
    "\n",
    "# Signatures - using non-Gu approach for now\n",
    "SIGNATURES = [\n",
    "    [(-1, 2), (-1, 2)],  # HH\n",
    "    [(-1, 2), (0, 2)],  # HE\n",
    "    [(-1, 2), (1, 2)],  # HS\n",
    "    [(1, 2), (1, 2)],  # SS\n",
    "    [(1, 2), (0, 2)],  # SE\n",
    "    [(-1, 4)],  # H\n",
    "    [(0, 4)],  # E\n",
    "    [(1, 4)],  # S\n",
    "]\n",
    "\n",
    "SIGNATURES_STR = [\"HH\", \"HE\", \"HS\", \"SS\", \"SE\", \"H\", \"E\", \"S\"]\n",
    "\n",
    "DIM = 4\n",
    "N_POINTS = 1_000\n",
    "N_CLASSES = 8\n",
    "N_CLUSTERS = 32\n",
    "COV_SCALE_MEANS = 1.0\n",
    "COV_SCALE_POINTS = 1.0\n",
    "\n",
    "for TASK in [\"classification\", \"regression\"]:\n",
    "    results = []\n",
    "    SCORE = [\"f1-micro\", \"accuracy\"] if TASK == \"classification\" else [\"rmse\"]\n",
    "\n",
    "    my_tqdm = tqdm(total=len(SIGNATURES) * N_SAMPLES)\n",
    "    for i, (sig, sigstr) in enumerate(zip(SIGNATURES, SIGNATURES_STR)):\n",
    "        for seed in range(N_SAMPLES):\n",
    "            try:\n",
    "                # Ensure unique seed per trial\n",
    "                seed = seed + N_SAMPLES * i\n",
    "                pm = embedders.manifolds.ProductManifold(signature=sig, device=sample_device)\n",
    "\n",
    "                # Get X, y\n",
    "                X, y = embedders.gaussian_mixture.gaussian_mixture(\n",
    "                    pm=pm,\n",
    "                    seed=seed,\n",
    "                    num_points=N_POINTS,\n",
    "                    num_classes=N_CLASSES,\n",
    "                    num_clusters=N_CLUSTERS,\n",
    "                    cov_scale_means=COV_SCALE_MEANS / DIM,\n",
    "                    cov_scale_points=COV_SCALE_POINTS / DIM,\n",
    "                    task=TASK,\n",
    "                )\n",
    "                X = X.to(device)\n",
    "                y = y.to(device)\n",
    "                pm = pm.to(device)\n",
    "\n",
    "                if RESAMPLE_SCALES:\n",
    "                    scale = 0.5 - np.random.rand() * 20\n",
    "                    pm.P[0].scale = torch.exp(torch.tensor(scale)).item()\n",
    "                    pm.P[0].manifold._log_scale = torch.nn.Parameter(torch.tensor(scale))\n",
    "\n",
    "                # Benchmarks are now handled by the benchmark function\n",
    "                model_results = embedders.benchmarks.benchmark(\n",
    "                    X,\n",
    "                    y,\n",
    "                    pm,\n",
    "                    max_depth=MAX_DEPTH,\n",
    "                    task=TASK,\n",
    "                    score=SCORE,\n",
    "                    seed=seed,\n",
    "                    n_features=N_FEATURES,\n",
    "                    device=device,\n",
    "                )\n",
    "\n",
    "                # Create a flat dictionary for this run\n",
    "                run_results = {\"signature\": sigstr, \"seed\": seed}\n",
    "\n",
    "                # Flatten the nested model results\n",
    "                for model, metrics in model_results.items():\n",
    "                    for metric, value in metrics.items():\n",
    "                        run_results[f\"{model}_{metric}\"] = value\n",
    "\n",
    "                results.append(run_results)\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}\")\n",
    "            my_tqdm.update(1)\n",
    "\n",
    "    results = pd.DataFrame(results)\n",
    "\n",
    "    results.to_csv(f\"embedders/data/results/{TASK}_nn_multiple_curvatures.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph embeddings - known matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRAPHS = [\n",
    "    (\"citeseer\", \"HS\", [(-1, 2), (1, 2)], \"classification\"),\n",
    "    (\"cora\", \"H\", [(-1, 4)], \"classification\"),\n",
    "    (\"polblogs\", \"SS\", [(1, 2), (1, 2)], \"classification\"),\n",
    "    (\"cs_phds\", \"H\", [(-1, 4)], \"regression\"),\n",
    "]\n",
    "\n",
    "results = []\n",
    "my_tqdm = tqdm(total=len(GRAPHS) * N_SAMPLES)\n",
    "for embedding, sigstr, sig, task in GRAPHS:\n",
    "    _, y, adj = embedders.dataloaders.load(embedding)\n",
    "    adj = adj.to(device).float().detach()\n",
    "    pm = embedders.manifolds.ProductManifold(signature=sig, device=device)\n",
    "\n",
    "    for i in range(N_SAMPLES):\n",
    "        try:\n",
    "            X = torch.tensor(np.load(f\"embedders/data/graphs/embeddings/{embedding}/{sigstr}_{i}.npy\"), device=device)\n",
    "            score = [\"f1-micro\", \"accuracy\"] if task == \"classification\" else [\"rmse\"]\n",
    "\n",
    "            model_results = embedders.benchmarks.benchmark(\n",
    "                X,\n",
    "                y,\n",
    "                pm,\n",
    "                max_depth=MAX_DEPTH,\n",
    "                n_features=N_FEATURES,\n",
    "                seed=i,\n",
    "                device=device,\n",
    "                adj=adj,\n",
    "                models=MODELS,\n",
    "                task=task,\n",
    "                score=score,\n",
    "            )\n",
    "\n",
    "            # Create a flat dictionary for this run\n",
    "            run_results = {\"embedding\": embedding, \"seed\": i}\n",
    "\n",
    "            # Flatten the nested model results\n",
    "            for model, metrics in model_results.items():\n",
    "                for metric, value in metrics.items():\n",
    "                    run_results[f\"{model}_{metric}\"] = value\n",
    "\n",
    "            results.append(run_results)\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "        my_tqdm.update(1)\n",
    "\n",
    "results = pd.DataFrame(results)\n",
    "results.to_csv(f\"embedders/data/results/all_nn_graph.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import embedders\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "embeddings_names = [\n",
    "    \"blood_cell_scrna\",\n",
    "    \"lymphoma\",\n",
    "    \"cifar_100\",\n",
    "    \"mnist\",\n",
    "]\n",
    "sigs = [\n",
    "    [(1, 2), (0, 2), (-1, 2), (-1, 2), (-1, 2)],\n",
    "    [(1, 2), (1, 2)],\n",
    "    [(1, 2), (1, 2), (1, 2), (1, 2)],\n",
    "    [(1, 2), (0, 2), (-1, 2)],\n",
    "]\n",
    "sets = [\"train\", \"test\"]\n",
    "datasets = [\"X\", \"y\"]\n",
    "\n",
    "# bad = []\n",
    "# for embedding in embeddings_names:\n",
    "#     for trial in range(n_trials):\n",
    "#         for set_name in sets:\n",
    "#             for dataset in datasets:\n",
    "#                 my_data = np.load(f\"../data/{embedding}/embeddings/{dataset}_{set_name}_{trial}.npy\")\n",
    "#                 if np.isnan(my_data).any():\n",
    "#                     bad.append((embedding, trial, set_name, dataset))\n",
    "#                     print(embedding, trial, set_name, dataset)\n",
    "#                 # print(my_data.shape)\n",
    "# print(bad)\n",
    "\n",
    "results = []\n",
    "my_tqdm = tqdm(total=len(embeddings_names) * N_SAMPLES)\n",
    "for embedding, sig in zip(embeddings_names, sigs):\n",
    "    pm = embedders.manifolds.ProductManifold(signature=sig)\n",
    "    for trial in range(N_SAMPLES):\n",
    "        # try:\n",
    "        X_train = np.load(f\"embedders/data/{embedding}/embeddings/X_train_{trial}.npy\")\n",
    "        y_train = np.load(f\"embedders/data/{embedding}/embeddings/y_train_{trial}.npy\")\n",
    "        X_test = np.load(f\"embedders/data/{embedding}/embeddings/X_test_{trial}.npy\")\n",
    "        y_test = np.load(f\"embedders/data/{embedding}/embeddings/y_test_{trial}.npy\")\n",
    "\n",
    "        # Convert to torch tensors\n",
    "        X_train = torch.tensor(X_train, device=device)\n",
    "        y_train = torch.tensor(y_train, device=device)\n",
    "        X_test = torch.tensor(X_test, device=device)\n",
    "        y_test = torch.tensor(y_test, device=device)\n",
    "\n",
    "        # Randomly subsample\n",
    "        if len(X_train) > DOWNSAMPLE:\n",
    "            idx = np.random.choice(X_train.shape[0], DOWNSAMPLE, replace=False)\n",
    "            X_train = X_train[idx]\n",
    "            y_train = y_train[idx]\n",
    "\n",
    "        if len(X_test) > DOWNSAMPLE:\n",
    "            idx = np.random.choice(X_test.shape[0], DOWNSAMPLE, replace=False)\n",
    "            X_test = X_test[idx]\n",
    "            y_test = y_test[idx]\n",
    "\n",
    "        model_results = embedders.benchmarks.benchmark(\n",
    "            X=None,\n",
    "            y=None,\n",
    "            X_train=X_train,\n",
    "            X_test=X_test,\n",
    "            y_train=y_train,\n",
    "            y_test=y_test,\n",
    "            pm=pm,\n",
    "            # models=[\"sklearn_dt\", \"product_dt\"],\n",
    "            max_depth=MAX_DEPTH,\n",
    "            batch_size=1,\n",
    "            n_features=N_FEATURES,\n",
    "            models=MODELS,\n",
    "            task=\"classification\",\n",
    "            score=[\"f1-micro\", \"accuracy\"],\n",
    "            device=device,\n",
    "        )\n",
    "        # res[\"embedding\"] = embedding\n",
    "        # res[\"trial\"] = trial\n",
    "\n",
    "        # results.append(res)\n",
    "        # my_tqdm.update(1)\n",
    "\n",
    "        run_results = {\"embedding\": embedding, \"seed\": trial}\n",
    "\n",
    "        # Flatten the nested model results\n",
    "        for model, metrics in model_results.items():\n",
    "            for metric, value in metrics.items():\n",
    "                run_results[f\"{model}_{metric}\"] = value\n",
    "\n",
    "        results.append(run_results)\n",
    "        # except Exception as e:\n",
    "        # print(f\"Error: {e}\")\n",
    "        my_tqdm.update(1)\n",
    "\n",
    "results = pd.DataFrame(results)\n",
    "results.to_csv(f\"embedders/data/results/all_nn_vae.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Empirical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import embedders\n",
    "import pandas as pd\n",
    "\n",
    "N_SAMPLES = 10\n",
    "# N_SAMPLES = 1\n",
    "DEVICE = \"cuda\"\n",
    "DOWNSAMPLE = 1_000\n",
    "\n",
    "# my_tqdm = tqdm(total=5 * N_SAMPLES)\n",
    "my_tqdm = tqdm(total=5 * N_SAMPLES)\n",
    "\n",
    "results = []\n",
    "for dataset, signature, objective in zip(\n",
    "    [\"landmasses\", \"neuron_33\", \"neuron_46\", \"temperature\", \"traffic\"],\n",
    "    [[(1, 2)], [(1, 1)] * 10, [(1, 1)] * 10, [(1, 2), (1, 1)], [(0, 1)] + [(1, 1)] * 4],\n",
    "    [\"classification\", \"classification\", \"classification\", \"regression\", \"regression\"],\n",
    "):\n",
    "    score = [\"f1-micro\", \"accuracy\"] if objective == \"classification\" else [\"rmse\"]\n",
    "    pm = embedders.manifolds.ProductManifold(signature=signature, device=DEVICE)\n",
    "\n",
    "    for seed in range(N_SAMPLES):\n",
    "        # try:\n",
    "        X, y, _ = embedders.dataloaders.load(dataset, seed=seed)\n",
    "        # Resample\n",
    "        if len(X) > DOWNSAMPLE:\n",
    "            random_sample = np.random.choice(X.shape[0], DOWNSAMPLE, replace=False)\n",
    "            X = X[random_sample]\n",
    "            y = y[random_sample]\n",
    "        model_results = embedders.benchmarks.benchmark(\n",
    "            X=X,\n",
    "            y=y,\n",
    "            pm=pm,\n",
    "            # max_depth=MAX_DEPTH,\n",
    "            # n_features=N_FEATURES,\n",
    "            seed=seed,\n",
    "            # device=device,\n",
    "            # models=MODELS,\n",
    "            task=objective,\n",
    "            score=score,\n",
    "            device=DEVICE\n",
    "        )\n",
    "\n",
    "        # Create a flat dictionary for this run\n",
    "        # run_results = {\"dataset\": dataset, \"seed\": 0}\n",
    "        model_results[\"dataset\"] = dataset\n",
    "        model_results[\"seed\"] = seed\n",
    "\n",
    "        results.append(model_results)\n",
    "        print(results)\n",
    "        # except Exception as e:\n",
    "            # print(f\"Error: {e}\")\n",
    "        my_tqdm.update(1)\n",
    "\n",
    "results = pd.DataFrame(results)\n",
    "# results.to_csv(f\"../data/results_icml/all_nn_empirical.tsv\", sep=\"\\t\", index=False)\n",
    "results.to_csv(f\"../data/results_icml/all_nn_neurons.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.signature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Special function to split dataset while ensuring pairs are in the same split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def split_dataset(X, y, **kwargs):\n",
    "    n_pairs, n_dims = X.shape\n",
    "    n_nodes = int(n_pairs**0.5)\n",
    "\n",
    "    # Reshape\n",
    "    X_reshaped = X.view(n_nodes, n_nodes, -1)\n",
    "    y_reshaped = y.view(n_nodes, n_nodes)\n",
    "\n",
    "    # Take 20% Of the nodes as test nodes\n",
    "    idx = list(range(n_nodes))\n",
    "    idx_train, idx_test = train_test_split(idx, **kwargs)\n",
    "\n",
    "    # Return test and train sets\n",
    "    X_train = X_reshaped[idx_train][:, idx_train].reshape(-1, n_dims)\n",
    "    y_train = y_reshaped[idx_train][:, idx_train].reshape(-1)\n",
    "\n",
    "    X_test = X_reshaped[idx_test][:, idx_test].reshape(-1, n_dims)\n",
    "    y_test = y_reshaped[idx_test][:, idx_test].reshape(-1)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Karate club\n",
    "USE_DISTS = True\n",
    "SIGNATURE = [(1, 2), (0, 2), (-1, 2)]\n",
    "TOTAL_ITERATIONS = 1_000\n",
    "\n",
    "results = []\n",
    "my_tqdm = tqdm(total=N_SAMPLES * 6)\n",
    "\n",
    "for dataset in [\"adjnoun\", \"dolphins\", \"football\", \"karate_club\", \"lesmis\", \"polbooks\"]:\n",
    "    dists, labels, adj = embedders.dataloaders.load(dataset)\n",
    "    dists = dists / dists.max()\n",
    "\n",
    "    results_dataset = []\n",
    "    i = -1\n",
    "    while len(results_dataset) < N_SAMPLES:\n",
    "        i += 1\n",
    "        pm = embedders.manifolds.ProductManifold(signature=SIGNATURE)\n",
    "        try:\n",
    "            X_embed, losses = embedders.coordinate_learning.train_coords(\n",
    "                pm,\n",
    "                dists,\n",
    "                burn_in_iterations=int(0.1 * TOTAL_ITERATIONS),\n",
    "                training_iterations=int(0.9 * TOTAL_ITERATIONS),\n",
    "                scale_factor_learning_rate=0.02,\n",
    "            )\n",
    "            assert not torch.isnan(X_embed).any()\n",
    "\n",
    "            X, y, pm_new = embedders.link_prediction.make_link_prediction_dataset(X_embed, pm, adj, add_dists=USE_DISTS)\n",
    "            X = X.to(device).detach()\n",
    "            y = y.to(device).detach()\n",
    "            X_train, X_test, y_train, y_test = split_dataset(X, y, test_size=0.2, random_state=i)\n",
    "            if len(X_train) > DOWNSAMPLE:\n",
    "                idx = np.random.choice(X_train.shape[0], DOWNSAMPLE, replace=False)\n",
    "                X_train = X_train[idx]\n",
    "                y_train = y_train[idx]\n",
    "            if len(X_test) > DOWNSAMPLE:\n",
    "                idx = np.random.choice(X_test.shape[0], DOWNSAMPLE, replace=False)\n",
    "                X_test = X_test[idx]\n",
    "                y_test = y_test[idx]\n",
    "\n",
    "            model_results = embedders.benchmarks.benchmark(\n",
    "                X=None,\n",
    "                y=None,\n",
    "                X_train=X_train,\n",
    "                X_test=X_test,\n",
    "                y_train=y_train,\n",
    "                y_test=y_test,\n",
    "                pm=pm_new,\n",
    "                max_depth=MAX_DEPTH,\n",
    "                task=\"classification\",\n",
    "                n_features=N_FEATURES,\n",
    "                models=MODELS,\n",
    "                device=device,\n",
    "            )\n",
    "            # model_results = embedders.benchmarks.benchmark(\n",
    "            #     X, y, pm_new, max_depth=MAX_DEPTH, task=\"classification\", score=[\"f1-micro\", \"accuracy\"], device=device, models=MODELS, n_features=N_FEATURES,\n",
    "            #     batch_size=1\n",
    "            # )\n",
    "            # Create a flat dictionary for this run\n",
    "            run_results = {\"dataset\": dataset, \"seed\": i}\n",
    "\n",
    "            # Flatten the nested model results\n",
    "            for model, metrics in model_results.items():\n",
    "                for metric, value in metrics.items():\n",
    "                    run_results[f\"{model}_{metric}\"] = value\n",
    "\n",
    "            results_dataset.append(run_results)\n",
    "\n",
    "        except ValueError as e:\n",
    "            print(e)\n",
    "\n",
    "        my_tqdm.update(1)\n",
    "\n",
    "    results.extend(results_dataset)\n",
    "\n",
    "\n",
    "# Print results\n",
    "results = pd.DataFrame(results)\n",
    "results.to_csv(f\"embedders/data/results/all_nn_link.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interrupt above code\n",
    "\n",
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_top_performances_markdown(df, metric=\"accuracy\", tolerance=0.01):\n",
    "    \"\"\"\n",
    "    Format DataFrame values with markdown bold and underline for best and second-best.\n",
    "    Returns a new DataFrame with markdown-formatted strings.\n",
    "\n",
    "    Args:\n",
    "        df: pandas DataFrame with mean ± std format strings\n",
    "        metric: 'accuracy' or 'rmse' to determine if higher or lower is better\n",
    "        tolerance: threshold for considering values equal\n",
    "    \"\"\"\n",
    "    # Create a copy to modify\n",
    "    formatted_df = df.copy()\n",
    "\n",
    "    # Extract mean values into a numeric DataFrame\n",
    "    means = df.apply(lambda x: pd.to_numeric(x.str.split(\"±\").str[0].str.strip()))\n",
    "\n",
    "    # Process each row\n",
    "    for idx in means.index:\n",
    "        row = means.loc[idx]\n",
    "\n",
    "        # Sort values and get indices based on metric\n",
    "        sorted_vals = row.sort_values(ascending=(metric == \"rmse\"))\n",
    "        best_val = sorted_vals.iloc[0]\n",
    "\n",
    "        # Find all values within tolerance of best\n",
    "        best_indices = row[abs(row - best_val) <= tolerance].index\n",
    "\n",
    "        if len(best_indices) > 1:\n",
    "            # Multiple bests - just bold them\n",
    "            for col in best_indices:\n",
    "                formatted_df.loc[idx, col] = f\"**{df.loc[idx, col]}**\"\n",
    "        else:\n",
    "            # One best - bold it and find second best\n",
    "            formatted_df.loc[idx, best_indices[0]] = f\"**{df.loc[idx, best_indices[0]]}**\"\n",
    "\n",
    "            # Find second best (first value not in best_indices)\n",
    "            for col in sorted_vals.index:\n",
    "                if col not in best_indices:\n",
    "                    formatted_df.loc[idx, col] = f\"_{df.loc[idx, col]}_\"\n",
    "                    break\n",
    "\n",
    "    return formatted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Summarize data\n",
    "# METRIC = \"rmse\"\n",
    "METRIC = \"accuracy\"\n",
    "\n",
    "\n",
    "def ci95_agg(vals):\n",
    "    return f\"{np.mean(vals):.2f} ± {1.96 * np.std(vals):.2f}\"\n",
    "\n",
    "\n",
    "for path, groupvar in zip(\n",
    "    [\n",
    "        # \"embedders/data/results/classification_nn_single_curvature.tsv\",\n",
    "        # \"embedders/data/results/classification_nn_multiple_curvatures.tsv\",\n",
    "        # \"embedders/data/results/regression_nn_single_curvature.tsv\",\n",
    "        # \"embedders/data/results/regression_nn_multiple_curvatures.tsv\",\n",
    "        # \"embedders/data/results/all_nn_graph.tsv\"\n",
    "        # \"embedders/data/results/all_nn_vae.tsv\"\n",
    "        \"../data/results/all_nn_empirical.tsv\"\n",
    "        # \"embedders/data/results/all_nn_link.tsv\"\n",
    "    ],\n",
    "    [\n",
    "        # \"curvature\",\n",
    "        # \"signature\",\n",
    "        # \"curvature\",\n",
    "        # \"signature\",\n",
    "        # \"embedding\"\n",
    "        # \"embedding\"\n",
    "        \"dataset\"\n",
    "        # \"dataset\"\n",
    "    ],\n",
    "):\n",
    "    results = pd.read_csv(path, sep=\"\\t\")\n",
    "    cols = [\n",
    "        f\"{model}_{METRIC}\"\n",
    "        for model in [\"product_dt\", \"product_rf\", \"tangent_mlp\", \"ambient_mlp\", \"tangent_gnn\", \"ambient_gnn\"]\n",
    "    ]  # \"tangent_gnn_adj\", \"ambient_gnn_adj\"]]\n",
    "    tab = results.groupby(groupvar).agg(ci95_agg)[cols]\n",
    "    tab.columns = [\n",
    "        \"Product DT\",\n",
    "        \"Product RF\",\n",
    "        \"Tangent MLP\",\n",
    "        \"Ambient MLP\",\n",
    "        \"Tangent GNN\",\n",
    "        \"Ambient GNN\",\n",
    "    ]  # , \"Tangent GNN (Adj)\", \"Ambient GNN (Adj)\"]\n",
    "\n",
    "    # Bold the best column(s) for each row at .2f precision\n",
    "    # Note that these are strings currently with ±, so we need to split and convert to float\n",
    "    # Use markdown: **x** to bold and <u>x</u> to underline\n",
    "    # best = tab.apply(lambda x: np.array([float(val.split(\" ± \")[0]) for val in x.values])).idxmax(axis=1)\n",
    "    # tab = tab.applymap(lambda x: f\"**{x}**\" if x.split(\" ± \")[0] == tab.loc[best[x], x].split(\" ± \")[0] else x)\n",
    "    # second_best = tab.apply(lambda x: np.array([float(val.split(\" ± \")[0]) for val in x.values if val != tab.loc[best[x], x]]), axis=1).nlargest(2).index\n",
    "    # tab = tab.applymap(lambda x: f\"<u>{x}</u>\" if x.split(\" ± \")[0] == tab.loc[best[x], x].split(\" ± \")[0] else x)\n",
    "    # display(tab)\n",
    "    # print(tab.to_latex())\n",
    "    # print(tab.to_markdown())\n",
    "\n",
    "    # For graphs\n",
    "    # tab = tab.loc[[\"citeseer\", \"cora\", \"polblogs\"]]\n",
    "    # tab = tab.loc[[\"cs_phds\"]\n",
    "    # tab = tab.loc[[\"adjnoun\", \"dolphins\", \"football\", \"karate_club\", \"lesmis\", \"polbooks\"]]\n",
    "\n",
    "    # For empirical\n",
    "    tab = tab.loc[[\"landmasses\", \"neuron_33\", \"neuron_46\"]]\n",
    "    # tab = tab.loc[[\"temperature\", \"traffic\"]]\n",
    "\n",
    "    styled_tab = format_top_performances_markdown(tab, metric=METRIC)\n",
    "    # display(styled_tab)\n",
    "    print(styled_tab.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "styled_tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runtimes experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import embedders\n",
    "import pandas as pd\n",
    "\n",
    "device = \"cuda\"\n",
    "MAX_DEPTH = 3\n",
    "N_CLASSES = 8\n",
    "N_CLUSTERS = 32\n",
    "COV_SCALE_MEANS = 1.0\n",
    "COV_SCALE_POINTS = 1.0\n",
    "N_FEATURES = \"d_choose_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run\n",
    "\n",
    "sig = [(-1, 2), (1, 2)]\n",
    "pm = embedders.manifolds.ProductManifold(signature=sig)\n",
    "results = []\n",
    "\n",
    "for size in [8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096]:  # , 8192]:\n",
    "    X, y = embedders.gaussian_mixture.gaussian_mixture(\n",
    "        pm=pm,\n",
    "        seed=0,\n",
    "        num_points=size,\n",
    "        num_classes=8,\n",
    "        num_clusters=32,\n",
    "        cov_scale_means=1.0 / 2,\n",
    "        cov_scale_points=1.0 / 2,\n",
    "        task=\"classification\",\n",
    "    )\n",
    "    X = X.to(device)\n",
    "    y = y.to(device)\n",
    "    pm = pm.to(device)\n",
    "\n",
    "    model_results = embedders.benchmarks.benchmark(\n",
    "        X,\n",
    "        y,\n",
    "        pm,\n",
    "        max_depth=MAX_DEPTH,\n",
    "        task=\"classification\",\n",
    "        score=[\"f1-micro\", \"accuracy\"],\n",
    "        seed=0,\n",
    "        n_features=N_FEATURES,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    # Create a flat dictionary for this run\n",
    "    run_results = {\"size\": size}\n",
    "\n",
    "    # Flatten the nested model results\n",
    "    for model, metrics in model_results.items():\n",
    "        for metric, value in metrics.items():\n",
    "            run_results[f\"{model}_{metric}\"] = value\n",
    "\n",
    "    results.append(run_results)\n",
    "\n",
    "results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set font to LaTeX times font\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "plt.rcParams[\"font.serif\"] = [\"Times New Roman\"] + plt.rcParams[\"font.serif\"]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Plot the bars using pandas plotting\n",
    "timecols = [c for c in results.columns if \"time\" in c]\n",
    "\n",
    "# Sort timecols by max time\n",
    "timecols = sorted(timecols, key=lambda c: results[c].max())\n",
    "\n",
    "# Remove tangent mlp and tangent gnn\n",
    "timecols = [c for c in timecols if \"tangent\" not in c]\n",
    "\n",
    "colors = plt.cm.turbo(np.linspace(0, 1, len(timecols)))\n",
    "\n",
    "# Plot each line\n",
    "lines = []\n",
    "for col, color in zip(timecols, colors):\n",
    "    line = plt.plot(results[\"size\"], results[col], label=col, color=color, linewidth=2, marker=\"o\", markersize=4)[0]\n",
    "    lines.append(line)\n",
    "\n",
    "# Set scales\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel(\"Dataset Size\")\n",
    "plt.ylabel(\"Runtime (s)\")\n",
    "plt.title(\"Runtime vs. Dataset Size\")\n",
    "\n",
    "# Add right-aligned labels\n",
    "xmax = results[\"size\"].max()\n",
    "for line, color, label, offset in zip(\n",
    "    lines,\n",
    "    colors,\n",
    "    [\"GNN\", \"Product RF\", \"MLP\", \"$k$-NN\", \"Product DT\", \"RF\", \"Perceptron\", \"DT\"][::-1],\n",
    "    # [1., 1., 1., 1.4, 1.2, 1., 0.75, 1.][::-1]\n",
    "    [1.0, 1.0, 1.4, 1.2, 1.0, 0.6, 1.0, 1.0][::-1],\n",
    "):\n",
    "    # Get the last y-value for this line\n",
    "    y = line.get_ydata()[-1] * offset\n",
    "    # Add text label\n",
    "    plt.text(xmax * 1.25, y, label, verticalalignment=\"center\", fontsize=10, color=color, fontweight=\"bold\")\n",
    "\n",
    "# Extend x-axis to make room for labels\n",
    "plt.xlim(results[\"size\"].min() * 0.9, xmax * 1.2)\n",
    "\n",
    "# Tight layout to prevent label cutoff\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"embedders/figures/runtime_vs_size.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Troubleshoot regression\n",
    "\n",
    "My regressions don't seem very good. For instance, the CS-PhDs dataset shows an RMSE of 1975 or whatever. How can I fix this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import embedders\n",
    "import numpy as np\n",
    "import torch \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "device=\"cpu\"\n",
    "\n",
    "# Load CS-PhDs\n",
    "_, y, adj = embedders.dataloaders.load(\"cs_phds\")\n",
    "\n",
    "# Get embeddings\n",
    "    # (\"cs_phds\", \"H\", [(-1, 4)], \"regression\"\n",
    "\n",
    "X = torch.tensor(np.load(\"embedders/data/graphs/embeddings/cs_phds/H_0.npy\"), device=device)\n",
    "\n",
    "pm = embedders.manifolds.ProductManifold(signature=[(-1, 4)], device=device)\n",
    "mlp = embedders.predictors.mlp.MLP(pm=pm, input_dim=5, hidden_dims=[128, 128], output_dim=1, task=\"regression\")\n",
    "mlp = mlp.to(device)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "mlp.fit(X_train, y_train, epochs=1_000)\n",
    "\n",
    "y_pred = mlp.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "rmse # Ok at 62.6 I'm satisfied with my hyperparameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embedders2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
