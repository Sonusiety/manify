{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import embedders\n",
    "\n",
    "DEVICE = torch.device(\"cuda\", 1) # Use the 2nd GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top CC has 34 nodes; original graph has 34 nodes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fd84516d81e4e66a08fa50a5bf5f361",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get some embeddings to work with\n",
    "\n",
    "# Get graph\n",
    "D, _, adj = embedders.dataloaders.load(\"karate_club\")\n",
    "D, adj = D.to(DEVICE), adj.to(DEVICE)\n",
    "pm = embedders.manifolds.ProductManifold(\n",
    "    signature=[(-1, 2), (0, 2), (1, 2)], device=DEVICE\n",
    ")\n",
    "\n",
    "# Get embeddings\n",
    "X, _ = embedders.coordinate_learning.train_coords(\n",
    "    pm=pm, dists=D, device=DEVICE, burn_in_iterations=400, training_iterations=1600\n",
    ")\n",
    "\n",
    "# Get stereographic version\n",
    "pm_stereo, X_stereo = pm.stereographic(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get an adjacency matrix that's not leaky\n",
    "dists = pm.pdist2(X)\n",
    "max_dist = dists[dists.isfinite()].max()\n",
    "dists /= max_dist\n",
    "A = torch.exp(-dists)\n",
    "A_hat = embedders.predictors.kappa_gcn.get_A_hat(A).float().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "923403dd631542d6b678c266ab2ed484",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.8405, device='cuda:1')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Train a KappaGCN on everything\n",
    "kgcn = embedders.predictors.kappa_gcn.KappaGCN(\n",
    "    pm=pm_stereo, output_dim=1, hidden_dims=[pm.dim, pm.dim], task=\"link_prediction\"\n",
    ").to(DEVICE)\n",
    "\n",
    "# Split on indices, since this is a weird graph thing\n",
    "y = adj.float().flatten()\n",
    "train_idx, test_idx = train_test_split(list(range(len(y))), test_size=0.2)\n",
    "\n",
    "# Fit on train indices using all X, but only some of the y - this masks out certain edges from the loss\n",
    "kgcn.fit(X, y=y[train_idx], A=A_hat, lr=1e-2, lp_indices=train_idx, use_tqdm=True, epochs=100)\n",
    "\n",
    "# Predict on test indices\n",
    "y_pred = kgcn.predict(X, A_hat)[test_idx]\n",
    "\n",
    "(y_pred == y[test_idx]).float().mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied from notebook 22\n",
    "\n",
    "def make_link_prediction_dataset(X_embed, pm, adj, add_dists=True):\n",
    "    # Stack embeddings\n",
    "    emb = []\n",
    "    for i in range(len(X_embed)):\n",
    "        for j in range(len(X_embed)):\n",
    "            joint_embed = torch.cat([X_embed[i], X_embed[j]])\n",
    "            emb.append(joint_embed)\n",
    "\n",
    "    X = torch.stack(emb)\n",
    "\n",
    "    # Add distances\n",
    "    if add_dists:\n",
    "        dists = pm.pdist(X_embed)\n",
    "        X = torch.cat([X, dists.flatten().unsqueeze(1)], dim=1)\n",
    "\n",
    "    # y = torch.tensor(adj.flatten())\n",
    "    if not torch.is_tensor(adj):\n",
    "        adj = torch.tensor(adj)\n",
    "    y = adj.flatten()\n",
    "\n",
    "    # Make a new signature\n",
    "    new_sig = pm.signature + pm.signature\n",
    "    if add_dists:\n",
    "        new_sig.append((0, 1))\n",
    "    new_pm = embedders.manifolds.ProductManifold(signature=new_sig)\n",
    "\n",
    "    return X, y, new_pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "437dca4159cd4513a3eeadddf110a21a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top CC has 62 nodes; original graph has 62 nodes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "467dc14e2b654c7aa5770c095b14c45c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c6e0925036549edb4be8b67a8cfcbe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a660daba08954fe1b88a7b2925c1e6aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c00eca9d175c492893b09588d24517ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "201b9d8e1bbf452598316b1f0e987422",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb22fd9bf5dd4e9bb68f542e0157cd7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a79e840852724768ab7ca18081234b0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a11cba6f7376477fafeabb22045beb0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b30a0398e7214bb3aaab878f7b5774dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "\n",
    "DATASETS = [\"dolphins\", \"football\", \"karate_club\", \"lesmis\", \"polbooks\"]#, \"adjnoun\"]\n",
    "SIGNATURE = [(-1, 2), (0, 2), (1, 2)]\n",
    "N_TRIALS = 10\n",
    "TOTAL_ITERATIONS = 1_000\n",
    "USE_DISTS = True\n",
    "USE_TQDM = True\n",
    "MODELS = [\n",
    "    \"sklearn_dt\",\n",
    "    \"sklearn_rf\",\n",
    "    \"product_dt\",\n",
    "    \"product_rf\",\n",
    "    \"tangent_dt\",\n",
    "    \"tangent_rf\",\n",
    "    \"knn\",\n",
    "    \"ps_perceptron\",\n",
    "    \"ambient_mlp\",\n",
    "    # \"ambient_gnn\",\n",
    "    # \"kappa_gcn\",\n",
    "    # \"product_mlr\",\n",
    "]\n",
    "LR = 1e-4\n",
    "EPOCHS = 4_000\n",
    "\n",
    "results = []\n",
    "\n",
    "# for dataset in [\"karate_club\"]:\n",
    "my_tqdm = tqdm(total=N_TRIALS * len(DATASETS))\n",
    "for i, dataset in enumerate(DATASETS):\n",
    "    dists, _, adj = embedders.dataloaders.load(dataset)\n",
    "    dists, adj = dists.to(DEVICE), adj.to(DEVICE)\n",
    "    dists = dists / dists[dists.isfinite()].max()\n",
    "\n",
    "    # while len(results) < N_TRIALS:\n",
    "    for seed in range(N_TRIALS):\n",
    "        seed = seed + i * N_TRIALS # Unique\n",
    "        pm = embedders.manifolds.ProductManifold(signature=SIGNATURE, device=DEVICE)\n",
    "        X, _ = embedders.coordinate_learning.train_coords(\n",
    "            pm=pm,\n",
    "            dists=dists,\n",
    "            burn_in_iterations=int(0.1 * TOTAL_ITERATIONS),\n",
    "            training_iterations=int(0.9 * TOTAL_ITERATIONS),\n",
    "            scale_factor_learning_rate=0.02,\n",
    "            device=DEVICE,\n",
    "        )\n",
    "        assert not torch.isnan(X).any()\n",
    "\n",
    "        # Get data for classification variants\n",
    "        XX, yy, pm_new = make_link_prediction_dataset(X, pm, adj, add_dists=USE_DISTS)\n",
    "        X_train, X_test, y_train, y_test, idx_train, idx_test = train_test_split(\n",
    "            XX, yy, list(range(len(yy))), test_size=0.2\n",
    "        )\n",
    "        res = embedders.benchmarks.benchmark(\n",
    "            XX, yy, pm_new, task=\"classification\", score=[\"accuracy\", \"f1-micro\"], device=DEVICE, models=MODELS, seed=seed\n",
    "        )\n",
    "\n",
    "        # Other manifolds we'll need\n",
    "        pm_stereo, X_stereo = pm.stereographic(X)\n",
    "        pm_stereo_euc = embedders.manifolds.ProductManifold(\n",
    "            signature=[(0, X.shape[1])], stereographic=True, device=DEVICE\n",
    "        )\n",
    "\n",
    "        # Get an adjacency matrix that's not leaky\n",
    "        dists = pm.pdist2(X)\n",
    "        max_dist = dists[dists.isfinite()].max()\n",
    "        dists /= max_dist\n",
    "        A = torch.exp(-dists)\n",
    "        A_hat = embedders.predictors.kappa_gcn.get_A_hat(A).float().to(DEVICE)\n",
    "\n",
    "        # Ambient GNN\n",
    "        agnn = embedders.predictors.kappa_gcn.KappaGCN(\n",
    "            pm=pm_stereo_euc, output_dim=1, hidden_dims=[pm_stereo_euc.dim], task=\"link_prediction\"\n",
    "        ).to(DEVICE)\n",
    "        t1 = time.time()\n",
    "        agnn.fit(X=X, y=y_train, A=A_hat, lr=LR, epochs=EPOCHS, lp_indices=idx_train, use_tqdm=USE_TQDM)\n",
    "        t2 = time.time()\n",
    "        y_pred = agnn.predict(X, A_hat)[idx_test]\n",
    "        res[\"ambient_gnn_accuracy\"] = (y_pred == y_test).float().mean().item()\n",
    "        res[\"ambient_gnn_f1_micro\"] = f1_score(y_test.cpu(), y_pred.cpu(), average=\"micro\")\n",
    "        res[\"ambient_gnn_time\"] = t2 - t1\n",
    "\n",
    "        # Kappa GCN\n",
    "        kgcn = embedders.predictors.kappa_gcn.KappaGCN(\n",
    "            pm=pm_stereo, output_dim=1, hidden_dims=[pm_stereo.dim], task=\"link_prediction\"\n",
    "        ).to(DEVICE)\n",
    "        t1 = time.time()\n",
    "        kgcn.fit(X=X_stereo, y=y_train, A=A_hat, lr=LR, epochs=EPOCHS, lp_indices=idx_train, use_tqdm=USE_TQDM)\n",
    "        t2 = time.time()\n",
    "        y_pred = kgcn.predict(X_stereo, A_hat)[idx_test]\n",
    "        res[\"kappa_gcn_accuracy\"] = (y_pred == y_test).float().mean().item()\n",
    "        res[\"kappa_gcn_f1_micro\"] = f1_score(y_test.cpu(), y_pred.cpu(), average=\"micro\")\n",
    "        res[\"kappa_gcn_time\"] = t2 - t1\n",
    "\n",
    "        # Product MLR\n",
    "        mlr = embedders.predictors.kappa_gcn.KappaGCN(\n",
    "            pm=pm_stereo, output_dim=1, hidden_dims=[], task=\"link_prediction\"\n",
    "        ).to(DEVICE)\n",
    "        t1 = time.time()\n",
    "        kgcn.fit(X=X_stereo, y=y_train, A=A_hat, lr=LR, epochs=EPOCHS, lp_indices=idx_train, use_tqdm=USE_TQDM)\n",
    "        t2 = time.time()\n",
    "        y_pred = kgcn.predict(X_stereo, A_hat)[idx_test]\n",
    "        res[\"product_mlr_accuracy\"] = (y_pred == y_test).float().mean().item()\n",
    "        res[\"product_mlr_f1_micro\"] = f1_score(y_test.cpu(), y_pred.cpu(), average=\"micro\")\n",
    "        res[\"product_mlr_time\"] = t2 - t1\n",
    "\n",
    "        # Other details\n",
    "        res[\"d_avg\"] = embedders.metrics.d_avg(pm.pdist(X), dists).item()\n",
    "        res[\"dataset\"] = dataset\n",
    "\n",
    "        results.append(res)\n",
    "        my_tqdm.update(1)\n",
    "        # except Exception as e:\n",
    "        #     print(e)\n",
    "        #     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"../data/results_icml/link_prediction.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "\n",
    "# DATASETS = [\"dolphins\", \"football\", \"karate_club\", \"lesmis\", \"polbooks\"]#, \"adjnoun\"]\n",
    "DATASETS = [\"adjnoun\"]\n",
    "SIGNATURE = [(-1, 2), (0, 2), (1, 2)]\n",
    "N_TRIALS = 10\n",
    "TOTAL_ITERATIONS = 1_000\n",
    "USE_DISTS = True\n",
    "USE_TQDM = True\n",
    "MODELS = [\n",
    "    \"sklearn_dt\",\n",
    "    \"sklearn_rf\",\n",
    "    \"product_dt\",\n",
    "    \"product_rf\",\n",
    "    \"tangent_dt\",\n",
    "    \"tangent_rf\",\n",
    "    \"knn\",\n",
    "    \"ps_perceptron\",\n",
    "    \"ambient_mlp\",\n",
    "    # \"ambient_gnn\",\n",
    "    # \"kappa_gcn\",\n",
    "    # \"product_mlr\",\n",
    "]\n",
    "LR = 1e-4\n",
    "EPOCHS = 4_000\n",
    "\n",
    "results2 = []\n",
    "\n",
    "# for dataset in [\"karate_club\"]:\n",
    "my_tqdm = tqdm(total=N_TRIALS * len(DATASETS))\n",
    "for dataset in DATASETS:\n",
    "    dists, _, adj = embedders.dataloaders.load(dataset)\n",
    "    dists, adj = dists.to(DEVICE), adj.to(DEVICE)\n",
    "    dists = dists / dists[dists.isfinite()].max()\n",
    "\n",
    "    while len(results) < N_TRIALS:\n",
    "        pm = embedders.manifolds.ProductManifold(signature=SIGNATURE, device=DEVICE)\n",
    "        X, _ = embedders.coordinate_learning.train_coords(\n",
    "            pm=pm,\n",
    "            dists=dists,\n",
    "            burn_in_iterations=int(0.1 * TOTAL_ITERATIONS),\n",
    "            training_iterations=int(0.9 * TOTAL_ITERATIONS),\n",
    "            scale_factor_learning_rate=0.02,\n",
    "            device=DEVICE,\n",
    "        )\n",
    "        assert not torch.isnan(X).any()\n",
    "\n",
    "        # Get data for classification variants\n",
    "        XX, yy, pm_new = make_link_prediction_dataset(X, pm, adj, add_dists=USE_DISTS)\n",
    "        X_train, X_test, y_train, y_test, idx_train, idx_test = train_test_split(\n",
    "            XX, yy, list(range(len(yy))), test_size=0.2\n",
    "        )\n",
    "        res = embedders.benchmarks.benchmark(\n",
    "            XX, yy, pm_new, task=\"classification\", score=[\"accuracy\", \"f1-micro\"], device=DEVICE, models=MODELS, batch_size=1\n",
    "        )\n",
    "\n",
    "        # Other manifolds we'll need\n",
    "        pm_stereo, X_stereo = pm.stereographic(X)\n",
    "        pm_stereo_euc = embedders.manifolds.ProductManifold(\n",
    "            signature=[(0, X.shape[1])], stereographic=True, device=DEVICE\n",
    "        )\n",
    "\n",
    "        # Get an adjacency matrix that's not leaky\n",
    "        dists = pm.pdist2(X)\n",
    "        max_dist = dists[dists.isfinite()].max()\n",
    "        dists /= max_dist\n",
    "        A = torch.exp(-dists)\n",
    "        A_hat = embedders.predictors.kappa_gcn.get_A_hat(A).float().to(DEVICE)\n",
    "\n",
    "        # Ambient GNN\n",
    "        agnn = embedders.predictors.kappa_gcn.KappaGCN(\n",
    "            pm=pm_stereo_euc, output_dim=1, hidden_dims=[pm_stereo_euc.dim], task=\"link_prediction\"\n",
    "        ).to(DEVICE)\n",
    "        t1 = time.time()\n",
    "        agnn.fit(X=X, y=y_train, A=A_hat, lr=LR, epochs=EPOCHS, lp_indices=idx_train, use_tqdm=USE_TQDM)\n",
    "        t2 = time.time()\n",
    "        y_pred = agnn.predict(X, A_hat)[idx_test]\n",
    "        res[\"ambient_gnn_accuracy\"] = (y_pred == y_test).float().mean().item()\n",
    "        res[\"ambient_gnn_f1_micro\"] = f1_score(y_test.cpu(), y_pred.cpu(), average=\"micro\")\n",
    "        res[\"ambient_gnn_time\"] = t2 - t1\n",
    "\n",
    "        # Kappa GCN\n",
    "        kgcn = embedders.predictors.kappa_gcn.KappaGCN(\n",
    "            pm=pm_stereo, output_dim=1, hidden_dims=[pm_stereo.dim], task=\"link_prediction\"\n",
    "        ).to(DEVICE)\n",
    "        t1 = time.time()\n",
    "        kgcn.fit(X=X_stereo, y=y_train, A=A_hat, lr=LR, epochs=EPOCHS, lp_indices=idx_train, use_tqdm=USE_TQDM)\n",
    "        t2 = time.time()\n",
    "        y_pred = kgcn.predict(X_stereo, A_hat)[idx_test]\n",
    "        res[\"kappa_gcn_accuracy\"] = (y_pred == y_test).float().mean().item()\n",
    "        res[\"kappa_gcn_f1_micro\"] = f1_score(y_test.cpu(), y_pred.cpu(), average=\"micro\")\n",
    "        res[\"kappa_gcn_time\"] = t2 - t1\n",
    "\n",
    "        # Product MLR\n",
    "        mlr = embedders.predictors.kappa_gcn.KappaGCN(\n",
    "            pm=pm_stereo, output_dim=1, hidden_dims=[], task=\"link_prediction\"\n",
    "        ).to(DEVICE)\n",
    "        t1 = time.time()\n",
    "        kgcn.fit(X=X_stereo, y=y_train, A=A_hat, lr=LR, epochs=EPOCHS, lp_indices=idx_train, use_tqdm=USE_TQDM)\n",
    "        t2 = time.time()\n",
    "        y_pred = kgcn.predict(X_stereo, A_hat)[idx_test]\n",
    "        res[\"product_mlr_accuracy\"] = (y_pred == y_test).float().mean().item()\n",
    "        res[\"product_mlr_f1_micro\"] = f1_score(y_test.cpu(), y_pred.cpu(), average=\"micro\")\n",
    "        res[\"product_mlr_time\"] = t2 - t1\n",
    "\n",
    "        # Other details\n",
    "        res[\"d_avg\"] = embedders.metrics.d_avg(pm.pdist(X), dists).item()\n",
    "        results2.append(res)\n",
    "        my_tqdm.update(1)\n",
    "        # except Exception as e:\n",
    "        #     print(e)\n",
    "        #     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df2 = pd.DataFrame(results2)\n",
    "results_df2.to_csv(\"../data/results_icml/link_prediction_adjnoun.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embedders",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
