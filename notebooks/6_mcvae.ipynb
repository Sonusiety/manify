{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get mnist, I guess (not using Keras)\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "\n",
    "from embedders.manifolds import ProductManifold\n",
    "from embedders.vae import ProductSpaceVAE\n",
    "\n",
    "mnist = torchvision.datasets.MNIST(\"/teamspace/studios/this_studio/embedders/data/MNIST\", download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Torch device management\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(0)\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe67d895ea0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAbV0lEQVR4nO3df2zU9R3H8dfxoydKe6zU9tpRWPkhOIEuQ+gaEWF0lBqZKFnAHwkQhxGLWWVOU6Mgk6QbRkdkCMmmMBNBIRGYxLFgsSXOlgWEMDbXUVKlBFomG3elQEH62R+EmydF+Ja7vnvt85F8E3r3/fTefv16T7+94+pzzjkBANDBelgPAADonggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAw0ct6gK9rbW3V0aNHlZycLJ/PZz0OAMAj55yampqUlZWlHj2ufJ3T6QJ09OhRZWdnW48BALhO9fX1GjBgwBXv73QBSk5OlnRx8JSUFONpAABehcNhZWdnR57PryRuAVq5cqVeeuklNTQ0KDc3VytWrNC4ceOuuu7Sj91SUlIIEAAksKu9jBKXNyG88847WrhwoRYvXqxPPvlEubm5Kiws1PHjx+PxcACABBSXAL3yyiuaN2+e5s6dq+9+97tavXq1brzxRr3xxhvxeDgAQAKKeYDOnTunPXv2qKCg4P8P0qOHCgoKVFVVddn+LS0tCofDURsAoOuLeYC++OILXbhwQRkZGVG3Z2RkqKGh4bL9y8rKFAgEIhvvgAOA7sH8L6KWlpYqFApFtvr6euuRAAAdIObvgktLS1PPnj3V2NgYdXtjY6OCweBl+/v9fvn9/liPAQDo5GJ+BZSUlKQxY8aovLw8cltra6vKy8uVn58f64cDACSouPw9oIULF2r27Nm6/fbbNW7cOC1fvlzNzc2aO3duPB4OAJCA4hKgmTNn6t///rcWLVqkhoYGfe9739O2bdsue2MCAKD78jnnnPUQXxUOhxUIBBQKhfgkBABIQNf6PG7+LjgAQPdEgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJnpZDwB0Jo8//rjnNatWrfK8ZtGiRZ7XPPzww57XDBs2zPMaoKNwBQQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmODDSIHr5PP5PK9ZunSp5zUbNmzwvOZ3v/ud5zWSNHbsWM9r/H5/ux4L3RdXQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACT6MFPiKuXPndsjjvP76657X/Otf//K85q677vK8RpI+/fRTz2tuueWWdj0Wui+ugAAAJggQAMBEzAP0wgsvyOfzRW0jRoyI9cMAABJcXF4Duu222/TBBx/8/0F68VITACBaXMrQq1cvBYPBeHxrAEAXEZfXgA4ePKisrCwNHjxYDz30kA4fPnzFfVtaWhQOh6M2AEDXF/MA5eXlae3atdq2bZtWrVqluro63XnnnWpqampz/7KyMgUCgciWnZ0d65EAAJ1QzANUVFSkn/zkJxo9erQKCwv1/vvv6+TJk9qwYUOb+5eWlioUCkW2+vr6WI8EAOiE4v7ugH79+umWW25RbW1tm/f7/X75/f54jwEA6GTi/veATp06pUOHDikzMzPeDwUASCAxD9BTTz2lyspKffbZZ/r444913333qWfPnnrggQdi/VAAgAQW8x/BHTlyRA888IBOnDihm2++WePHj1d1dbVuvvnmWD8UACCB+ZxzznqIrwqHwwoEAgqFQkpJSbEeB4iLp59+2vOal19+OQ6TtO2ee+7xvGbLli1xmASJ6Fqfx/ksOACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADARNx/IR2Ay7344oue1/Tp08fzmqVLl3peI0k7duzwvObDDz/0vGbSpEme16Dr4AoIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJvg0bMCA3+/3vGbOnDme17T307BPnz7tec2ZM2fa9VjovrgCAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBM8GGkgIHly5d7XvPGG2/EfpAruPXWWz2vGT58eBwmQVfGFRAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIPI0WXtH379nat++1vf+t5TWVlpec1Z86c8bzmyy+/9LymvYYMGdIha9C9cQUEADBBgAAAJjwHaOfOnZo2bZqysrLk8/m0efPmqPudc1q0aJEyMzPVp08fFRQU6ODBg7GaFwDQRXgOUHNzs3Jzc7Vy5co271+2bJleffVVrV69Wrt27dJNN92kwsJCnT179rqHBQB0HZ7fhFBUVKSioqI273POafny5Xruued07733SpLefPNNZWRkaPPmzZo1a9b1TQsA6DJi+hpQXV2dGhoaVFBQELktEAgoLy9PVVVVba5paWlROByO2gAAXV9MA9TQ0CBJysjIiLo9IyMjct/XlZWVKRAIRLbs7OxYjgQA6KTM3wVXWlqqUCgU2err661HAgB0gJgGKBgMSpIaGxujbm9sbIzc93V+v18pKSlRGwCg64tpgHJychQMBlVeXh65LRwOa9euXcrPz4/lQwEAEpznd8GdOnVKtbW1ka/r6uq0b98+paamauDAgSopKdHSpUs1bNgw5eTk6Pnnn1dWVpamT58ey7kBAAnOc4B2796tSZMmRb5euHChJGn27Nlau3atnn76aTU3N+vRRx/VyZMnNX78eG3btk033HBD7KYGACQ8n3POWQ/xVeFwWIFAQKFQiNeD0G533XVXu9Z99NFHnte05z8hn8/neU1ycrLnNVu3bvW8RpL69+/vec2tt97arsdC13Otz+Pm74IDAHRPBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMOH51zEAsHHu3DnPa06cONGuxxo/fny71gFecAUEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJjwOeec9RBfFQ6HFQgEFAqFlJKSYj0OcFWPP/645zUNDQ2e12zevNnzmva65557PK/54x//GIdJkIiu9XmcKyAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwEQv6wGARPfaa695XtPc3Ox5zaxZszyvef/99z2vkaT//ve/ntf85z//8bwmNTXV8xp0HVwBAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAm+DBSwMBNN93keU1JSYnnNe39MNKPP/7Y85rq6mrPa+6++27Pa9B1cAUEADBBgAAAJjwHaOfOnZo2bZqysrLk8/m0efPmqPvnzJkjn88XtU2dOjVW8wIAugjPAWpublZubq5Wrlx5xX2mTp2qY8eORbb169df15AAgK7H85sQioqKVFRU9I37+P1+BYPBdg8FAOj64vIaUEVFhdLT0zV8+HDNnz9fJ06cuOK+LS0tCofDURsAoOuLeYCmTp2qN998U+Xl5fr1r3+tyspKFRUV6cKFC23uX1ZWpkAgENmys7NjPRIAoBOK+d8DmjVrVuTPo0aN0ujRozVkyBBVVFRo8uTJl+1fWlqqhQsXRr4Oh8NECAC6gbi/DXvw4MFKS0tTbW1tm/f7/X6lpKREbQCAri/uATpy5IhOnDihzMzMeD8UACCBeP4R3KlTp6KuZurq6rRv3z6lpqYqNTVVS5Ys0YwZMxQMBnXo0CE9/fTTGjp0qAoLC2M6OAAgsXkO0O7duzVp0qTI15dev5k9e7ZWrVql/fv36w9/+INOnjyprKwsTZkyRS+++KL8fn/spgYAJDzPAZo4caKcc1e8/89//vN1DQSgbbfffrv1CEBM8VlwAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMBHzX8mN7uPMmTOe15SUlHhe8/LLL3te07dvX89rOru//e1v1iMAMcUVEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABggg8jRbs+VFSSSktLPa/5/e9/73lNMBj0vObZZ5/1vEaS/H5/u9Z1hNWrV3fYY40bN87zmttvvz0Ok6Ar4woIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADDBh5FC5eXl7Vq3YsWKGE/StqVLl3pe86Mf/ahdjzV+/HjPa9r7wade7d+/v0MeR5J++tOfel6Tnp4eh0nQlXEFBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCY8DnnnPUQXxUOhxUIBBQKhZSSkmI9Trfw5ZdftmvdkSNHPK/58Y9/7HnN3//+d89r+vbt63mNJPXo4f3/yUKhkOc1Pp/P85qO9Nlnn3lek52dHftBkJCu9XmcKyAAgAkCBAAw4SlAZWVlGjt2rJKTk5Wenq7p06erpqYmap+zZ8+quLhY/fv3V9++fTVjxgw1NjbGdGgAQOLzFKDKykoVFxerurpa27dv1/nz5zVlyhQ1NzdH9nnyySf13nvvaePGjaqsrNTRo0d1//33x3xwAEBi8/QbUbdt2xb19dq1a5Wenq49e/ZowoQJCoVCev3117Vu3Tr98Ic/lCStWbNGt956q6qrq/WDH/wgdpMDABLadb0GdOndP6mpqZKkPXv26Pz58yooKIjsM2LECA0cOFBVVVVtfo+WlhaFw+GoDQDQ9bU7QK2trSopKdEdd9yhkSNHSpIaGhqUlJSkfv36Re2bkZGhhoaGNr9PWVmZAoFAZOOtnADQPbQ7QMXFxTpw4IDefvvt6xqgtLRUoVAostXX11/X9wMAJAZPrwFdsmDBAm3dulU7d+7UgAEDIrcHg0GdO3dOJ0+ejLoKamxsVDAYbPN7+f1++f3+9owBAEhgnq6AnHNasGCBNm3apB07dignJyfq/jFjxqh3794qLy+P3FZTU6PDhw8rPz8/NhMDALoET1dAxcXFWrdunbZs2aLk5OTI6zqBQEB9+vRRIBDQI488ooULFyo1NVUpKSl64oknlJ+fzzvgAABRPAVo1apVkqSJEydG3b5mzRrNmTNHkvSb3/xGPXr00IwZM9TS0qLCwkK99tprMRkWANB18GGk6FCff/655zWbNm3yvGbx4sWe10jSqVOnPK9pz39C7fkw0oEDB3peM3PmTM9rJGnJkiWe1/BaLi7hw0gBAJ0aAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATLTrN6IC7TVo0CDPa0pKSjyvSUpK8rxGkp544ol2rfNq2LBhntds3brV85qhQ4d6XgN0FK6AAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATPuecsx7iq8LhsAKBgEKhkFJSUqzHAQB4dK3P41wBAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACY8BaisrExjx45VcnKy0tPTNX36dNXU1ETtM3HiRPl8vqjtsccei+nQAIDE5ylAlZWVKi4uVnV1tbZv367z589rypQpam5ujtpv3rx5OnbsWGRbtmxZTIcGACS+Xl523rZtW9TXa9euVXp6uvbs2aMJEyZEbr/xxhsVDAZjMyEAoEu6rteAQqGQJCk1NTXq9rfeektpaWkaOXKkSktLdfr06St+j5aWFoXD4agNAND1eboC+qrW1laVlJTojjvu0MiRIyO3P/jggxo0aJCysrK0f/9+PfPMM6qpqdG7777b5vcpKyvTkiVL2jsGACBB+Zxzrj0L58+frz/96U/66KOPNGDAgCvut2PHDk2ePFm1tbUaMmTIZfe3tLSopaUl8nU4HFZ2drZCoZBSUlLaMxoAwFA4HFYgELjq83i7roAWLFigrVu3aufOnd8YH0nKy8uTpCsGyO/3y+/3t2cMAEAC8xQg55yeeOIJbdq0SRUVFcrJybnqmn379kmSMjMz2zUgAKBr8hSg4uJirVu3Tlu2bFFycrIaGhokSYFAQH369NGhQ4e0bt063X333erfv7/279+vJ598UhMmTNDo0aPj8g8AAEhMnl4D8vl8bd6+Zs0azZkzR/X19Xr44Yd14MABNTc3Kzs7W/fdd5+ee+65a34951p/dggA6Jzi8hrQ1VqVnZ2tyspKL98SANBN8VlwAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATvawH+DrnnCQpHA4bTwIAaI9Lz9+Xns+vpNMFqKmpSZKUnZ1tPAkA4Ho0NTUpEAhc8X6fu1qiOlhra6uOHj2q5ORk+Xy+qPvC4bCys7NVX1+vlJQUowntcRwu4jhcxHG4iONwUWc4Ds45NTU1KSsrSz16XPmVnk53BdSjRw8NGDDgG/dJSUnp1ifYJRyHizgOF3EcLuI4XGR9HL7pyucS3oQAADBBgAAAJhIqQH6/X4sXL5bf77cexRTH4SKOw0Uch4s4Dhcl0nHodG9CAAB0Dwl1BQQA6DoIEADABAECAJggQAAAEwkToJUrV+o73/mObrjhBuXl5emvf/2r9Ugd7oUXXpDP54vaRowYYT1W3O3cuVPTpk1TVlaWfD6fNm/eHHW/c06LFi1SZmam+vTpo4KCAh08eNBm2Di62nGYM2fOZefH1KlTbYaNk7KyMo0dO1bJyclKT0/X9OnTVVNTE7XP2bNnVVxcrP79+6tv376aMWOGGhsbjSaOj2s5DhMnTrzsfHjssceMJm5bQgTonXfe0cKFC7V48WJ98sknys3NVWFhoY4fP249Woe77bbbdOzYscj20UcfWY8Ud83NzcrNzdXKlSvbvH/ZsmV69dVXtXr1au3atUs33XSTCgsLdfbs2Q6eNL6udhwkaerUqVHnx/r16ztwwvirrKxUcXGxqqurtX37dp0/f15TpkxRc3NzZJ8nn3xS7733njZu3KjKykodPXpU999/v+HUsXctx0GS5s2bF3U+LFu2zGjiK3AJYNy4ca64uDjy9YULF1xWVpYrKysznKrjLV682OXm5lqPYUqS27RpU+Tr1tZWFwwG3UsvvRS57eTJk87v97v169cbTNgxvn4cnHNu9uzZ7t577zWZx8rx48edJFdZWemcu/jvvnfv3m7jxo2RfT799FMnyVVVVVmNGXdfPw7OOXfXXXe5n/3sZ3ZDXYNOfwV07tw57dmzRwUFBZHbevTooYKCAlVVVRlOZuPgwYPKysrS4MGD9dBDD+nw4cPWI5mqq6tTQ0ND1PkRCASUl5fXLc+PiooKpaena/jw4Zo/f75OnDhhPVJchUIhSVJqaqokac+ePTp//nzU+TBixAgNHDiwS58PXz8Ol7z11ltKS0vTyJEjVVpaqtOnT1uMd0Wd7sNIv+6LL77QhQsXlJGREXV7RkaG/vnPfxpNZSMvL09r167V8OHDdezYMS1ZskR33nmnDhw4oOTkZOvxTDQ0NEhSm+fHpfu6i6lTp+r+++9XTk6ODh06pGeffVZFRUWqqqpSz549rceLudbWVpWUlOiOO+7QyJEjJV08H5KSktSvX7+ofbvy+dDWcZCkBx98UIMGDVJWVpb279+vZ555RjU1NXr33XcNp43W6QOE/ysqKor8efTo0crLy9OgQYO0YcMGPfLII4aToTOYNWtW5M+jRo3S6NGjNWTIEFVUVGjy5MmGk8VHcXGxDhw40C1eB/0mVzoOjz76aOTPo0aNUmZmpiZPnqxDhw5pyJAhHT1mmzr9j+DS0tLUs2fPy97F0tjYqGAwaDRV59CvXz/dcsstqq2ttR7FzKVzgPPjcoMHD1ZaWlqXPD8WLFigrVu36sMPP4z69S3BYFDnzp3TyZMno/bvqufDlY5DW/Ly8iSpU50PnT5ASUlJGjNmjMrLyyO3tba2qry8XPn5+YaT2Tt16pQOHTqkzMxM61HM5OTkKBgMRp0f4XBYu3bt6vbnx5EjR3TixIkudX4457RgwQJt2rRJO3bsUE5OTtT9Y8aMUe/evaPOh5qaGh0+fLhLnQ9XOw5t2bdvnyR1rvPB+l0Q1+Ltt992fr/frV271v3jH/9wjz76qOvXr59raGiwHq1D/fznP3cVFRWurq7O/eUvf3EFBQUuLS3NHT9+3Hq0uGpqanJ79+51e/fudZLcK6+84vbu3es+//xz55xzv/rVr1y/fv3cli1b3P79+929997rcnJy3JkzZ4wnj61vOg5NTU3uqaeeclVVVa6urs598MEH7vvf/74bNmyYO3v2rPXoMTN//nwXCARcRUWFO3bsWGQ7ffp0ZJ/HHnvMDRw40O3YscPt3r3b5efnu/z8fMOpY+9qx6G2ttb98pe/dLt373Z1dXVuy5YtbvDgwW7ChAnGk0dLiAA559yKFSvcwIEDXVJSkhs3bpyrrq62HqnDzZw502VmZrqkpCT37W9/282cOdPV1tZajxV3H374oZN02TZ79mzn3MW3Yj///PMuIyPD+f1+N3nyZFdTU2M7dBx803E4ffq0mzJlirv55ptd79693aBBg9y8efO63P+ktfXPL8mtWbMmss+ZM2fc448/7r71rW+5G2+80d13333u2LFjdkPHwdWOw+HDh92ECRNcamqq8/v9bujQoe4Xv/iFC4VCtoN/Db+OAQBgotO/BgQA6JoIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABP/A1nU2LWSdxICAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(mnist.data[1234].detach().numpy(), cmap=\"gray_r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, pm):\n",
    "        super().__init__()\n",
    "        self.pm = pm\n",
    "        self.fc1 = torch.nn.Linear(28 * 28, 256)\n",
    "        self.fc3_z_mean = torch.nn.Linear(256, pm.dim)  # Use ambient dim\n",
    "        self.fc3_z_logvar = torch.nn.Linear(256, pm.dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        z_mean_tangent = self.fc3_z_mean(h1)\n",
    "        z_logvar = self.fc3_z_logvar(h1)\n",
    "\n",
    "        z_mean = pm.manifold.expmap(x=pm.mu0, u=z_mean_tangent @ pm.projection_matrix)\n",
    "\n",
    "        return z_mean, z_logvar\n",
    "\n",
    "\n",
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self, pm):\n",
    "        super().__init__()\n",
    "        self.pm = pm\n",
    "        self.fc1 = torch.nn.Linear(pm.ambient_dim, 256)\n",
    "        # self.fc2 = torch.nn.Linear(64, 256)\n",
    "        self.fc3 = torch.nn.Linear(256, 28 * 28)\n",
    "\n",
    "    def forward(self, z):\n",
    "        h1 = F.relu(self.fc1(z))\n",
    "        # h2 = F.relu(self.fc2(h1))\n",
    "        x_recon = torch.sigmoid(self.fc3(h1))\n",
    "\n",
    "        return x_recon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ProductManifold' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 14\u001b[0m\n\u001b[1;32m     10\u001b[0m CLIP_GRAD \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Manifold stuff\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# pm = ProductManifold([(-1, 2), (0, 2), (1, 2)])\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m pm \u001b[38;5;241m=\u001b[39m \u001b[43mProductManifold\u001b[49m(SIGNATURE)\n\u001b[1;32m     15\u001b[0m vae \u001b[38;5;241m=\u001b[39m ProductSpaceVAE(\n\u001b[1;32m     16\u001b[0m     product_manifold\u001b[38;5;241m=\u001b[39mpm, encoder\u001b[38;5;241m=\u001b[39mEncoder(pm), decoder\u001b[38;5;241m=\u001b[39mDecoder(pm), beta\u001b[38;5;241m=\u001b[39mBETA, n_samples\u001b[38;5;241m=\u001b[39mN_SAMPLES, device\u001b[38;5;241m=\u001b[39mdevice\n\u001b[1;32m     17\u001b[0m )\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Training stuff\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ProductManifold' is not defined"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "SIGNATURE = [(-1, 16), (0, 16), (1, 16)]\n",
    "BATCH_SIZE = 64\n",
    "N_EPOCHS = 5\n",
    "LR = 1e-5\n",
    "BETA = 0.1\n",
    "N_SAMPLES = 32\n",
    "CLIP_GRAD = False\n",
    "\n",
    "# Manifold stuff\n",
    "# pm = ProductManifold([(-1, 2), (0, 2), (1, 2)])\n",
    "pm = ProductManifold(SIGNATURE)\n",
    "vae = ProductSpaceVAE(\n",
    "    product_manifold=pm, encoder=Encoder(pm), decoder=Decoder(pm), beta=BETA, n_samples=N_SAMPLES, device=device\n",
    ")\n",
    "\n",
    "# Training stuff\n",
    "X_train = mnist.data.float().view(-1, 28 * 28) / 255.0\n",
    "opt = torch.optim.Adam(vae.parameters(), lr=LR)\n",
    "\n",
    "# Visualization stuff\n",
    "my_tqdm = tqdm(total=N_EPOCHS * len(X_train))\n",
    "\n",
    "# Device stuff\n",
    "vae = vae.to(device)\n",
    "X_train = X_train.to(device)\n",
    "pm = pm.to(device)\n",
    "\n",
    "\n",
    "# Gradient checking stuff\n",
    "def grads_ok(vae):\n",
    "    out = True\n",
    "    for name, param in vae.named_parameters():\n",
    "        if param.grad is not None:\n",
    "            if torch.isnan(param.grad).any():\n",
    "                print(f\"NaN gradient in {name}\")\n",
    "                out = False\n",
    "            if torch.isinf(param.grad).any():\n",
    "                print(f\"Inf gradient in {name}\")\n",
    "                out = False\n",
    "    return out\n",
    "\n",
    "\n",
    "L = torch.nn.MSELoss(reduction=\"none\")\n",
    "for epoch in range(N_EPOCHS):\n",
    "    # opt.param_groups[0][\"lr\"] = lr\n",
    "    for i in range(0, len(X_train), BATCH_SIZE):\n",
    "        x_batch = X_train[i : i + BATCH_SIZE]\n",
    "\n",
    "        elbo, ll, kl = vae.elbo(x_batch)\n",
    "        loss = -elbo\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient clipping\n",
    "        if CLIP_GRAD:\n",
    "            torch.nn.utils.clip_grad_norm_(vae.parameters(), 1.0)\n",
    "        if torch.isnan(loss):\n",
    "            print(f\"Loss is NaN at iteration {i}\")\n",
    "        elif torch.isinf(loss):\n",
    "            print(f\"Loss is inf at iteration {i}\")\n",
    "        elif grads_ok(vae):\n",
    "            opt.step()\n",
    "\n",
    "        # if i % 100 * BATCH_SIZE == 0:\n",
    "        #     z_mean, z_sigma = vae.encoder(x_batch)\n",
    "        #     my_tqdm.set_postfix({\"Example latent\": \", \".join([f\"{x:.2f}\" for x in z_mean[0]])})\n",
    "\n",
    "        my_tqdm.update(BATCH_SIZE)\n",
    "        my_tqdm.set_description(f\"Epoch {epoch}, loss: {loss.item():.1f}, ll: {ll.item():.1f}, kl: {kl.item():.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[3.5733e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
       "          1.0000e+00, 1.0000e+00],\n",
       "         [1.0000e+00, 5.3354e+02, 1.0000e+00,  ..., 1.0000e+00,\n",
       "          1.0000e+00, 1.0000e+00],\n",
       "         [1.0000e+00, 1.0000e+00, 1.9099e+00,  ..., 1.0000e+00,\n",
       "          1.0000e+00, 1.0000e+00],\n",
       "         ...,\n",
       "         [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 3.5696e+01,\n",
       "          1.0000e+00, 1.0000e+00],\n",
       "         [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
       "          1.1972e+00, 1.0000e+00],\n",
       "         [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
       "          1.0000e+00, 1.1346e+00]],\n",
       "\n",
       "        [[3.6516e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
       "          1.0000e+00, 1.0000e+00],\n",
       "         [1.0000e+00, 1.8000e+03, 1.0000e+00,  ..., 1.0000e+00,\n",
       "          1.0000e+00, 1.0000e+00],\n",
       "         [1.0000e+00, 1.0000e+00, 1.8901e+00,  ..., 1.0000e+00,\n",
       "          1.0000e+00, 1.0000e+00],\n",
       "         ...,\n",
       "         [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 6.7089e+01,\n",
       "          1.0000e+00, 1.0000e+00],\n",
       "         [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
       "          1.1476e+00, 1.0000e+00],\n",
       "         [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
       "          1.0000e+00, 1.1005e+00]],\n",
       "\n",
       "        [[3.5458e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
       "          1.0000e+00, 1.0000e+00],\n",
       "         [1.0000e+00, 2.8620e+07, 1.0000e+00,  ..., 1.0000e+00,\n",
       "          1.0000e+00, 1.0000e+00],\n",
       "         [1.0000e+00, 1.0000e+00, 1.7381e+00,  ..., 1.0000e+00,\n",
       "          1.0000e+00, 1.0000e+00],\n",
       "         ...,\n",
       "         [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.3188e+03,\n",
       "          1.0000e+00, 1.0000e+00],\n",
       "         [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
       "          1.0550e+00, 1.0000e+00],\n",
       "         [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
       "          1.0000e+00, 1.0374e+00]],\n",
       "\n",
       "        [[3.3601e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
       "          1.0000e+00, 1.0000e+00],\n",
       "         [1.0000e+00, 1.6601e+03, 1.0000e+00,  ..., 1.0000e+00,\n",
       "          1.0000e+00, 1.0000e+00],\n",
       "         [1.0000e+00, 1.0000e+00, 1.8228e+00,  ..., 1.0000e+00,\n",
       "          1.0000e+00, 1.0000e+00],\n",
       "         ...,\n",
       "         [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 4.2186e+01,\n",
       "          1.0000e+00, 1.0000e+00],\n",
       "         [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
       "          1.1595e+00, 1.0000e+00],\n",
       "         [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
       "          1.0000e+00, 1.1181e+00]],\n",
       "\n",
       "        [[3.2320e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
       "          1.0000e+00, 1.0000e+00],\n",
       "         [1.0000e+00, 5.5670e+01, 1.0000e+00,  ..., 1.0000e+00,\n",
       "          1.0000e+00, 1.0000e+00],\n",
       "         [1.0000e+00, 1.0000e+00, 1.9429e+00,  ..., 1.0000e+00,\n",
       "          1.0000e+00, 1.0000e+00],\n",
       "         ...,\n",
       "         [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.2027e+01,\n",
       "          1.0000e+00, 1.0000e+00],\n",
       "         [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
       "          1.3459e+00, 1.0000e+00],\n",
       "         [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
       "          1.0000e+00, 1.2470e+00]]], device='cuda:0', grad_fn=<ExpBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_logvar.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_x = torch.repeat_interleave(torch.Tensor([[1], [2], [3]]), dim=0, repeats=5)\n",
    "_x.view(-1, 5).mean(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
