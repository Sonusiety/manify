{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some installs we need\n",
    "# !pip install cvxpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import embedders\n",
    "\n",
    "from hyperdt.product_space_svm import mix_curv_svm\n",
    "from hyperdt.product_space_perceptron import mix_curv_perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabaghi code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quentin's code for signature conversion, slightly rewritten for the new class\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def get_signature_str(pm):\n",
    "    return \",\".join([f\"{M.type.lower()}{M.dim}\" for M in pm.P])\n",
    "\n",
    "\n",
    "def get_embed_data(pm, X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    return {\n",
    "        \"X_train\": X_train.detach().cpu().numpy(),\n",
    "        \"X_test\": X_test.detach().cpu().numpy(),\n",
    "        \"y_train\": y_train.detach().cpu().numpy(),\n",
    "        \"y_test\": y_test.detach().cpu().numpy(),\n",
    "        \"max_norm\": [M.manifold.inner(x, x).max().item() for M, x in zip(pm.P, pm.factorize(X))],\n",
    "        \"curv_value\": [abs(M.curvature) for M in pm.P],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedders part: generate data\n",
    "\n",
    "pm = embedders.manifolds.ProductManifold([(-1, 2), (0, 2), (1, 2)])\n",
    "X, y = embedders.gaussian_mixture.gaussian_mixture(pm)\n",
    "y_relabeled = y * 2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:00<00:00, 1350.90it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 1329.90it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 3786.86it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 4975.43it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 4964.47it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 6268.80it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 6444.50it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 9156.04it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 14060.22it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 9772.66it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 10330.03it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 9588.05it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 9091.81it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 13448.78it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 11560.53it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 12355.81it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 9422.09it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 10732.34it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 8133.88it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 13036.11it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 6936.86it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 10340.73it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 7368.11it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 9840.70it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 9959.41it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 8671.99it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 12715.98it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 13903.10it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 10216.58it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 11782.25it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 10307.19it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 13383.34it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 9438.45it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 12073.63it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 10153.06it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 7663.21it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 11009.72it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 9755.84it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 13723.08it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 11999.58it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 13016.59it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 12397.86it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 12515.59it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 13604.95it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 11215.50it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 10889.38it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 13515.79it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 12090.77it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 10124.29it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 9273.64it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 10837.89it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 9040.37it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 11369.91it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 13218.52it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 12807.92it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 7564.65it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 12673.67it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 13441.07it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 13314.46it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 13281.57it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 13440.43it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 13365.85it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 13480.93it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 13286.20it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 13386.01it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 13466.43it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 11916.31it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 12157.31it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 11980.90it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 10096.93it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 11104.05it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 13212.02it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 13171.51it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 13210.25it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 12905.70it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 9057.90it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 11466.94it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 12969.35it/s]\n",
      "100%|██████████| 800/800 [00:00<00:00, 11374.00it/s]\n",
      " 45%|████▌     | 361/800 [00:00<00:00, 12067.20it/s]\n",
      "100%|██████████| 200/200 [00:00<00:00, 323.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  1  1  1  1  1 -1  1 -1  1  1  1  1  1  1 -1  1  1  1  1  1 -1  1 -1\n",
      "  1  1  1 -1  1  1 -1 -1  1  1  1  1  1 -1 -1  1  1  1 -1  1  1  1  1  1\n",
      " -1  1  1  1  1  1 -1  1 -1  1  1  1  1 -1  1  1  1  1 -1  1  1 -1 -1  1\n",
      " -1  1  1 -1 -1 -1  1  1 -1  1 -1  1 -1  1  1 -1 -1  1  1 -1 -1 -1  1  1\n",
      "  1 -1  1  1  1  1  1  1  1  1  1  1 -1  1  1  1  1  1  1 -1 -1  1 -1  1\n",
      " -1  1  1 -1 -1  1  1  1 -1  1  1  1  1  1  1  1  1  1  1  1 -1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1 -1  1  1 -1 -1 -1  1  1 -1  1 -1  1  1  1\n",
      "  1  1  1  1  1  1  1  1 -1  1  1 -1  1 -1  1  1  1  1 -1  1 -1 -1  1  1\n",
      "  1  1  1  1  1  1  1 -1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mix_component = get_signature_str(pm)\n",
    "embed_data = get_embed_data(pm, X, y_relabeled)\n",
    "# Convert to (1, -1) labels:\n",
    "\n",
    "ps_perceptron = mix_curv_perceptron(\n",
    "    mix_component=mix_component,\n",
    "    embed_data=embed_data,\n",
    "    multiclass=False,  # for now, just do binary\n",
    "    max_round=10_000,\n",
    "    max_update=10_000,\n",
    ")\n",
    "y_pred = ps_perceptron.process_data()\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 0 1 1 0 1 0 0 1 1 0 0 1\n",
      " 0 0 0 1 0 0 1 1 1 0 0 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0\n",
      " 1 1 0 0 1 1 0 0 0 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 0 1\n",
      " 1 1 1 0 0 1 0 0 0 1 1 1 1 0 0 0 0 0 1 0 1 1 0 0 0 0 1 1 0 0 0 0 1 0 0 1 0\n",
      " 1 0 1 0 0 1 0 0 1 1 0 1 0 0 1 0 1 1 1 0 0 0 0 0 1 1 0 0 0 0 1 1 1 0 0 1 1\n",
      " 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "# What about multiclass?\n",
    "\n",
    "# Embedders part: generate data\n",
    "\n",
    "pm = embedders.manifolds.ProductManifold([(-1, 2), (0, 2), (1, 2)])\n",
    "X, y = embedders.gaussian_mixture.gaussian_mixture(pm, num_classes=2)\n",
    "\n",
    "mix_component = get_signature_str(pm)\n",
    "embed_data = get_embed_data(pm, X, y)\n",
    "# Convert to (1, -1) labels:\n",
    "\n",
    "ps_perceptron = mix_curv_perceptron(\n",
    "    mix_component=mix_component, embed_data=embed_data, multiclass=True, max_round=10_000, max_update=10_000\n",
    ")\n",
    "y_pred = ps_perceptron.process_data()\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1,\n",
       "       0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1,\n",
       "       1, 1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_data[\"y_test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ok, I'm not happy with how their code doesn't return predictions. Let's rewrite this a bit\n",
    "import numpy as np\n",
    "from hyperdt.platt import SigmoidTrain, SigmoidPredict\n",
    "\n",
    "\n",
    "def perceptron_predict(perceptron):\n",
    "    tmp_error_record = {0: 1}\n",
    "    test_probability = np.zeros((perceptron.n_test_samples, perceptron.n_class), dtype=float)\n",
    "    for class_val in perceptron.class_labels:\n",
    "        y_bin_train = np.array([1 if val == class_val else -1 for val in perceptron.y_train])\n",
    "\n",
    "        # Train part\n",
    "        decision_vals = [0] * perceptron.n_train_samples\n",
    "        for idx in range(perceptron.n_train_samples):\n",
    "            decision_vals[idx] = perceptron.mix_classifier_train(idx, tmp_error_record, y_bin_train)\n",
    "            tmp_ab = SigmoidTrain(deci=decision_vals, label=y_bin_train, prior1=None, prior0=None)\n",
    "\n",
    "        # Test part\n",
    "        for idx in range(perceptron.n_test_samples):\n",
    "            yn = perceptron.mix_classifier_test(idx, tmp_error_record, y_bin_train)\n",
    "            test_probability[idx, perceptron.class_labels.index(class_val)] = SigmoidPredict(deci=yn, AB=tmp_ab)\n",
    "\n",
    "    # Get predictions\n",
    "    return test_probability\n",
    "\n",
    "\n",
    "perceptron_predict(ps_perceptron).argmax(axis=1)\n",
    "\n",
    "# Now we start to see the issue: all predictions are 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 0 1 1 0 1 0 0 1 1 0 0 1\n",
      " 0 0 0 1 0 0 1 1 1 0 0 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0\n",
      " 1 1 0 0 1 1 0 0 0 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 0 1\n",
      " 1 1 1 0 0 1 0 0 0 1 1 1 1 0 0 0 0 0 1 0 1 1 0 0 0 0 1 1 0 0 0 0 1 0 0 1 0\n",
      " 1 0 1 0 0 1 0 0 1 1 0 1 0 0 1 0 1 1 1 0 0 0 0 0 1 1 0 0 0 0 1 1 1 0 0 1 1\n",
      " 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "ps_perceptron_more_epochs = mix_curv_perceptron(\n",
    "    mix_component=mix_component,\n",
    "    embed_data=embed_data,\n",
    "    multiclass=False,  # for now, just do binary\n",
    "    max_round=1,\n",
    "    max_update=100,\n",
    ")\n",
    "score = ps_perceptron.process_data()\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.64592858, 0.69015549],\n",
       "       [0.59545233, 0.64249456],\n",
       "       [0.20436469, 0.23874382],\n",
       "       [0.33006785, 0.37561037],\n",
       "       [0.3794162 , 0.42742353],\n",
       "       [0.75062549, 0.78610532],\n",
       "       [0.7002529 , 0.74042111],\n",
       "       [0.4437521 , 0.49342738],\n",
       "       [0.41373555, 0.46284661],\n",
       "       [0.62736935, 0.67273995],\n",
       "       [0.44408791, 0.49376741],\n",
       "       [0.63791642, 0.68265242],\n",
       "       [0.43520183, 0.48475409],\n",
       "       [0.31560773, 0.36022789],\n",
       "       [0.3059968 , 0.34995297],\n",
       "       [0.30616528, 0.35013345],\n",
       "       [0.84869997, 0.87259459],\n",
       "       [0.39698415, 0.44561819],\n",
       "       [0.62015168, 0.66593313],\n",
       "       [0.61513658, 0.66119225],\n",
       "       [0.46922468, 0.51909045],\n",
       "       [0.59065267, 0.63791363],\n",
       "       [0.80847747, 0.83750818],\n",
       "       [0.41215829, 0.46122943],\n",
       "       [0.51230572, 0.56190298],\n",
       "       [0.42210602, 0.47141173],\n",
       "       [0.57250984, 0.6205197 ],\n",
       "       [0.44227191, 0.49192803],\n",
       "       [0.34905478, 0.39566982],\n",
       "       [0.60352511, 0.65018009],\n",
       "       [0.51303721, 0.56262359],\n",
       "       [0.49612055, 0.54590483],\n",
       "       [0.58521898, 0.63271719],\n",
       "       [0.45644983, 0.50625286],\n",
       "       [0.4858998 , 0.53574896],\n",
       "       [0.37069322, 0.41834086],\n",
       "       [0.5267403 , 0.57608429],\n",
       "       [0.52869733, 0.57800074],\n",
       "       [0.59075698, 0.63801328],\n",
       "       [0.29724608, 0.34056208],\n",
       "       [0.6862542 , 0.72756851],\n",
       "       [0.33300824, 0.37872712],\n",
       "       [0.53433957, 0.58351771],\n",
       "       [0.65116602, 0.69504758],\n",
       "       [0.42167382, 0.4709702 ],\n",
       "       [0.38020996, 0.42824842],\n",
       "       [0.5527969 , 0.60147957],\n",
       "       [0.42196293, 0.47126557],\n",
       "       [0.48697577, 0.53682005],\n",
       "       [0.43067742, 0.48015247],\n",
       "       [0.40865349, 0.4576322 ],\n",
       "       [0.3109644 , 0.35526887],\n",
       "       [0.6199089 , 0.66570384],\n",
       "       [0.29064878, 0.33345957],\n",
       "       [0.47365821, 0.52353041],\n",
       "       [0.4940736 , 0.54387419],\n",
       "       [0.3377549 , 0.38375051],\n",
       "       [0.63427131, 0.67923121],\n",
       "       [0.43282714, 0.48233992],\n",
       "       [0.45743093, 0.50724112],\n",
       "       [0.32613355, 0.3714342 ],\n",
       "       [0.75466953, 0.78973516],\n",
       "       [0.32792481, 0.37333642],\n",
       "       [0.26887713, 0.309882  ],\n",
       "       [0.31952679, 0.36440601],\n",
       "       [0.57715129, 0.62498133],\n",
       "       [0.45448735, 0.50427491],\n",
       "       [0.40596896, 0.45487341],\n",
       "       [0.43347629, 0.48300009],\n",
       "       [0.20153814, 0.23558257],\n",
       "       [0.35390451, 0.40076847],\n",
       "       [0.32836515, 0.37380382],\n",
       "       [0.40543204, 0.45432128],\n",
       "       [0.37551723, 0.42336779],\n",
       "       [0.34687057, 0.39337019],\n",
       "       [0.4710857 , 0.52095512],\n",
       "       [0.37402082, 0.42180949],\n",
       "       [0.51741602, 0.5669329 ],\n",
       "       [0.59290282, 0.64006231],\n",
       "       [0.32414557, 0.36932142],\n",
       "       [0.28383381, 0.32610226],\n",
       "       [0.40736672, 0.45631021],\n",
       "       [0.45518799, 0.50498126],\n",
       "       [0.55812815, 0.60664343],\n",
       "       [0.55509841, 0.60371014],\n",
       "       [0.68359056, 0.72511513],\n",
       "       [0.38963521, 0.43802292],\n",
       "       [0.70505067, 0.74481024],\n",
       "       [0.56341787, 0.61175637],\n",
       "       [0.8398204 , 0.86489412],\n",
       "       [0.59594675, 0.64296595],\n",
       "       [0.35867907, 0.40577819],\n",
       "       [0.52758314, 0.57690984],\n",
       "       [0.54171358, 0.59070947],\n",
       "       [0.49715945, 0.54693483],\n",
       "       [0.50583428, 0.55551867],\n",
       "       [0.40172262, 0.45050348],\n",
       "       [0.56348082, 0.61181715],\n",
       "       [0.6849862 , 0.72640092],\n",
       "       [0.50947885, 0.55911619],\n",
       "       [0.54852915, 0.597338  ],\n",
       "       [0.30316871, 0.34692171],\n",
       "       [0.57585068, 0.62373193],\n",
       "       [0.46849889, 0.51836284],\n",
       "       [0.37767031, 0.42560824],\n",
       "       [0.49743541, 0.54720835],\n",
       "       [0.6962804 , 0.73678085],\n",
       "       [0.63425978, 0.67922039],\n",
       "       [0.48178379, 0.53164736],\n",
       "       [0.49055519, 0.54037993],\n",
       "       [0.4224169 , 0.47172928],\n",
       "       [0.67171645, 0.71414771],\n",
       "       [0.50795631, 0.55761394],\n",
       "       [0.34032258, 0.38646381],\n",
       "       [0.64494153, 0.68923241],\n",
       "       [0.37277324, 0.42050959],\n",
       "       [0.63069227, 0.67586731],\n",
       "       [0.57012362, 0.61822275],\n",
       "       [0.45042075, 0.50017129],\n",
       "       [0.25520763, 0.29496889],\n",
       "       [0.39908543, 0.44778574],\n",
       "       [0.65964905, 0.70295029],\n",
       "       [0.40387564, 0.4527201 ],\n",
       "       [0.33319812, 0.37892826],\n",
       "       [0.49482209, 0.54461691],\n",
       "       [0.21826695, 0.25423747],\n",
       "       [0.64612761, 0.69034157],\n",
       "       [0.41877487, 0.4680066 ],\n",
       "       [0.59807589, 0.64499493],\n",
       "       [0.62027706, 0.66605153],\n",
       "       [0.50737451, 0.55703966],\n",
       "       [0.49462101, 0.5444174 ],\n",
       "       [0.54285799, 0.59182371],\n",
       "       [0.5044317 , 0.55413281],\n",
       "       [0.49010833, 0.53993579],\n",
       "       [0.24719356, 0.286186  ],\n",
       "       [0.28694192, 0.3294603 ],\n",
       "       [0.55067635, 0.59942258],\n",
       "       [0.73652551, 0.77340583],\n",
       "       [0.29623022, 0.33946969],\n",
       "       [0.34014902, 0.38628049],\n",
       "       [0.27310789, 0.31448044],\n",
       "       [0.54815247, 0.59697212],\n",
       "       [0.55949128, 0.60796202],\n",
       "       [0.36550424, 0.41292254],\n",
       "       [0.42395906, 0.47330395],\n",
       "       [0.44697265, 0.49668653],\n",
       "       [0.65337776, 0.69711051],\n",
       "       [0.67766417, 0.71964752],\n",
       "       [0.65996323, 0.70324248],\n",
       "       [0.69220588, 0.73304135],\n",
       "       [0.25127511, 0.29066279],\n",
       "       [0.38952407, 0.43790787],\n",
       "       [0.52734893, 0.57668046],\n",
       "       [0.5682347 , 0.61640299],\n",
       "       [0.30232128, 0.3460127 ],\n",
       "       [0.67599109, 0.7181017 ],\n",
       "       [0.57843408, 0.62621299],\n",
       "       [0.52899879, 0.57829582],\n",
       "       [0.35416072, 0.40103755],\n",
       "       [0.3805869 , 0.42864004],\n",
       "       [0.55390604, 0.60255478],\n",
       "       [0.57701049, 0.62484611],\n",
       "       [0.60759184, 0.65404259],\n",
       "       [0.62021602, 0.66599389],\n",
       "       [0.608891  , 0.65527522],\n",
       "       [0.31713497, 0.36185689],\n",
       "       [0.59092884, 0.63817745],\n",
       "       [0.19670713, 0.23017073],\n",
       "       [0.33760621, 0.38359331],\n",
       "       [0.56613267, 0.61437631],\n",
       "       [0.27503417, 0.31657144],\n",
       "       [0.67313538, 0.71546093],\n",
       "       [0.70860479, 0.74805647],\n",
       "       [0.44243879, 0.49209712],\n",
       "       [0.31524336, 0.35983909],\n",
       "       [0.33438462, 0.38018476],\n",
       "       [0.40144396, 0.45021644],\n",
       "       [0.55178175, 0.60049506],\n",
       "       [0.69513067, 0.73572625],\n",
       "       [0.51209913, 0.56169943],\n",
       "       [0.36095518, 0.40816296],\n",
       "       [0.3720041 , 0.41970786],\n",
       "       [0.59761907, 0.64455974],\n",
       "       [0.65406709, 0.6977531 ],\n",
       "       [0.47131695, 0.52118673],\n",
       "       [0.5369015 , 0.58601869],\n",
       "       [0.48967363, 0.53950365],\n",
       "       [0.44647604, 0.49618425],\n",
       "       [0.63749491, 0.68225705],\n",
       "       [0.55631072, 0.60488428],\n",
       "       [0.47488442, 0.524757  ],\n",
       "       [0.28716927, 0.32970576],\n",
       "       [0.68872563, 0.72984261],\n",
       "       [0.59504204, 0.6421033 ],\n",
       "       [0.59093753, 0.63818575],\n",
       "       [0.31949111, 0.36436799],\n",
       "       [0.48742819, 0.53727028],\n",
       "       [0.2435962 , 0.28223394],\n",
       "       [0.23264484, 0.27016596]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron_predict(ps_perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 106/4568 [00:00<00:01, 2556.86it/s]\n",
      "100%|██████████| 1142/1142 [00:00<00:00, 1390.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1 -1  1 ...  1 -1  1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Can we force the perceptron to predict 0s?\n",
    "import torch\n",
    "\n",
    "X_0_bias = torch.cat([X[y == 0]] * 10 + [X], dim=0)\n",
    "y_0_bias = torch.cat([torch.zeros_like(y[y == 0])] * 10 + [y], dim=0)\n",
    "\n",
    "embed_data_0_bias = get_embed_data(pm, X_0_bias, y_0_bias)\n",
    "\n",
    "ps_perceptron_0_bias = mix_curv_perceptron(\n",
    "    mix_component=mix_component,\n",
    "    embed_data=embed_data_0_bias,\n",
    "    multiclass=False,  # for now, just do binary\n",
    "    max_round=1000,\n",
    "    max_update=100,\n",
    ")\n",
    "score = ps_perceptron_0_bias.process_data()\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mperceptron_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mps_perceptron_0_bias\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39margmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[40], line 15\u001b[0m, in \u001b[0;36mperceptron_predict\u001b[0;34m(perceptron)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(perceptron\u001b[38;5;241m.\u001b[39mn_train_samples):\n\u001b[1;32m     14\u001b[0m     decision_vals[idx] \u001b[38;5;241m=\u001b[39m perceptron\u001b[38;5;241m.\u001b[39mmix_classifier_train(idx, tmp_error_record, y_bin_train)\n\u001b[0;32m---> 15\u001b[0m     tmp_ab \u001b[38;5;241m=\u001b[39m \u001b[43mSigmoidTrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeci\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecision_vals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_bin_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprior1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprior0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Test part\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(perceptron\u001b[38;5;241m.\u001b[39mn_test_samples):\n",
      "File \u001b[0;32m~/hyperDT_with_submodules/src/hyperdt/platt.py:43\u001b[0m, in \u001b[0;36mSigmoidTrain\u001b[0;34m(deci, label, prior1, prior0)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(length):\n\u001b[1;32m     42\u001b[0m \t\u001b[38;5;28;01mif\u001b[39;00m label[i] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 43\u001b[0m \t\t\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhiTarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \t\u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     45\u001b[0m \t\tt\u001b[38;5;241m.\u001b[39mappend(loTarget)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "perceptron_predict(ps_perceptron_0_bias).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedders part: generate data\n",
    "import embedders\n",
    "\n",
    "pm = embedders.manifolds.ProductManifold([(-1, 2), (0, 2), (1, 2)])\n",
    "X, y = embedders.gaussian_mixture.gaussian_mixture(pm)\n",
    "y_relabeled = y * 2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training perceptron for class 0 vs. rest\n",
      "Converged for class 0 after 7 epochs (no improvement).\n",
      "tensor([[ 514.1910, -514.1910],\n",
      "        [ 150.3096, -150.3096],\n",
      "        [  95.0430,  -95.0430],\n",
      "        ...,\n",
      "        [ 229.6605, -229.6605],\n",
      "        [  31.0748,  -31.0748],\n",
      "        [  20.6654,  -20.6654]], grad_fn=<CopySlices>)\n",
      "tensor(0.9810)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "\n",
    "class ProductSpacePerceptron(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, pm, max_epochs=1000, patience=5):\n",
    "        self.pm = pm  # ProductManifold instance\n",
    "        self.max_epochs = max_epochs\n",
    "        self.patience = patience  # Number of consecutive epochs without improvement to consider convergence\n",
    "        self.classes_ = None\n",
    "        self.classifiers_ = {}  # Dictionary to store classifiers for one-vs-rest approach\n",
    "        self.R = []  # To store maximum radius for each hyperbolic manifold\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Identify unique classes for multiclass classification\n",
    "        self.classes_ = torch.unique(y).tolist()\n",
    "\n",
    "        # Compute maximum hyperbolic radii for each hyperbolic manifold\n",
    "        self.R = [0] * len(self.pm.P)\n",
    "        for i, (M, x) in enumerate(zip(self.pm.P, self.pm.factorize(X))):\n",
    "            if M.type == \"H\":\n",
    "                self.R[i] = torch.sqrt(\n",
    "                    torch.abs(M.manifold.inner(x, x).max())\n",
    "                ).item()  # Use absolute value for Minkowski norm\n",
    "\n",
    "        # Relabel y to -1 and 1 for binary classification per class\n",
    "        for class_label in self.classes_:\n",
    "            # Binary classification shortcut\n",
    "            if len(self.classes_) == 2 and class_label == self.classes_[1]:\n",
    "                self.classifiers_[class_label] = -1 * self.classifiers_[self.classes_[0]]\n",
    "\n",
    "            else:\n",
    "                print(f\"Training perceptron for class {class_label} vs. rest\")\n",
    "                binary_y = torch.where(y == class_label, 1, -1)  # One-vs-rest relabeling\n",
    "\n",
    "                # Initialize decision function g for this binary classifier\n",
    "                g = torch.zeros(X.shape[1], dtype=X.dtype, device=X.device)\n",
    "\n",
    "                n_epochs = 0\n",
    "                epochs_without_improvement = 0  # Track consecutive epochs without improvement\n",
    "                best_error_count = float(\"inf\")  # Best error count seen so far\n",
    "\n",
    "                while n_epochs < self.max_epochs:\n",
    "                    errors = 0\n",
    "                    for n in range(X.shape[0]):\n",
    "                        # Compute the decision function value for the current point\n",
    "                        decision_value = g @ X[n]\n",
    "\n",
    "                        # Check if the point is misclassified\n",
    "                        if torch.sign(decision_value) != binary_y[n]:\n",
    "                            # Calculate the kernel K(x, x_n) for the current point x_n\n",
    "                            K = torch.ones(X.shape[0], dtype=X.dtype, device=X.device)  # Start with the bias term\n",
    "\n",
    "                            for i, (M, x) in enumerate(zip(self.pm.P, self.pm.factorize(X))):\n",
    "                                # Compute kernel matrix between x[n:n+1] and all training points\n",
    "                                if M.type == \"E\":\n",
    "                                    K += M.scale * M.manifold.inner(x[n : n + 1], x)  # Kernel matrix for Euclidean\n",
    "                                elif M.type == \"S\":\n",
    "                                    K += M.scale * torch.asin(\n",
    "                                        torch.clamp(M.manifold.inner(x[n : n + 1], x), -1, 1)\n",
    "                                    )  # Kernel matrix for Spherical\n",
    "                                elif M.type == \"H\":\n",
    "                                    K += M.scale * torch.asin(\n",
    "                                        torch.clamp((self.R[i] ** -2) * M.manifold.inner(x[n : n + 1], x), -1, 1)\n",
    "                                    )  # Kernel matrix for Hyperbolic\n",
    "\n",
    "                            # Update decision function using the computed kernel\n",
    "                            g += binary_y[n] * X[n]  # Update with current point only\n",
    "                            errors += 1  # Track the number of errors in this epoch\n",
    "\n",
    "                    # Convergence check based on error improvement\n",
    "                    if errors < best_error_count:\n",
    "                        best_error_count = errors\n",
    "                        epochs_without_improvement = 0  # Reset the counter if we have an improvement\n",
    "                    else:\n",
    "                        epochs_without_improvement += 1\n",
    "\n",
    "                    if epochs_without_improvement >= self.patience:\n",
    "                        print(f\"Converged for class {class_label} after {n_epochs} epochs (no improvement).\")\n",
    "                        break\n",
    "\n",
    "                    n_epochs += 1\n",
    "\n",
    "                # Store the classifier (decision function) for the current class\n",
    "                self.classifiers_[class_label] = g\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Initialize matrix to store decision values for each class\n",
    "        decision_values = torch.zeros((X.shape[0], len(self.classes_)), dtype=X.dtype, device=X.device)\n",
    "\n",
    "        # Compute decision values for each classifier\n",
    "        for idx, class_label in enumerate(self.classes_):\n",
    "            g = self.classifiers_[class_label]\n",
    "            decision_values[:, idx] = X @ g\n",
    "\n",
    "        # Return the class with the highest decision value\n",
    "        print(decision_values)\n",
    "        argmax_idx = torch.argmax(decision_values, dim=1)\n",
    "        return torch.tensor([self.classes_[i] for i in argmax_idx])\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "ps_perc_pac = ProductSpacePerceptron(pm, max_epochs=100, patience=5)\n",
    "ps_perc_pac.fit(X, y)\n",
    "predictions = ps_perc_pac.predict(X)\n",
    "predictions\n",
    "\n",
    "# Check the accuracy\n",
    "print((predictions == y).float().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0001, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0001, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0001, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -0.9999, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0001,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -0.9999, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -0.9998, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0001, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0001, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0001,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0002, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9990, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9999, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -0.9999, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0001, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9999, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -0.9999, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -0.9999, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0001,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -0.9999, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -0.9998, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "       grad_fn=<DifferentiableGraphBackward>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_x = pm.factorize(X)[0]\n",
    "pm.P[0].manifold._log_scale = torch.nn.Parameter(torch.tensor(10.0))\n",
    "pm.P[0].manifold.inner(_x, _x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New code: kernel check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/phil/miniforge3/envs/embedders2/lib/python3.10/site-packages/torch/distributions/wishart.py:271: UserWarning: Singular sample detected.\n",
      "  warnings.warn(\"Singular sample detected.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor(False), tensor(False), tensor(False)]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import embedders\n",
    "\n",
    "pm = embedders.manifolds.ProductManifold([(-1, 2), (0, 2), (1, 2)])\n",
    "X, y = embedders.gaussian_mixture.gaussian_mixture(pm)\n",
    "\n",
    "[x.isnan().any() for x in product_kernel(pm, X, X)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.5703, -0.1795,  1.0183,  ..., -1.0199,  0.2129, -0.2404],\n",
       "        [-0.1795,  1.5708,  0.2632,  ...,  0.7079, -0.8280, -0.9777],\n",
       "        [ 1.0183,  0.2632,  1.5705,  ..., -0.4905,  0.0947, -0.7749],\n",
       "        ...,\n",
       "        [-1.0199,  0.7079, -0.4905,  ...,  1.5708, -0.4669, -0.3033],\n",
       "        [ 0.2129, -0.8280,  0.0947,  ..., -0.4669,  1.5703,  0.3170],\n",
       "        [-0.2404, -0.9777, -0.7749,  ..., -0.3033,  0.3170,  1.5705]],\n",
       "       grad_fn=<AsinBackward0>)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_kernel(pm, X, X)[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(-4), tensor(1.), tensor(2.)]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_kernel(embedders.manifolds.ProductManifold(signature=[(-4, 2), (0, 2), (4, 2)]), X, X)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000, -0.1786,  0.8512,  ..., -0.8521,  0.2113, -0.2381],\n",
       "        [-0.1786,  1.0000,  0.2602,  ...,  0.6502, -0.7366, -0.8292],\n",
       "        [ 0.8512,  0.2602,  1.0000,  ..., -0.4711,  0.0946, -0.6997],\n",
       "        ...,\n",
       "        [-0.8521,  0.6502, -0.4711,  ...,  1.0000, -0.4501, -0.2986],\n",
       "        [ 0.2113, -0.7366,  0.0946,  ..., -0.4501,  1.0000,  0.3117],\n",
       "        [-0.2381, -0.8292, -0.6997,  ..., -0.2986,  0.3117,  1.0000]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "_x = pm.factorize(X)[-1]\n",
    "pm.P[-1].inner(_x, _x) * pm.P[-1].curvature * pm.P[-1].scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],\n",
       "        [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],\n",
       "        [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],\n",
       "        ...,\n",
       "        [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],\n",
       "        [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],\n",
       "        [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pm.P[-1].inner(_x, _x)pm.P[-1].curvature * pm.P[-1].scale\n",
    "import embedders.manifolds\n",
    "\n",
    "\n",
    "embedders.manifolds.Manifold(curvature=2, dim=2).inner(_x, _x) / embedders.manifolds.Manifold(curvature=1, dim=2).inner(\n",
    "    _x, _x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.asin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1000])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm.P[0].manifold.inner(_x[:, None], _x[None, :]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptron = embedders.perceptron.ProductSpacePerceptron(pm)\n",
    "\n",
    "ptron.fit(X, y)\n",
    "(ptron.predict(X) == y).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7450)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do the same thing with train-test split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = embedders.gaussian_mixture.gaussian_mixture(pm)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "ptron = embedders.perceptron.ProductSpacePerceptron(pm)\n",
    "ptron.fit(X_train, y_train)\n",
    "(ptron.predict(X_test) == y_test).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ks, norms = embedders.kernel.product_kernel(pm, X, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 38.8659, -16.0567,  23.4093,  ...,   4.2112, -14.9139,  -2.0029],\n",
       "        [-16.0567,   7.4579, -11.1123,  ...,  -1.8085,   0.5661,  -0.4191],\n",
       "        [ 23.4093, -11.1123,  18.4601,  ...,   2.8568, -12.1712,  -0.5609],\n",
       "        ...,\n",
       "        [  4.2112,  -1.8085,   2.8568,  ...,   2.1052,  -5.3676,   0.5950],\n",
       "        [-14.9139,   0.5661, -12.1712,  ...,  -5.3676,   4.3270,  -3.2937],\n",
       "        [ -2.0029,  -0.4191,  -0.5609,  ...,   0.5950,  -3.2937,   1.2123]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = torch.ones(X.shape[0], X.shape[0])\n",
    "for mat in Ks:\n",
    "    K += mat\n",
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1202, 0.7269, 0.7182, 0.8251, 0.9668, 0.4298, 0.5931, 0.9310])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = torch.rand(X.shape[1])\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = torch.sign(X @ g) != (y * 2 - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.8569e+10,  5.5664e+09,  1.7664e+10,  1.0065e+06, -3.8445e+05,\n",
       "         2.2273e+05,  9.1254e+04, -1.8895e+05], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(((y * 2 - 1)[err, None] * K[err, :]).sum(dim=1)[:, None] * X[err, :]).sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.8569e+10,  5.5664e+09,  1.7664e+10,  1.0065e+06, -3.8445e+05,\n",
       "         2.2273e+05,  9.1254e+04, -1.8895e+05], grad_fn=<SqueezeBackward4>)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((y * 2 - 1)[err, None] * K[err, :]).sum(dim=1) @ X[err]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (582x8 and 582x1000)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[157], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43merr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43merr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m[\u001b[49m\u001b[43merr\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (582x8 and 582x1000)"
     ]
    }
   ],
   "source": [
    "((y * 2 - 1)[err, None]) * X[err] @ K[err]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 8])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K[:, err] @ X[err]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([582])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((y * 2 - 1)[err, None] * K[err, :]).sum(dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "inconsistent tensor size, expected tensor [1000] and src [8] to have the same number of elements, but got 1000 and 8 elements respectively",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[175], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;66;03m# Should be positive\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: inconsistent tensor size, expected tensor [1000] and src [8] to have the same number of elements, but got 1000 and 8 elements respectively"
     ]
    }
   ],
   "source": [
    "(y[0] * K[0]) @ X[0]  # Should be positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-143785.7812, grad_fn=<DotBackward0>), tensor(0))"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(-1 * K[0] @ X) @ X[0], y[0]  # Should be negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(19303.4414, grad_fn=<DotBackward0>), tensor(0))"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(-1 * K[1] @ X) @ X[1], y[1]  # Should be negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-21385.4707, grad_fn=<DotBackward0>), tensor(1))"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(-1 * K[6] @ X) @ X[6], y[6]  # Should be positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/phil/miniforge3/envs/embedders2/lib/python3.10/site-packages/torch/distributions/wishart.py:271: UserWarning: Singular sample detected.\n",
      "  warnings.warn(\"Singular sample detected.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.29910954e-12  6.29910954e-12 -8.43519079e-12  6.29910954e-12\n",
      "  6.29910954e-12  6.29910954e-12  6.29910954e-12 -8.43515007e-12\n",
      "  6.29910954e-12  6.29910954e-12  6.29910954e-12  6.29910954e-12\n",
      " -8.43523387e-12 -8.43557690e-12 -8.43522458e-12 -8.43522142e-12\n",
      "  6.29910954e-12  6.29910954e-12  6.29910954e-12 -8.43549300e-12\n",
      "  6.29910954e-12 -8.43525357e-12  6.29910954e-12  6.29910954e-12\n",
      " -8.43517822e-12  6.29910954e-12 -8.43525074e-12  6.29910954e-12\n",
      "  6.29910954e-12 -8.43431589e-12  6.29910954e-12  6.29910954e-12\n",
      " -8.43515676e-12 -8.43507610e-12  6.29910954e-12  6.29910954e-12\n",
      "  6.29910954e-12 -8.43566267e-12 -8.43529861e-12  6.29910954e-12\n",
      " -8.43524562e-12  6.29910954e-12  6.29910954e-12  6.29910954e-12\n",
      "  6.29910954e-12  6.29910954e-12  6.29910954e-12  6.29910954e-12\n",
      " -8.43497067e-12  6.29910954e-12  6.29910954e-12  6.29910954e-12\n",
      "  6.29910954e-12 -8.43650385e-12  6.29910954e-12  6.29910954e-12\n",
      "  6.29910954e-12  6.29910954e-12 -8.43521011e-12  6.29910954e-12\n",
      "  6.29910954e-12 -8.43523485e-12 -8.43565819e-12  6.29910954e-12\n",
      "  6.29910954e-12 -8.43524230e-12  6.29910954e-12  6.29910954e-12\n",
      "  6.29910954e-12 -8.43578252e-12  6.29910954e-12 -8.43525061e-12\n",
      "  6.29910954e-12 -8.43524052e-12 -8.43513867e-12 -8.43539152e-12\n",
      "  6.29910954e-12 -8.43521167e-12 -8.43518308e-12  6.29910954e-12\n",
      " -8.43489599e-12 -8.43523997e-12  6.29910954e-12  6.29910954e-12\n",
      "  6.29910954e-12  6.29910954e-12  6.29910954e-12 -8.43479416e-12\n",
      " -8.43528098e-12  6.29910954e-12  6.29910954e-12 -8.43524829e-12\n",
      " -8.43520503e-12 -8.43523270e-12 -8.43522831e-12 -8.43521047e-12\n",
      "  6.29910954e-12  6.29910954e-12 -8.43524294e-12  6.29910954e-12\n",
      "  6.29910954e-12  6.29910954e-12  6.29910954e-12  6.29910954e-12\n",
      "  6.29910954e-12  6.29910954e-12 -8.43522142e-12  6.29910954e-12\n",
      "  6.29910954e-12  6.29910954e-12  6.29910954e-12  6.29910954e-12\n",
      "  6.29910954e-12  6.29910954e-12  6.29910954e-12  6.29910954e-12\n",
      " -8.43521364e-12  6.29910954e-12  6.29910954e-12 -8.43515349e-12\n",
      "  6.29910954e-12  6.29910954e-12  6.29910954e-12  6.29910954e-12\n",
      "  6.29910954e-12 -8.43525025e-12 -8.43519840e-12 -8.43510636e-12\n",
      "  6.29910954e-12 -8.43535166e-12  6.29910954e-12  6.29910954e-12\n",
      "  6.29910954e-12  6.29910954e-12 -8.43541320e-12  6.29910954e-12\n",
      "  6.29910954e-12  6.29910954e-12 -8.43573620e-12  6.29910954e-12\n",
      " -8.43520514e-12 -8.43525665e-12 -8.43512872e-12  6.29910954e-12\n",
      "  6.29910954e-12 -8.43512744e-12 -8.43521398e-12  6.29910954e-12\n",
      "  6.29910954e-12 -8.43510513e-12 -8.43698523e-12  6.29910954e-12\n",
      "  6.29910954e-12  6.29910954e-12  6.29910954e-12  6.29910954e-12\n",
      "  6.29910954e-12 -8.43526308e-12 -8.43532879e-12 -8.43527866e-12\n",
      "  6.29910954e-12 -8.43512330e-12 -8.43600666e-12 -8.43520592e-12\n",
      "  6.29910954e-12  6.29910954e-12  6.29910954e-12  6.29910954e-12\n",
      " -8.43525067e-12 -8.43519967e-12 -8.43513595e-12  6.29910954e-12\n",
      " -8.43519034e-12 -8.43510884e-12 -8.43529270e-12  6.29910954e-12\n",
      "  6.29910954e-12 -8.43529632e-12  6.29910954e-12 -8.43530758e-12\n",
      " -8.43527775e-12 -8.43522774e-12  6.29910954e-12 -8.43522658e-12\n",
      "  6.29910954e-12 -8.43541227e-12  6.29910954e-12  6.29910954e-12\n",
      "  6.29910954e-12  6.29910954e-12 -8.43524668e-12 -8.43504931e-12\n",
      "  6.29910954e-12 -8.43526760e-12  6.29910954e-12  6.29910954e-12\n",
      " -8.43522305e-12 -8.43555926e-12 -8.43522654e-12 -8.43566251e-12\n",
      " -8.43514751e-12 -8.43525183e-12 -8.43525143e-12 -8.43391238e-12\n",
      " -8.43524550e-12  6.29910954e-12  6.29910954e-12  6.29910954e-12\n",
      " -8.43521226e-12  6.29910954e-12 -8.43530085e-12 -8.43528508e-12\n",
      "  6.29910954e-12 -8.43533457e-12  6.29910954e-12  6.29910954e-12\n",
      "  6.29910954e-12 -8.43520901e-12  6.29910954e-12 -8.43505998e-12\n",
      "  6.29910954e-12 -8.43573621e-12 -8.43524073e-12 -8.43519949e-12\n",
      " -8.43527478e-12  6.29910954e-12 -8.43525131e-12 -8.43523698e-12\n",
      "  6.29910954e-12  6.29910954e-12  6.29910954e-12  6.29910954e-12\n",
      "  6.29910954e-12 -8.43545732e-12  6.29910954e-12  6.29910954e-12\n",
      " -8.43539431e-12  6.29910954e-12 -8.43521651e-12  6.29910954e-12\n",
      "  6.29910954e-12  6.29910954e-12 -8.43528081e-12 -8.43544371e-12\n",
      "  6.29910954e-12  6.29910954e-12 -8.43523724e-12  6.29910954e-12\n",
      " -8.43545101e-12 -8.43527182e-12  6.29910954e-12  6.29910954e-12\n",
      " -8.43529873e-12  6.29910954e-12  6.29910954e-12 -8.43522472e-12\n",
      "  6.29910954e-12  6.29910954e-12 -8.43521464e-12  6.29910954e-12\n",
      "  6.29910954e-12 -8.43541153e-12  6.29910954e-12  6.29910954e-12\n",
      " -8.43522098e-12 -8.43530295e-12  6.29910954e-12  6.29910954e-12\n",
      "  6.29910954e-12 -8.43521795e-12 -8.43566368e-12  6.29910954e-12\n",
      " -8.43481156e-12 -8.43522741e-12 -8.43531236e-12 -8.43528487e-12\n",
      " -8.43519649e-12  6.29910954e-12  6.29910954e-12 -8.43527886e-12\n",
      " -8.43526864e-12 -8.43525776e-12  6.29910954e-12 -8.43518331e-12\n",
      " -8.43515068e-12  6.29910954e-12 -8.43531686e-12 -8.43524112e-12\n",
      " -8.43524086e-12  6.29910954e-12 -8.43524516e-12  6.29910954e-12\n",
      "  6.29910954e-12  6.29910954e-12  6.29910954e-12  6.29910954e-12\n",
      " -8.43493841e-12  6.29910954e-12 -8.43528589e-12  6.29910954e-12\n",
      "  6.29910954e-12 -8.43511608e-12  6.29910954e-12 -8.43520276e-12\n",
      " -8.43492882e-12 -8.43522470e-12  6.29910954e-12  6.29910954e-12\n",
      " -8.43530303e-12  6.29910954e-12 -8.43525080e-12  6.29910954e-12\n",
      "  6.29910954e-12  6.29910954e-12 -8.43521563e-12 -8.43547209e-12\n",
      "  6.29910954e-12  6.29910954e-12  6.29910954e-12 -8.43515433e-12\n",
      "  6.29910954e-12 -8.43521422e-12  6.29910954e-12  6.29910954e-12\n",
      " -8.43492599e-12 -8.43522695e-12 -8.43517179e-12 -8.43556987e-12\n",
      " -8.43510328e-12  6.29910954e-12 -8.43543550e-12  6.29910954e-12\n",
      "  6.29910954e-12  6.29910954e-12  6.29910954e-12  6.29910954e-12\n",
      "  6.29910954e-12  6.29910954e-12 -8.43721708e-12  6.29910954e-12\n",
      "  6.29910954e-12  6.29910954e-12  6.29910954e-12 -8.43523649e-12\n",
      "  6.29910954e-12  6.29910954e-12  6.29910954e-12  6.29910954e-12\n",
      " -8.43524249e-12  6.29910954e-12  6.29910954e-12  6.29910954e-12\n",
      " -8.43522739e-12  6.29910954e-12 -8.43461172e-12 -8.43525274e-12\n",
      " -8.43524033e-12  6.29910954e-12 -8.43519852e-12  6.29910954e-12\n",
      "  6.29910954e-12 -8.43516864e-12  6.29910954e-12 -8.43520298e-12\n",
      "  6.29910954e-12  6.29910954e-12  6.29910954e-12 -8.43520845e-12\n",
      "  6.29910954e-12  6.29910954e-12 -8.43729274e-12 -8.43381369e-12\n",
      "  6.29910954e-12 -8.43506722e-12 -8.43521074e-12 -8.43528334e-12\n",
      "  6.29910954e-12  6.29910954e-12  6.29910954e-12 -8.43505895e-12\n",
      "  6.29910954e-12 -8.43523480e-12 -8.43518067e-12  6.29910954e-12\n",
      " -8.43507282e-12 -8.43522756e-12 -8.43521846e-12  6.29910954e-12\n",
      "  6.29910954e-12  6.29910954e-12  6.29910954e-12  6.29910954e-12\n",
      "  6.29910954e-12  6.29910954e-12  6.29910954e-12 -8.43524915e-12\n",
      "  6.29910954e-12  6.29910954e-12  6.29910954e-12 -8.43523022e-12\n",
      " -8.43511107e-12  6.29910954e-12 -8.43526272e-12 -8.43556068e-12\n",
      " -8.43528718e-12  6.29910954e-12  6.29910954e-12 -8.43523728e-12\n",
      "  6.29910954e-12  6.29910954e-12  6.29910954e-12  6.29910954e-12\n",
      " -8.43524460e-12  6.29910954e-12 -8.43433477e-12  6.29910954e-12\n",
      " -8.43401217e-12  6.29910954e-12  6.29910954e-12  6.29910954e-12\n",
      "  6.29910954e-12  6.29910954e-12 -8.43521464e-12 -8.43519093e-12\n",
      "  6.29910954e-12  6.29910954e-12 -8.43516822e-12 -8.43519800e-12\n",
      "  6.29910954e-12  6.29910954e-12 -8.43523005e-12  6.29910954e-12\n",
      "  6.29910954e-12  6.29910954e-12 -8.43508121e-12  6.29910954e-12\n",
      "  6.29910954e-12  6.29910954e-12  6.29910954e-12  6.29910954e-12\n",
      "  6.29910954e-12  6.29910954e-12  6.29910954e-12  6.29910954e-12\n",
      " -8.43526596e-12 -8.43525295e-12  6.29910954e-12  6.29910954e-12\n",
      "  6.29910954e-12 -8.43512169e-12  6.29910954e-12  6.29910954e-12\n",
      "  6.29910954e-12  6.29910954e-12 -8.43521883e-12 -8.43516663e-12\n",
      " -8.43523996e-12  6.29910954e-12 -8.43525375e-12  6.29910954e-12\n",
      "  6.29910954e-12 -8.43519611e-12  6.29910954e-12 -8.43524594e-12\n",
      " -8.43545157e-12  6.29910954e-12  6.29910954e-12 -8.43557724e-12\n",
      "  6.29910954e-12  6.29910954e-12  6.29910954e-12 -8.43522769e-12\n",
      "  6.29910954e-12 -8.43542175e-12 -8.43468842e-12 -8.43511292e-12\n",
      "  6.29910954e-12 -8.43517254e-12 -8.43496071e-12 -8.43525709e-12\n",
      "  6.29910954e-12  6.29910954e-12 -8.43521825e-12  6.29910954e-12\n",
      " -8.43516948e-12  6.29910954e-12 -8.43583763e-12 -8.43505082e-12\n",
      "  6.29910954e-12  6.29910954e-12 -8.43522696e-12 -8.43461953e-12\n",
      "  6.29910954e-12 -8.43513117e-12  6.29910954e-12 -8.43516572e-12\n",
      "  6.29910954e-12 -8.43533902e-12  6.29910954e-12  6.29910954e-12\n",
      " -8.43514501e-12  6.29910954e-12 -8.43531368e-12 -8.43537092e-12\n",
      " -8.43519777e-12 -8.43523295e-12  6.29910954e-12  6.29910954e-12\n",
      " -8.43626078e-12 -8.41875719e-12  6.29910954e-12 -8.43550125e-12\n",
      " -8.43526296e-12  6.29910954e-12 -8.43597882e-12  6.29910954e-12\n",
      "  6.29910954e-12  6.29910954e-12  6.29910954e-12 -8.43507243e-12\n",
      "  6.29910954e-12  6.29910954e-12 -8.43517446e-12 -8.43520450e-12\n",
      " -8.43530805e-12  6.29910954e-12  6.29910954e-12  6.29910954e-12\n",
      " -8.43486279e-12  6.29910954e-12  6.29910954e-12 -8.43527583e-12\n",
      " -8.43522351e-12 -8.43523108e-12 -8.43544021e-12  6.29910954e-12\n",
      "  6.29910954e-12  6.29910954e-12 -8.43526341e-12  6.29910954e-12\n",
      "  6.29910954e-12  6.29910954e-12  6.29910954e-12 -8.43538359e-12\n",
      " -8.43529258e-12  6.29910954e-12  6.29910954e-12 -8.43519706e-12\n",
      "  6.29910954e-12  6.29910954e-12 -8.43521732e-12 -8.43519389e-12\n",
      " -8.43528191e-12 -8.43518108e-12 -8.43525959e-12  6.29910954e-12\n",
      "  6.29910954e-12 -8.43522401e-12 -8.43531356e-12 -8.43521943e-12\n",
      "  6.29910954e-12 -8.43523738e-12 -8.43506921e-12  6.29910954e-12\n",
      " -8.43524663e-12  6.29910954e-12 -8.43531366e-12  6.29910954e-12\n",
      "  6.29910954e-12  6.29910954e-12 -8.43514007e-12 -8.43518721e-12\n",
      "  6.29910954e-12 -8.43471958e-12 -8.43520230e-12 -8.43521495e-12\n",
      "  6.29910954e-12  6.29910954e-12  6.29910954e-12 -8.43524584e-12\n",
      "  6.29910954e-12 -8.43523627e-12  6.29910954e-12 -8.43528632e-12\n",
      "  6.29910954e-12  6.29910954e-12  6.29910954e-12 -8.43508616e-12\n",
      "  6.29910954e-12  6.29910954e-12  6.29910954e-12  6.29910954e-12\n",
      "  6.29910954e-12 -8.43525819e-12 -8.43680137e-12  6.29910954e-12\n",
      "  6.29910954e-12  6.29910954e-12  6.29910954e-12  6.29910954e-12\n",
      "  6.29910954e-12 -8.43519762e-12 -8.43514763e-12 -8.43521536e-12\n",
      "  6.29910954e-12  6.29910954e-12 -8.43525288e-12  6.29910954e-12\n",
      "  6.29910954e-12  6.29910954e-12  6.29910954e-12 -8.43523637e-12\n",
      " -8.43550462e-12 -8.43522135e-12 -8.43517891e-12 -8.43507107e-12\n",
      "  6.29910954e-12  6.29910954e-12  6.29910954e-12  6.29910954e-12\n",
      " -8.43557916e-12 -8.43524619e-12  6.29910954e-12  6.29910954e-12\n",
      " -8.43516765e-12 -8.43524286e-12  6.29910954e-12  6.29910954e-12\n",
      "  6.29910954e-12 -8.43638004e-12  6.29910954e-12  6.29910954e-12\n",
      " -8.43508411e-12 -8.43525308e-12 -8.43524117e-12 -8.43525749e-12\n",
      " -8.43520554e-12  6.29910954e-12  6.29910954e-12 -8.43525276e-12\n",
      " -8.43523372e-12  6.29910954e-12 -8.43478909e-12  6.29910954e-12\n",
      " -8.43525205e-12 -8.43523148e-12 -8.43522478e-12  6.29910954e-12\n",
      "  6.29910954e-12 -8.43462874e-12  6.29910954e-12  6.29910954e-12\n",
      "  6.29910954e-12 -8.43455861e-12 -8.43501787e-12 -8.43527222e-12\n",
      " -8.43509476e-12 -8.43509321e-12 -8.43523913e-12 -8.43601406e-12\n",
      " -8.43513747e-12 -8.43504411e-12  6.29910954e-12 -8.43557313e-12\n",
      "  6.29910954e-12  6.29910954e-12  6.29910954e-12 -8.43495450e-12\n",
      "  6.29910954e-12 -8.43575010e-12  6.29910954e-12  6.29910954e-12\n",
      " -8.43530322e-12 -8.43509157e-12  6.29910954e-12  6.29910954e-12\n",
      " -8.43492934e-12 -8.43511305e-12  6.29910954e-12  6.29910954e-12\n",
      " -8.43524909e-12  6.29910954e-12  6.29910954e-12 -8.43527552e-12\n",
      " -8.43520675e-12  6.29910954e-12 -8.43529262e-12 -8.43512815e-12\n",
      "  6.29910954e-12 -8.43512049e-12  6.29910954e-12  6.29910954e-12\n",
      " -8.43536053e-12 -8.43523256e-12  6.29910954e-12 -8.43521524e-12\n",
      "  6.29910954e-12 -8.45040559e-12  6.29910954e-12 -8.43516422e-12\n",
      "  6.29910954e-12  6.29910954e-12 -8.43517595e-12 -8.43538204e-12\n",
      " -8.43516249e-12  6.29910954e-12 -8.43526238e-12 -8.43519303e-12\n",
      "  6.29910954e-12 -8.43519764e-12 -8.43523810e-12  6.29910954e-12\n",
      " -8.43505343e-12  6.29910954e-12  6.29910954e-12 -8.43514941e-12\n",
      " -8.43553451e-12 -8.43520768e-12 -8.43520882e-12  6.29910954e-12\n",
      " -8.43506236e-12  6.29910954e-12  6.29910954e-12 -8.43523468e-12\n",
      "  6.29910954e-12 -8.43482791e-12 -8.43505848e-12 -8.43517256e-12\n",
      " -8.43521890e-12 -8.43533873e-12 -8.43530182e-12  6.29910954e-12\n",
      " -8.43522235e-12 -8.43510759e-12 -8.43517757e-12  6.29910954e-12\n",
      " -8.43524816e-12  6.29910954e-12 -8.43524847e-12  6.29910954e-12\n",
      "  6.29910954e-12  6.29910954e-12  6.29910954e-12 -8.43521936e-12\n",
      "  6.29910954e-12  6.29910954e-12  6.29910954e-12  6.29910954e-12\n",
      " -8.43524358e-12  6.29910954e-12 -8.43558999e-12 -8.43524722e-12\n",
      "  6.29910954e-12  6.29910954e-12  6.29910954e-12 -8.43525484e-12\n",
      "  6.29910954e-12  6.29910954e-12 -8.43566821e-12  6.29910954e-12\n",
      " -8.43547537e-12  6.29910954e-12 -8.43533787e-12 -8.43479814e-12\n",
      " -8.43525468e-12 -8.43528115e-12  6.29910954e-12  6.29910954e-12\n",
      " -8.43522870e-12  6.29910954e-12  6.29910954e-12  6.29910954e-12\n",
      " -8.43548776e-12 -8.43523832e-12 -8.43538822e-12  6.29910954e-12\n",
      "  6.29910954e-12 -8.43503036e-12  6.29910954e-12  6.29910954e-12\n",
      " -8.43460913e-12 -8.43502618e-12 -8.43551538e-12  6.29910954e-12\n",
      " -8.43524575e-12  6.29910954e-12 -8.43528373e-12 -8.43483876e-12\n",
      "  6.29910954e-12  6.29910954e-12 -8.43475896e-12 -8.43611309e-12\n",
      "  6.29910954e-12 -8.43453142e-12 -8.43526593e-12 -8.43523525e-12\n",
      " -8.43527926e-12  6.29910954e-12  6.29910954e-12  6.29910954e-12\n",
      " -8.43523591e-12  6.29910954e-12 -8.43509581e-12  6.29910954e-12\n",
      "  6.29910954e-12 -8.43560771e-12 -8.43498863e-12  6.29910954e-12\n",
      "  6.29910954e-12  6.29910954e-12 -8.43554226e-12 -8.43522298e-12\n",
      " -8.43543349e-12 -8.43533880e-12 -8.43517798e-12  6.29910954e-12\n",
      "  6.29910954e-12 -8.43483013e-12  6.29910954e-12  6.29910954e-12\n",
      "  6.29910954e-12  6.29910954e-12  6.29910954e-12 -8.43520458e-12\n",
      "  6.29910954e-12  6.29910954e-12  6.29910954e-12  6.29910954e-12\n",
      " -8.43552214e-12  6.29910954e-12 -8.43525301e-12  6.29910954e-12\n",
      "  6.29910954e-12 -8.43533002e-12  6.29910954e-12 -8.43524728e-12\n",
      "  6.29910954e-12 -8.43525808e-12 -8.43485544e-12  6.29910954e-12\n",
      "  6.29910954e-12 -8.43525219e-12 -8.43524467e-12  6.29910954e-12\n",
      "  6.29910954e-12 -8.43522558e-12  6.29910954e-12  6.29910954e-12\n",
      "  6.29910954e-12 -8.43534427e-12 -8.43523596e-12  6.29910954e-12\n",
      "  6.29910954e-12  6.29910954e-12 -8.43524428e-12 -8.43535433e-12\n",
      " -8.43524342e-12 -8.43526335e-12  6.29910954e-12  6.29910954e-12\n",
      "  6.29910954e-12 -8.43531419e-12 -8.43524409e-12  6.29910954e-12\n",
      "  6.29910954e-12  6.29910954e-12  6.29910954e-12  6.29910954e-12\n",
      " -8.43529385e-12 -8.43522107e-12  6.29910954e-12  6.29910954e-12\n",
      " -8.43508740e-12 -8.43548301e-12  6.29910954e-12  6.29910954e-12\n",
      "  6.29910954e-12 -8.43525533e-12 -8.43520822e-12  6.29910954e-12\n",
      "  6.29910954e-12 -8.43513966e-12  6.29910954e-12  6.29910954e-12\n",
      " -8.43497988e-12  6.29910954e-12  6.29910954e-12  6.29910954e-12\n",
      "  6.29910954e-12  6.29910954e-12  6.29910954e-12  6.29910954e-12\n",
      " -8.43527776e-12 -8.43520931e-12 -8.43529653e-12  6.29910954e-12\n",
      " -8.43524686e-12 -8.43542030e-12  6.29910954e-12 -8.43537761e-12\n",
      "  6.29910954e-12 -8.43598144e-12 -8.43520486e-12 -8.43531204e-12\n",
      " -8.43534032e-12 -8.43533340e-12  6.29910954e-12 -8.43525796e-12\n",
      "  6.29910954e-12 -8.43515081e-12 -8.43524114e-12 -8.43525163e-12\n",
      "  6.29910954e-12  6.29910954e-12  6.29910954e-12  6.29910954e-12\n",
      "  6.29910954e-12  6.29910954e-12 -8.43529962e-12  6.29910954e-12\n",
      "  6.29910954e-12 -8.43514184e-12  6.29910954e-12 -8.43498559e-12\n",
      "  6.29910954e-12 -8.43531773e-12 -8.43495910e-12 -8.43536277e-12\n",
      " -8.43501115e-12  6.29910954e-12  6.29910954e-12  6.29910954e-12\n",
      "  6.29910954e-12 -8.43525958e-12 -8.43527151e-12  6.29910954e-12\n",
      "  6.29910954e-12 -8.43522556e-12 -8.43588661e-12  6.29910954e-12\n",
      " -8.43566853e-12 -8.43526569e-12 -8.43513640e-12 -8.43527732e-12\n",
      "  6.29910954e-12 -8.43518085e-12 -8.43543840e-12 -8.43518330e-12\n",
      " -8.43519223e-12  6.29910954e-12  6.29910954e-12  6.29910954e-12\n",
      " -8.43525523e-12  6.29910954e-12  6.29910954e-12  6.29910954e-12\n",
      "  6.29910954e-12  6.29910954e-12 -8.43523947e-12  6.29910954e-12\n",
      "  6.29910954e-12  6.29910954e-12  6.29910954e-12  6.29910954e-12\n",
      " -8.43426824e-12 -8.43450638e-12  6.29910954e-12  6.29910954e-12\n",
      " -8.43516265e-12  6.29910954e-12  6.29910954e-12  6.29910954e-12\n",
      "  6.29910954e-12  6.29910954e-12 -8.43542473e-12  6.29910954e-12\n",
      " -8.43506151e-12  6.29910954e-12  6.29910954e-12  6.29910954e-12\n",
      "  6.29910954e-12  6.29910954e-12 -8.43506825e-12  6.29910954e-12\n",
      "  6.29910954e-12  6.29910954e-12 -8.43525864e-12  6.29910954e-12\n",
      " -8.43527995e-12 -8.43522067e-12 -8.43507732e-12 -8.43513101e-12\n",
      "  6.29910954e-12  6.29910954e-12  6.29910954e-12  6.29910954e-12\n",
      "  6.29910954e-12  6.29910954e-12  6.29910954e-12  6.29910954e-12] [-4.51877109e+00  1.77311835e+00 -3.21764736e+00  1.31171728e+01\n",
      "  3.09149132e+00  8.31801718e+00  8.69645304e-01 -4.71052132e+00\n",
      "  3.17994908e+00  6.37020904e-01 -3.16698374e+00  4.93076622e+00\n",
      "  3.69490477e+00  2.21477173e+01 -7.16327157e+00 -1.33712142e+01\n",
      " -2.56864156e+00  4.45286871e+00 -2.84552596e+00  3.11532553e+01\n",
      " -3.43042603e+00  5.31438765e-01 -1.99927656e+00  4.94772821e+00\n",
      " -1.09730595e+01  1.15343924e+00 -4.62656352e+00 -3.04302227e+00\n",
      " -1.75441842e+00 -5.33457017e+01  5.05071976e+00  9.77747268e+00\n",
      "  7.57008654e+00 -2.04340385e+00 -4.87689765e+00 -2.01915621e+00\n",
      "  6.38335676e+00  6.69215307e+00 -2.33577480e+00  1.38171542e+01\n",
      "  9.17390445e+00 -2.26232460e-01 -5.47463807e-01 -7.97343876e-01\n",
      " -3.98367328e+00 -1.28358311e+00  1.64780054e+00 -2.51051846e+00\n",
      " -3.68858270e+01 -1.34063799e+00  1.28045899e+01  1.04578770e+01\n",
      " -2.04504980e+00  4.62558523e+01  1.86302711e+00  2.00715563e+00\n",
      " -5.94433274e+00  1.94634162e+00 -6.25675475e+00  3.03621641e+00\n",
      " -5.61134618e+00  2.16007802e+00  3.16637164e+01  9.34743496e+00\n",
      " -1.00585421e-01 -2.84310063e-01 -2.29228098e+00  3.19486769e+00\n",
      " -2.72490930e+00  4.94886965e+01 -2.43856199e-02  1.47556472e+00\n",
      " -2.15151527e+00  3.27773282e+00 -1.14374836e+01  1.06872316e+00\n",
      "  3.86461812e+00  1.07956732e+01 -2.49426415e+01  5.15719164e-02\n",
      " -2.05591755e+01  5.87924754e+00  1.80199114e+00  5.41704525e+00\n",
      " -2.23370305e+00 -7.07395414e+00 -3.31231627e+00  2.12711169e+01\n",
      " -7.90647291e+00  6.36814181e+00 -4.33491042e-02 -1.60891520e+00\n",
      " -3.78290001e+00  6.89348330e+00 -3.04066773e+01 -6.43533306e+00\n",
      "  3.75937508e+00  1.96433905e+00  6.09030376e-01  1.25056284e+01\n",
      " -4.50016714e+00  7.55873338e+00  7.02175276e+00 -4.94495330e+00\n",
      "  2.94101772e+00  1.09611171e+01 -1.18143106e+00  2.28659335e+00\n",
      "  6.14718248e+00 -1.45589569e+00 -7.97572540e-01 -6.06135418e+00\n",
      " -7.97157127e+00  4.04306861e+00 -2.60907551e+00 -2.64986058e+00\n",
      "  3.64795094e+00  1.45094920e+00  2.23213764e+00 -3.13956360e+00\n",
      " -3.32663090e+00 -3.68149321e+00  1.69122153e+00 -4.26394916e-01\n",
      " -4.91263758e+00 -5.58210718e+00 -7.57912898e+00 -1.60592041e+01\n",
      " -1.66156087e-01  1.55947533e+01  1.67285478e+00 -1.12232167e-01\n",
      "  4.78359486e+00  6.14184629e+00 -3.48629038e+01 -1.60251671e+00\n",
      "  5.12378953e+00 -4.28727422e+00  2.23698330e+01 -4.69610059e+00\n",
      "  5.01213039e+00  6.34396000e+00 -6.54758094e+00  1.28723107e+01\n",
      " -5.98868869e+00 -2.57218788e+00 -4.72115493e+00 -6.54007665e-01\n",
      "  1.23376473e+01 -1.83415646e+01  5.98380046e+01 -2.65914948e+00\n",
      " -5.12250178e+00  2.94602734e+00 -2.39623534e+00  7.20339159e+00\n",
      "  4.02594957e+00  4.86753719e+00 -1.23095723e+01  1.32612972e+01\n",
      "  2.70892353e+01 -3.09959829e+01  4.69427875e+01 -9.80967378e+00\n",
      " -8.66962465e+00  9.33546141e-02  8.48508246e+00  7.21694215e+00\n",
      "  5.77566446e-01 -3.98204011e+01 -8.87881845e+00 -3.15068523e+00\n",
      " -4.79564756e+01  3.77003229e+01 -5.00459560e+00  2.98175944e+00\n",
      "  1.02583738e+00 -7.88875021e+00  2.62953911e+00 -7.96221062e+00\n",
      " -5.15244384e+00 -3.50796608e+00 -8.13195719e+00 -9.17081635e-02\n",
      "  1.96126713e+01  1.80853695e+01 -7.82759832e-01 -6.46413396e+00\n",
      "  1.48700128e+01 -4.88857588e+00 -8.55726172e-01 -2.98097167e+01\n",
      "  2.99097528e+00  6.92249531e+00 -2.78354816e+00  2.14951095e-01\n",
      " -2.14317398e+00  5.01422662e+00  7.36889984e+00 -3.98553511e+01\n",
      "  2.95643213e+00  1.77496919e+01 -4.31556417e+00 -4.60935069e+01\n",
      " -1.66295392e-01  9.54593188e+00 -1.27151389e+00 -4.09606570e+00\n",
      "  2.26333609e-02 -1.62173325e-01 -1.55284643e+01 -1.89477058e+00\n",
      "  3.90822715e+00  4.31956044e+00 -9.19064518e-01  9.25497450e+00\n",
      "  4.88976378e-01 -1.74005377e+01 -2.09606216e+00  3.77434494e+00\n",
      " -1.64401822e+00  8.51512352e+00 -9.85273064e+00  5.05411356e+00\n",
      "  6.74611203e+00  1.01848986e+00  1.03418409e+01 -4.23032894e+00\n",
      " -1.03346708e+00 -2.95962296e+00  1.92144481e+00  4.44437938e+00\n",
      "  3.17313885e+00  1.77437548e+01  6.38349257e+00 -5.35805111e-01\n",
      " -1.47527142e+01 -7.60965709e-01 -6.88769798e+00  1.22663807e+01\n",
      "  1.19542875e+00 -1.83894870e-01 -2.18200086e-01  2.65639605e+01\n",
      " -2.05389560e+00  2.93504622e+00  2.25747891e+00 -8.52570796e-01\n",
      "  2.07178784e+01  4.94708101e+00 -6.47303970e-02 -1.49503862e+00\n",
      "  3.23093632e+01  1.03895157e+01 -2.11964134e+00 -5.53650228e+00\n",
      " -1.85975197e+00 -2.15164794e+00 -8.02043211e+00  5.42953880e+00\n",
      "  5.52569879e+00  1.83314523e+01  3.00117401e+01 -3.76059043e+00\n",
      " -9.59261504e+00  1.05441609e+01  3.19650507e+00  2.43039550e+00\n",
      " -8.12021086e-01 -1.22149505e+01 -1.88587444e+01  6.20371991e+00\n",
      "  4.87685418e+00  1.72182226e+01  8.67229893e+00  1.18036127e+01\n",
      " -1.19823581e+01  2.32201886e-01 -3.83079051e-01  5.94804230e+00\n",
      "  1.50540214e+00  6.14316899e+00 -3.92680016e+00 -1.09812667e+00\n",
      "  1.72771909e+01 -5.23713110e+00 -3.37567986e+00 -6.69130267e-01\n",
      "  3.13031344e+00  3.30321664e-01 -1.17290700e+00 -2.43702822e+00\n",
      "  1.34906633e+00 -6.79970580e-01 -1.49222217e+00  5.74367230e-01\n",
      " -8.65778375e+00  5.41927403e+00  7.13864429e+00 -4.03920059e+00\n",
      "  1.65780325e+01  1.18066399e+00  1.08641832e+00  6.03261069e+00\n",
      " -1.16478220e+00 -3.85135442e-01 -3.30403112e-01 -1.96205655e+00\n",
      "  2.15212508e+01  2.60773325e+00  6.71824775e-01 -5.36711353e-02\n",
      " -2.01718250e-01 -2.71599375e+00 -9.00057870e+00  7.60000528e+00\n",
      "  2.04635804e+00 -5.55662939e-02 -2.12701192e+00  1.69677598e+01\n",
      " -8.14262843e+00 -2.62283073e+01  4.26097469e+00 -1.94076228e+00\n",
      " -1.52651551e+01 -6.33849634e+00  1.26048032e+00  2.24413509e+01\n",
      " -1.27613583e+01 -2.06069461e+00  2.51018066e+01  1.16668554e-02\n",
      " -4.03560357e+00 -5.42950401e-01  5.14702049e+00 -2.86886043e-02\n",
      " -5.51370997e+00  3.37877826e+00  2.85244261e+01 -3.54642937e+00\n",
      " -1.94591553e+01  1.27069530e+00  4.01165922e+00  1.42564547e+00\n",
      "  3.84593120e+00 -9.50671316e-01  6.39481005e+00  3.60722770e+00\n",
      " -1.22237578e+01  1.95746154e+00 -4.29793441e+00  3.12843555e+00\n",
      " -9.78506466e+00  1.00558209e+01 -6.13893206e+01  3.55704474e+00\n",
      "  1.74676990e+00  4.43582744e-01 -4.63652102e+00  2.98615305e+00\n",
      "  3.17120215e+00 -6.00723991e+00 -5.46698666e+00  9.34152510e+00\n",
      "  1.27616839e+01 -3.48285261e+00  5.17862466e+00 -8.29956357e+00\n",
      " -5.10953204e+00 -7.22129178e+00  3.76892095e+01 -3.31381663e+01\n",
      "  5.36152770e+00 -9.75758373e+00 -6.88214522e+00  3.00066995e+00\n",
      "  7.38092098e+00 -2.00569704e+00 -3.83968054e-02 -1.71178607e+01\n",
      "  1.03491997e+01 -7.00073677e-01  1.77889566e+00  7.86396978e+00\n",
      " -2.89669007e+01  2.98415348e+00  3.92237955e+00  4.51318293e+00\n",
      " -9.28099629e+00  3.94873689e+00  4.66581682e+00  1.22198358e+01\n",
      "  6.38600079e+00  7.74006186e-02 -1.00492690e+01  7.53993179e-01\n",
      " -6.28572466e+00  1.85807980e+01  2.92440403e+00  2.00673927e+00\n",
      " -2.90836184e+01  1.41607163e+01  1.25898820e+00  5.15241130e+01\n",
      "  2.94854726e+00 -2.20282874e+00  2.03418171e+00 -5.88461230e-01\n",
      " -3.68333079e+00 -5.28152020e+00 -7.15549872e-01  2.13065855e-01\n",
      " -1.10709684e+01 -8.31720774e+00 -2.83366064e+01  1.21468122e+00\n",
      " -5.49366475e+01  7.40773857e+00  6.51355800e+00 -1.73159158e+00\n",
      " -3.63184539e+00 -4.40991788e+00 -1.20618887e+01 -7.91504822e+00\n",
      " -5.18838055e+00 -3.51080372e+00 -7.69165821e+00  3.67504320e+01\n",
      " -3.31176666e+00  2.48337188e+00 -4.24499161e-01 -4.79913601e+00\n",
      "  8.93662179e-01 -5.22594636e+00 -3.02583404e+01 -4.05972727e+00\n",
      " -2.54964309e+00  3.89382500e+00  1.07240896e+00 -1.57625496e+00\n",
      " -2.90358764e+00 -2.91887705e+00 -3.60112717e+00 -4.69097126e+00\n",
      "  2.92957344e+01  1.45336055e-01  8.73895397e+00 -1.97629460e-01\n",
      " -1.63400925e+00 -9.61197307e+00 -4.12182638e+00  8.90321570e-01\n",
      "  3.96617780e+00 -9.25094737e-01 -2.45336360e+00 -2.12819521e+01\n",
      " -3.34887360e+00  3.57042904e-01  6.00539882e+00 -1.83150123e+00\n",
      "  4.48131955e+00 -2.42861692e+01 -4.47634615e+00  1.44098871e+00\n",
      "  9.37600676e+00 -9.10715684e-01  2.80042654e+00  2.15075560e+00\n",
      "  4.56835867e+00  5.48084070e+00  1.58225619e-01  4.47172285e+00\n",
      " -5.13655976e+00  3.78701400e+01 -2.95669130e+01 -1.82130371e+01\n",
      "  8.35787064e-01  1.78292808e+00 -1.10335030e+01 -7.27556209e+00\n",
      "  1.49541616e+01 -3.08184430e+00 -1.26743200e+01 -6.58839646e+00\n",
      " -3.07922615e+00  2.91966118e+00  3.79356781e+01 -9.37988797e+00\n",
      " -8.75477661e+00 -1.71153945e+00 -6.41949698e+00 -3.94086345e+01\n",
      "  2.13383330e-01 -1.86815784e+01 -6.45249839e-01 -8.95158908e+00\n",
      "  1.19755909e+00  5.07908151e+00 -6.24441873e+00 -1.58450961e+00\n",
      "  7.16235993e+00 -2.82760541e+00  1.72431536e+01  1.11921157e+01\n",
      " -2.29637347e+01 -1.43352071e+00 -1.17213106e+00 -2.92715691e+00\n",
      "  3.89351705e+01 -5.07928752e+01  8.15814494e-01 -1.07487791e-01\n",
      " -8.06499268e-01  2.04062009e+00  1.19980405e+01 -3.39545511e+00\n",
      "  6.40556089e-02  1.71000985e+00  2.67354858e+00 -3.42310050e+01\n",
      " -7.12095319e+00  4.14396222e-01 -7.50452413e+00 -2.24896723e+01\n",
      "  7.69284645e+00  5.01882336e+00  9.64355255e+00 -4.22731065e+00\n",
      "  1.03798813e+01  2.85317342e+00 -1.59337816e+00 -6.38410254e+00\n",
      " -8.24759626e+00  5.16392375e+00 -1.86910658e+01  7.01990065e+00\n",
      " -3.17031380e+00  6.23395368e+00  5.00686254e+00 -4.84546894e+00\n",
      " -3.87055228e+00 -1.22218751e+00 -7.89132750e+00  3.51652890e+01\n",
      " -1.17369832e+01 -3.98413812e+00 -6.72196495e+00 -2.77470757e-01\n",
      "  1.23567999e+00  3.50652984e+00  3.44830571e+00 -8.09352943e+00\n",
      " -1.50432574e+01  4.56880774e+00 -3.14851079e+00  6.78304986e+00\n",
      "  6.36843111e+00  2.15885223e+00 -2.40410268e+01 -2.03913135e-01\n",
      " -7.29720822e+00  6.16470237e+00  2.04364534e+01 -3.00211382e+01\n",
      "  4.44347905e+00 -3.78128671e+00  1.54415428e+01 -8.80218545e-01\n",
      " -3.35170537e+00 -5.26433699e+00  6.14663020e+00 -2.00044152e+01\n",
      "  1.05846713e+01  7.95978659e+00 -3.09583758e+01  5.26742516e+00\n",
      "  3.23095714e+00  1.05168313e+01 -2.89099807e-02 -7.97980548e+00\n",
      " -3.83104539e+00  4.11815146e+00  3.05603422e+00  9.02387994e+00\n",
      " -4.34045091e+00 -3.07677423e+00  5.33722269e+00 -1.81773029e+01\n",
      " -3.77263303e+00 -1.60075953e-01 -4.63987222e+00  2.91191007e+00\n",
      " -4.29443732e+00  5.27718594e+00  1.92242843e+01 -4.06890325e+00\n",
      "  3.55088155e+00 -3.35162556e+00 -2.30781332e+00 -1.22897736e+01\n",
      " -4.53592434e+00 -1.14722316e+01 -7.03143219e+00 -6.76828064e+00\n",
      "  2.05463729e+00 -1.58594554e+00 -2.47188247e+00  4.70724576e+00\n",
      "  6.71188841e+00  1.04148571e+00 -4.31143805e-01 -7.90062225e+00\n",
      "  3.67719029e+01  8.22809435e+00  1.30381008e+01 -2.94702459e+00\n",
      " -3.09168538e+00 -1.17060468e+00  1.04043123e+01 -2.67851170e+00\n",
      " -1.11912279e+01 -1.02334805e+01  1.39159610e-01 -2.91511806e+00\n",
      " -5.40283941e+00 -3.62256042e+00  3.91521042e+00  2.40747454e+00\n",
      "  1.67200770e+00  5.71048177e+01  1.35501338e+01  1.04367330e+01\n",
      "  1.60608696e+01  5.48538505e-01  9.09403466e-01 -1.88711900e+01\n",
      " -2.03778377e+01 -1.04960635e+00 -2.05988667e+00  2.04428813e+00\n",
      "  3.53648430e+00 -3.54879175e+00  1.72475527e+01  2.21413863e+00\n",
      " -5.33008570e+00 -7.23121209e+00 -7.41013161e+00  4.06638046e+00\n",
      "  4.11390013e+00 -5.01237558e+01  1.23360508e+01 -6.18663957e+00\n",
      "  1.72348663e+01 -2.43510076e+01 -3.19568904e+01 -5.53916170e-01\n",
      " -8.98868249e+00 -7.17343377e+00 -3.36819329e+00  4.61204103e+01\n",
      " -2.47384881e+01 -1.89063790e+01  4.07104186e+00  2.14100367e+01\n",
      " -1.79267422e+00  6.62342301e+00 -4.41697783e+00  2.90001225e+00\n",
      "  5.49839006e+00  2.10902690e+01 -4.02839384e+00  1.67194998e+00\n",
      " -1.55016028e+01 -4.36332342e+00  3.69667324e+00  8.07586645e+00\n",
      " -4.92497963e-01 -1.72739274e+01  2.08510145e+00  9.86735403e+00\n",
      "  1.19336597e+01 -8.84110163e-01 -1.96347598e+00 -3.19660976e+00\n",
      " -7.33297603e+00  5.24549269e+00  6.53131929e+00  1.28279464e+01\n",
      " -4.38494242e+00 -2.33500852e+01  2.24887512e+00  3.33198790e+00\n",
      " -1.30240038e+01 -3.39803041e+00 -3.93347844e+00 -5.12880312e+00\n",
      " -4.06177962e+00  7.24606205e+01  8.52008184e-01 -1.20570388e+01\n",
      "  4.28889501e+00  3.88428241e+00  6.82192537e-02  1.76863721e+01\n",
      "  1.13916760e+01 -1.28795346e+00 -2.90297247e+00 -1.13274849e+00\n",
      " -5.76647427e+00  1.02788375e+01 -5.04144605e+00 -5.84952173e+00\n",
      " -2.11956828e+01 -4.03819186e+00 -6.63006654e-01 -2.89963614e+01\n",
      "  3.02231893e+01  2.44085806e+00 -5.50037336e+00 -2.02840527e+00\n",
      "  1.06778992e+01  4.83146480e+00 -3.62401264e+00 -3.56502403e+00\n",
      " -8.56787019e-01 -3.51168136e+01  1.15486300e+00  8.94553521e+00\n",
      " -3.59432148e+00 -4.24759764e+00  9.94178488e+00  4.61868245e+00\n",
      "  2.28078381e+00  1.76015614e+01  5.74591043e+00  1.41270525e+00\n",
      "  2.41633622e+00  8.82538451e+00  3.17852825e+00  8.02819573e-02\n",
      " -3.29945633e+00  1.73454428e+00  8.80317533e-02 -6.86932624e+00\n",
      "  5.07963601e+00 -8.20612399e+00  6.12595184e-02 -2.44040386e+00\n",
      " -2.21231167e+00  3.53893008e+00 -2.73055291e+00 -3.21351429e-01\n",
      " -6.37398421e+00  2.99511981e-01  1.02781000e+01  1.81677600e+00\n",
      "  6.29100628e-01 -6.29381339e+00  4.85035668e+01 -4.85083177e+00\n",
      " -7.28823687e+00 -2.36166053e+00  3.77879192e+00  1.32251824e+01\n",
      " -3.41048704e+01 -4.20060859e+00 -1.65693708e+00  6.92612365e+00\n",
      " -3.02742100e+00 -4.63138476e+00  4.39553986e+00 -6.36527239e+00\n",
      "  1.75341372e+01 -1.92422283e+00  9.23128336e+00  3.17939187e+00\n",
      "  2.59297990e-01  4.45665925e+00 -2.20417573e+00 -4.19035732e+00\n",
      "  4.54728919e+01 -2.09778150e+01  1.39299922e+01  1.68827915e+01\n",
      "  1.32725575e+00  2.36782538e+00  2.72549182e-01 -3.67774589e+01\n",
      " -5.28525406e+00 -9.47222981e-01 -1.93139792e+01  4.35986225e+01\n",
      " -3.23929744e+00 -7.11707740e+00 -1.23987865e+00  1.39097426e+00\n",
      "  1.04913386e+01  3.40032674e-01 -3.52056584e+00 -1.78358651e+00\n",
      " -3.63687480e+00  7.21366677e+00 -9.67650569e+00 -2.91135527e+00\n",
      " -4.05469560e+00  3.45751745e+00  1.09395735e+01 -5.15840099e+00\n",
      "  1.13814165e+00  9.09829468e+00  1.24199947e+01  7.59405978e+00\n",
      "  1.99358028e+01  1.89637133e+00 -1.11812628e+01 -2.46193002e+00\n",
      "  4.50764664e+00 -1.57330749e+01 -4.98649667e+00 -3.32204936e+00\n",
      "  8.52673498e+00  7.40010750e+00 -1.26108962e+00 -1.15313769e+01\n",
      " -4.87035785e-01  9.89806557e+00  1.36126349e+00  6.42242053e-01\n",
      "  2.59014776e+01  2.76126334e+00  4.82017559e+00 -1.00051942e+00\n",
      "  4.36258202e+00  1.24436828e+01  1.01120253e+01  3.63799734e+00\n",
      " -9.75656866e+00 -2.05604075e+00 -8.50601176e+00 -1.34435856e+01\n",
      "  6.75629118e-01  9.95834873e-01  2.16524394e-01  3.24323727e+00\n",
      " -8.86587772e+00 -5.90622692e+00 -4.50831580e+00  2.41990541e+00\n",
      " -1.42698438e+01  3.57355612e+00  8.55343320e+00  6.95447924e+00\n",
      " -5.30054422e+00 -4.30460818e+00  1.21715397e+01 -8.94466550e+00\n",
      "  1.46706857e-01 -6.70507343e+00 -1.62216855e+00  9.04140835e+00\n",
      "  3.01187647e+00  3.60470506e-01 -6.06771696e+00  1.57701606e+00\n",
      " -2.32502090e+00  7.12691429e+00  7.72556941e-01  5.25474730e-01\n",
      "  1.73394231e+01 -7.12398300e+00  3.94971717e+00  9.66869319e-02\n",
      " -2.69310516e+01  1.75483334e+01  1.00143321e+01  4.26073957e+00\n",
      "  7.57213122e+00  1.15916007e+01 -4.49663130e+00  5.82422910e+00\n",
      " -3.07131769e+00  1.95868971e+00  4.59414226e+00 -4.68510031e+00\n",
      " -2.87386549e+01 -4.02644033e+00  4.72325638e-01 -1.14798105e+00\n",
      " -8.31181643e-01 -2.17602312e+00  3.18236480e-01  4.78384430e+00\n",
      " -7.68233929e+00 -3.00240150e+00 -9.45048252e+00  2.63449926e+00\n",
      "  2.37991302e+00  2.71137172e+01 -5.61435173e+00 -2.22631870e+01\n",
      "  8.94304545e+00  3.92729223e+01 -2.58881623e+00 -5.47824211e+00\n",
      "  2.11963254e+01 -8.06144944e+00  1.27413365e+00 -1.80552891e+00\n",
      " -3.83756665e+00 -1.83320429e+01 -1.06533687e+01 -2.08325364e+00\n",
      " -2.77595835e+00  4.92623544e+00 -6.81006990e-02 -6.02799805e+00\n",
      "  4.47918858e+00 -8.41686158e+00  2.12444319e+01  1.53962633e+00\n",
      " -8.00187552e+00  1.90614483e+01  2.01337477e-01 -1.27101525e+01\n",
      "  9.70579014e-01 -1.49921339e+00 -7.34009943e+00  2.08336248e+01\n",
      " -2.20173973e+01 -3.38623030e+00 -3.08522511e+00 -1.56797199e-01\n",
      "  6.36508160e+00 -9.70715422e-01 -6.80435965e-02 -4.25883217e+00\n",
      " -2.88987395e+00 -5.41017463e+00  1.62221004e+00 -4.69636140e+00\n",
      " -4.71659521e+00  7.05018070e-01 -3.10702641e+01 -2.19408317e+00\n",
      "  6.73095223e+00  1.26280164e+00  2.08779210e+01  1.88397202e+01\n",
      "  1.15128355e+01 -4.14166311e+00  3.87140107e+00  8.72963371e+00\n",
      "  1.53073582e+01 -8.18085222e+00 -2.94928626e+00  1.06962794e+00\n",
      "  1.13374540e+00 -9.58795070e-01  3.70311385e+00 -3.94721331e+00\n",
      "  4.02144861e+00 -1.49119839e+00  5.46359580e-01  1.54285457e+01\n",
      " -4.13806032e+01 -4.15974071e+01 -6.10491498e+00 -4.96969971e+00\n",
      " -1.22397510e+01  2.31203282e+00 -2.49113936e+00  3.48662589e+00\n",
      " -4.81423041e+00  1.23315552e+01  1.04751424e+01  5.78234873e+00\n",
      "  1.20646715e+00  8.02682203e+00  2.45551975e+00 -4.79845355e+00\n",
      "  5.83218570e+00  4.41191973e+00 -9.59412833e+00  6.06156852e+00\n",
      " -5.24343855e-01 -3.84330312e+00 -5.22649392e+00  1.76156074e+00\n",
      " -6.40687486e+00  1.43053954e+00 -3.56885399e+01 -1.74633503e+01\n",
      " -4.56295091e+00 -9.42781147e-01 -4.78718338e+00 -1.36560600e+00\n",
      " -4.89469786e+00  1.42147099e+00  4.73091643e+00 -4.60391782e+00] [6.10486837e-12]\n"
     ]
    }
   ],
   "source": [
    "from embedders.manifolds import ProductManifold\n",
    "from embedders.gaussian_mixture import gaussian_mixture\n",
    "from embedders.kernel import product_kernel\n",
    "import torch\n",
    "import cvxpy\n",
    "\n",
    "# Get pm and sample\n",
    "pm = ProductManifold(signature=[(-1, 2), (0, 2), (1, 2)])\n",
    "X, y = gaussian_mixture(pm)\n",
    "\n",
    "# Make y in {-1, 1}\n",
    "# TODO: Do we need this?\n",
    "# y = 2 * y - 1\n",
    "\n",
    "# Get kernel\n",
    "n_samples = X.shape[0]\n",
    "Ks, norms = product_kernel(pm, X, X)\n",
    "K = torch.zeros(n_samples, n_samples)\n",
    "# K = torch.ones((n_samples, n_samples))\n",
    "for K_component in Ks:\n",
    "    K += K_component\n",
    "\n",
    "# Make numpy arrays\n",
    "X = X.detach().cpu().numpy()\n",
    "Y = torch.diagflat(y).detach().cpu().numpy()\n",
    "K = K.detach().cpu().numpy()\n",
    "\n",
    "# Make variables\n",
    "zeta = cvxpy.Variable(X.shape[0])\n",
    "beta = cvxpy.Variable(X.shape[0])\n",
    "epsilon = cvxpy.Variable(1)\n",
    "\n",
    "# Get constraints\n",
    "constraints = [\n",
    "    epsilon >= 0,\n",
    "    zeta >= 0,\n",
    "    Y @ (K @ beta + cvxpy.sum(beta)) >= epsilon - zeta,\n",
    "    # Y @ (K @ beta) >= epsilon - zeta,  # Replaced with sum-less form\n",
    "]\n",
    "for M, K_component, norm in zip(pm.P, Ks, norms):\n",
    "    K_component = K_component.detach().cpu().numpy()\n",
    "    norm = norm.item()\n",
    "    if M.type == \"E\":\n",
    "        alpha_E = 1.0  # TODO: make this flexible\n",
    "        # constraints.append(cvxpy.quad_form(beta, K_component) <= alpha_E**2)\n",
    "    elif M.type == \"S\":\n",
    "        pass\n",
    "        # constraints.append(cvxpy.quad_form(beta, K_component) <= torch.pi / 2)\n",
    "    elif M.type == \"H\":\n",
    "        pass  # No constraints currently\n",
    "        # K_component_pos = K_component.clip(0, None)\n",
    "        # K_component_neg = K_component.clip(None, 0)\n",
    "        # constraints.append(cvxpy.quad_form(beta, K_component_neg) <= 1e-5)\n",
    "        # constraints.append(cvxpy.quad_form(beta, K_component_pos) <= 1e-5 + norm)\n",
    "\n",
    "# CVXPY solver\n",
    "cvxpy.Problem(\n",
    "    objective=cvxpy.Minimize(-epsilon + cvxpy.sum(zeta)),\n",
    "    constraints=constraints,\n",
    ").solve()\n",
    "print(zeta.value, beta.value, epsilon.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/phil/miniforge3/envs/embedders2/lib/python3.10/site-packages/torch/distributions/wishart.py:271: UserWarning: Singular sample detected.\n",
      "  warnings.warn(\"Singular sample detected.\")\n"
     ]
    },
    {
     "ename": "DCPError",
     "evalue": "Problem does not follow DCP rules. Specifically:\nThe following constraints are not DCP:\nQuadForm(var96, [[-0.00 -0.00 ... -0.00 -0.00]\n [-0.00 -0.00 ... -0.00 -0.00]\n ...\n [-0.00 -0.00 ... -0.00 -0.00]\n [-0.00 -0.00 ... -0.00 -0.00]]) <= 1e-10 , because the following subexpressions are not:\n|--  QuadForm(var96, [[-0.00 -0.00 ... -0.00 -0.00]\n [-0.00 -0.00 ... -0.00 -0.00]\n ...\n [-0.00 -0.00 ... -0.00 -0.00]\n [-0.00 -0.00 ... -0.00 -0.00]])\nQuadForm(var96, [[0.17 -0.58 ... -0.25 0.17]\n [-0.58 2.01 ... 1.19 -0.15]\n ...\n [-0.25 1.19 ... 4.34 4.99]\n [0.17 -0.15 ... 4.99 7.11]]) <= 1.0 , because the following subexpressions are not:\n|--  QuadForm(var96, [[0.17 -0.58 ... -0.25 0.17]\n [-0.58 2.01 ... 1.19 -0.15]\n ...\n [-0.25 1.19 ... 4.34 4.99]\n [0.17 -0.15 ... 4.99 7.11]])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDCPError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# _h, _s, _e = False, False, False\u001b[39;00m\n\u001b[1;32m     12\u001b[0m ps_svm \u001b[38;5;241m=\u001b[39m ProductSpaceSVM(pm\u001b[38;5;241m=\u001b[39mpm, h_constraints\u001b[38;5;241m=\u001b[39m_h, s_constraints\u001b[38;5;241m=\u001b[39m_s, e_constraints\u001b[38;5;241m=\u001b[39m_e, epsilon\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-10\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m \u001b[43mps_svm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/embedders/src/embedders/svm.py:79\u001b[0m, in \u001b[0;36mProductSpaceSVM.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     73\u001b[0m         constraints\u001b[38;5;241m.\u001b[39mappend(cvxpy\u001b[38;5;241m.\u001b[39mquad_form(beta, K_component_pos) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meps \u001b[38;5;241m+\u001b[39m norm)\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# CVXPY solver\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[43mcvxpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProblem\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjective\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcvxpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMinimize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mepsilon\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcvxpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzeta\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconstraints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconstraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m---> 79\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzeta[class_label] \u001b[38;5;241m=\u001b[39m zeta\u001b[38;5;241m.\u001b[39mvalue\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta[class_label] \u001b[38;5;241m=\u001b[39m beta\u001b[38;5;241m.\u001b[39mvalue\n",
      "File \u001b[0;32m~/miniforge3/envs/embedders2/lib/python3.10/site-packages/cvxpy/problems/problem.py:503\u001b[0m, in \u001b[0;36mProblem.solve\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    502\u001b[0m     solve_func \u001b[38;5;241m=\u001b[39m Problem\u001b[38;5;241m.\u001b[39m_solve\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msolve_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/embedders2/lib/python3.10/site-packages/cvxpy/problems/problem.py:1073\u001b[0m, in \u001b[0;36mProblem._solve\u001b[0;34m(self, solver, warm_start, verbose, gp, qcp, requires_grad, enforce_dpp, ignore_dpp, canon_backend, **kwargs)\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munpack(chain\u001b[38;5;241m.\u001b[39mretrieve(soln))\n\u001b[1;32m   1071\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue\n\u001b[0;32m-> 1073\u001b[0m data, solving_chain, inverse_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_problem_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1074\u001b[0m \u001b[43m    \u001b[49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menforce_dpp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_dpp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcanon_backend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m   1075\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1077\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[1;32m   1078\u001b[0m     \u001b[38;5;28mprint\u001b[39m(_NUM_SOLVER_STR)\n",
      "File \u001b[0;32m~/miniforge3/envs/embedders2/lib/python3.10/site-packages/cvxpy/problems/problem.py:646\u001b[0m, in \u001b[0;36mProblem.get_problem_data\u001b[0;34m(self, solver, gp, enforce_dpp, ignore_dpp, verbose, canon_backend, solver_opts)\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache\u001b[38;5;241m.\u001b[39mkey:\n\u001b[1;32m    645\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache\u001b[38;5;241m.\u001b[39minvalidate()\n\u001b[0;32m--> 646\u001b[0m     solving_chain \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_construct_chain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[43m        \u001b[49m\u001b[43msolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m        \u001b[49m\u001b[43menforce_dpp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menforce_dpp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_dpp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_dpp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcanon_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcanon_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[43m        \u001b[49m\u001b[43msolver_opts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver_opts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    652\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;241m=\u001b[39m key\n\u001b[1;32m    653\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache\u001b[38;5;241m.\u001b[39msolving_chain \u001b[38;5;241m=\u001b[39m solving_chain\n",
      "File \u001b[0;32m~/miniforge3/envs/embedders2/lib/python3.10/site-packages/cvxpy/problems/problem.py:898\u001b[0m, in \u001b[0;36mProblem._construct_chain\u001b[0;34m(self, solver, gp, enforce_dpp, ignore_dpp, canon_backend, solver_opts)\u001b[0m\n\u001b[1;32m    896\u001b[0m candidate_solvers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_find_candidate_solvers(solver\u001b[38;5;241m=\u001b[39msolver, gp\u001b[38;5;241m=\u001b[39mgp)\n\u001b[1;32m    897\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sort_candidate_solvers(candidate_solvers)\n\u001b[0;32m--> 898\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstruct_solving_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcandidate_solvers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[43m                               \u001b[49m\u001b[43menforce_dpp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menforce_dpp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mignore_dpp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_dpp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    901\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mcanon_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcanon_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[43m                               \u001b[49m\u001b[43msolver_opts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver_opts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    903\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mspecified_solver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/embedders2/lib/python3.10/site-packages/cvxpy/reductions/solvers/solving_chain.py:228\u001b[0m, in \u001b[0;36mconstruct_solving_chain\u001b[0;34m(problem, candidates, gp, enforce_dpp, ignore_dpp, canon_backend, solver_opts, specified_solver)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(problem\u001b[38;5;241m.\u001b[39mvariables()) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SolvingChain(reductions\u001b[38;5;241m=\u001b[39m[ConstantSolver()])\n\u001b[0;32m--> 228\u001b[0m reductions \u001b[38;5;241m=\u001b[39m \u001b[43m_reductions_for_problem_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproblem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcandidates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolver_opts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;66;03m# Process DPP status of the problem.\u001b[39;00m\n\u001b[1;32m    231\u001b[0m dpp_context \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdcp\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m gp \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdgp\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/embedders2/lib/python3.10/site-packages/cvxpy/reductions/solvers/solving_chain.py:143\u001b[0m, in \u001b[0;36m_reductions_for_problem_class\u001b[0;34m(problem, candidates, gp, solver_opts)\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m problem\u001b[38;5;241m.\u001b[39mis_dqcp():\n\u001b[1;32m    141\u001b[0m         append \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mHowever, the problem does follow DQCP rules. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    142\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConsider calling solve() with `qcp=True`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DCPError(\n\u001b[1;32m    144\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProblem does not follow DCP rules. Specifically:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m append)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m gp \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m problem\u001b[38;5;241m.\u001b[39mis_dgp():\n\u001b[1;32m    146\u001b[0m     append \u001b[38;5;241m=\u001b[39m build_non_disciplined_error_msg(problem, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDGP\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mDCPError\u001b[0m: Problem does not follow DCP rules. Specifically:\nThe following constraints are not DCP:\nQuadForm(var96, [[-0.00 -0.00 ... -0.00 -0.00]\n [-0.00 -0.00 ... -0.00 -0.00]\n ...\n [-0.00 -0.00 ... -0.00 -0.00]\n [-0.00 -0.00 ... -0.00 -0.00]]) <= 1e-10 , because the following subexpressions are not:\n|--  QuadForm(var96, [[-0.00 -0.00 ... -0.00 -0.00]\n [-0.00 -0.00 ... -0.00 -0.00]\n ...\n [-0.00 -0.00 ... -0.00 -0.00]\n [-0.00 -0.00 ... -0.00 -0.00]])\nQuadForm(var96, [[0.17 -0.58 ... -0.25 0.17]\n [-0.58 2.01 ... 1.19 -0.15]\n ...\n [-0.25 1.19 ... 4.34 4.99]\n [0.17 -0.15 ... 4.99 7.11]]) <= 1.0 , because the following subexpressions are not:\n|--  QuadForm(var96, [[0.17 -0.58 ... -0.25 0.17]\n [-0.58 2.01 ... 1.19 -0.15]\n ...\n [-0.25 1.19 ... 4.34 4.99]\n [0.17 -0.15 ... 4.99 7.11]])"
     ]
    }
   ],
   "source": [
    "from embedders.manifolds import ProductManifold\n",
    "from embedders.gaussian_mixture import gaussian_mixture\n",
    "from embedders.svm import ProductSpaceSVM\n",
    "\n",
    "# Get pm and sample\n",
    "pm = ProductManifold(signature=[(-1, 2), (0, 2), (1, 2)])\n",
    "X, y = gaussian_mixture(pm)\n",
    "\n",
    "# Get SVM and fit\n",
    "_h, _s, _e = True, True, True\n",
    "# _h, _s, _e = False, False, False\n",
    "ps_svm = ProductSpaceSVM(pm=pm, h_constraints=_h, s_constraints=_s, e_constraints=_e, epsilon=1e-10)\n",
    "ps_svm.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H: False, S: True, E: False\n",
      "H: False, S: False, E: False\n"
     ]
    }
   ],
   "source": [
    "# Which versions of constraints pass?\n",
    "\n",
    "for _h in [True, False]:\n",
    "    for _s in [True, False]:\n",
    "        for _e in [True, False]:\n",
    "            ps_svm = ProductSpaceSVM(\n",
    "                pm=pm, h_constraints=_h, s_constraints=_s, e_constraints=_e\n",
    "            )\n",
    "            try:\n",
    "                ps_svm.fit(X, y)\n",
    "                print(f\"H: {_h}, S: {_s}, E: {_e}\")\n",
    "            except:\n",
    "                pass\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embedders2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
