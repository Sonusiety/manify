{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e2f2916-ac0c-4f8b-b760-121ae2a3c605",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70f27751-5fd3-429c-bc63-0bf7ef36c866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(0)\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94427327-f801-4af3-a685-3df110f62f1b",
   "metadata": {},
   "source": [
    "# Generating embeddings for graphs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "428d513a-1122-4567-9eda-02d5f657959d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top CC has 1222 nodes; original graph has 1490 nodes.\n"
     ]
    }
   ],
   "source": [
    "from embedders import dataloaders\n",
    "#Load Data\n",
    "polblogs_dists, polblogs_labels,sub = dataloaders.load(\"polblogs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96af5274-42e1-4e07-bd11-bb25cbf22bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S_1.0^4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Specify signature - useful to re-initialize the manifold here\n",
    "from embedders import manifolds\n",
    "from embedders import coordinate_learning\n",
    "torch.manual_seed(0)  \n",
    "signature = [(1, 4)]\n",
    "pm = manifolds.ProductManifold(signature=signature)\n",
    "print(pm.name)\n",
    "\n",
    "# Rescale distances\n",
    "dists_rescaled = polblogs_dists / polblogs_dists.max()\n",
    "\n",
    "# Get embedding\n",
    "coordinate_learning.train_coords(\n",
    "    pm,\n",
    "    dists_rescaled,\n",
    "    device=device,\n",
    "    burn_in_iterations=100,\n",
    "    training_iterations=100 * 9,\n",
    "    learning_rate=1e-1,\n",
    "    burn_in_learning_rate=1e-2,\n",
    "    scale_factor_learning_rate=1e-1,\n",
    ")\n",
    "\n",
    "h6_polblogs = pm.x_embed.detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c51b3a4-88fa-45c9-95be-04390d046424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProductDT\t80.86\n"
     ]
    }
   ],
   "source": [
    "#Evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from embedders.predictors import tree_new\n",
    "X_train, X_test, y_train, y_test = train_test_split(h6_polblogs, polblogs_labels.detach().cpu(), test_size=0.2, random_state=0)\n",
    "pdt = tree_new.ProductSpaceDT(pm=pm, max_depth=3, use_special_dims=True)\n",
    "pdt.fit(X_train, y_train)\n",
    "pdt_f1 = f1_score(y_test, pdt.predict(X_test),average=\"weighted\")\n",
    "print(f\"ProductDT\\t{pdt_f1*100:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f48969-2717-4e36-b3a0-cf6f479b2fb4",
   "metadata": {},
   "source": [
    "# Generating embeddings for Mixed Curvature VAE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "defd4e36-95e2-4604-b388-4247102ab17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([13410, 1056]) torch.Size([13410])\n"
     ]
    }
   ],
   "source": [
    "#Load data\n",
    "X, y, _ = dataloaders.load(\"lymphoma\")\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "#Define Encoder and Decoder\n",
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, pm):\n",
    "        super().__init__()\n",
    "        self.pm = pm\n",
    "        self.fc1 = torch.nn.Linear(1056, 200)\n",
    "        self.fc2 = torch.nn.Linear(200, 200)\n",
    "        self.fc3_z_mean = torch.nn.Linear(200, pm.dim)\n",
    "        self.fc3_z_logvar = torch.nn.Linear(200, pm.dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Hidden layers\n",
    "        h1 = torch.relu(self.fc1(x))\n",
    "        h2 = torch.relu(self.fc2(h1))\n",
    "\n",
    "        # Reparameterization\n",
    "        z_mean_tangent = self.fc3_z_mean(h2)\n",
    "        z_logvar = self.fc3_z_logvar(h2)\n",
    "        z_mean = pm.manifold.expmap(x=pm.mu0, u=z_mean_tangent @ pm.projection_matrix)\n",
    "\n",
    "        return z_mean, z_logvar\n",
    "\n",
    "\n",
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self, pm):\n",
    "        super().__init__()\n",
    "        self.pm = pm\n",
    "        self.fc1 = torch.nn.Linear(pm.ambient_dim, 200)\n",
    "        self.fc2 = torch.nn.Linear(200, 200)\n",
    "        self.fc3 = torch.nn.Linear(200, 1056)\n",
    "\n",
    "    def forward(self, z):\n",
    "        # Hidden layers\n",
    "        h1 = torch.relu(self.fc1(z))\n",
    "        h2 = torch.relu(self.fc2(h1))\n",
    "\n",
    "        # Output layer\n",
    "        x = torch.sigmoid(self.fc3(h2))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1276a03-7459-40f9-9ff5-775313dd8207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e901a6d13cb45688ae5c747c35ab8a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1072800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ec7dc175b26407eb6cd6f57f2625b1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1072800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f55411763f7342c7bf4f9037cd3ac6b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1072800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "from embedders import vae\n",
    "#Specify the hyperparameter\n",
    "SIGNATURE = [(1, 2), (1, 2)]\n",
    "N_EPOCHS = 100\n",
    "BATCH_SIZE = 4_096\n",
    "BETA = 1.0\n",
    "N_SAMPLES = 32\n",
    "TRIALS = 3\n",
    "\n",
    "# Skopek hyperparamters (aka standard Adam hyperparameters)\n",
    "LR = 1e-4 \n",
    "BETA1 = 0.9\n",
    "BETA2 = 0.999\n",
    "EPS = 1e-8\n",
    "CURVATURE_LR = 1e-4\n",
    "\n",
    "\n",
    "for trial in range(TRIALS):\n",
    "    # Set seeds\n",
    "    torch.manual_seed(trial)\n",
    "    np.random.seed(trial)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=trial)\n",
    "    pm = manifolds.ProductManifold(SIGNATURE)\n",
    "    myvae = vae.ProductSpaceVAE(\n",
    "        pm=pm, encoder=Encoder(pm), decoder=Decoder(pm), beta=BETA, n_samples=N_SAMPLES, device=device\n",
    "    )\n",
    "    opt = torch.optim.Adam(\n",
    "        [\n",
    "            {\"params\": myvae.parameters(), \"lr\": LR * 0.1, \"betas\": (BETA1, BETA2), \"eps\": EPS},\n",
    "            {\"params\": pm.params(), \"lr\": 0, \"betas\": (BETA1, BETA2), \"eps\":  EPS}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Visualization stuff\n",
    "    my_tqdm = tqdm(total=N_EPOCHS * len(X_train))\n",
    "\n",
    "    # Device stuff\n",
    "    myvae = myvae.to(device)\n",
    "    \n",
    "    X_train = X_train.to(device)\n",
    "    X_test = X_test.to(device)\n",
    "    pm = pm.to(device)\n",
    "\n",
    "\n",
    "    # Gradient checking stuff\n",
    "    def grads_ok(myvae):\n",
    "        out = True\n",
    "        for name, param in myvae.named_parameters():\n",
    "            if param.grad is not None:\n",
    "                if torch.isnan(param.grad).any():\n",
    "                    print(f\"NaN gradient in {name}\")\n",
    "                    out = False\n",
    "                if torch.isinf(param.grad).any():\n",
    "                    print(f\"Inf gradient in {name}\")\n",
    "                    out = False\n",
    "        return out\n",
    "\n",
    "\n",
    "    losses = []\n",
    "    for epoch in range(N_EPOCHS):\n",
    "        # Stop the burn-in\n",
    "        if epoch == 20:\n",
    "            opt.param_groups[1][\"lr\"] = CURVATURE_LR\n",
    "            opt.param_groups[0][\"lr\"] = LR\n",
    "        \n",
    "        for i in range(0, len(X_train), BATCH_SIZE):\n",
    "            x_batch = X_train[i : i + BATCH_SIZE]\n",
    "\n",
    "            elbo, ll, kl = myvae.elbo(x_batch)\n",
    "            loss = -elbo\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "\n",
    "            if torch.isnan(loss):\n",
    "                print(f\"Loss is NaN at iteration {i}\")\n",
    "            elif torch.isinf(loss):\n",
    "                print(f\"Loss is inf at iteration {i}\")\n",
    "            elif grads_ok(myvae):\n",
    "                opt.step()\n",
    "\n",
    "            my_tqdm.update(BATCH_SIZE)\n",
    "            my_tqdm.set_description(f\"Epoch {epoch}, loss: {loss.item():.1f}, ll: {ll.item():.1f}, kl: {kl.item():.1f}\")\n",
    "            my_tqdm.set_postfix(\n",
    "                {f\"r{i}\": f\"{x._log_scale.item():.3f}\" for i, x in enumerate(pm.manifold.manifolds)}\n",
    "            )\n",
    "    \n",
    "    # Save the embeddings\n",
    "    embeddings = []\n",
    "    for i in range(0, len(X_train), BATCH_SIZE):\n",
    "        x_batch = X_train[i : i + BATCH_SIZE]\n",
    "        z_mean, _ = myvae.encoder(x_batch)\n",
    "        embeddings.append(z_mean.detach().cpu().numpy())\n",
    "\n",
    "    embeddings = np.concatenate(embeddings)\n",
    "\n",
    "    # Save the test embeddings\n",
    "    test_embeddings = []\n",
    "    for i in range(0, len(X_test), BATCH_SIZE):\n",
    "        x_batch = X_test[i : i + BATCH_SIZE]\n",
    "        z_mean, _ = myvae.encoder(x_batch)\n",
    "        test_embeddings.append(z_mean.detach().cpu().numpy())\n",
    "    \n",
    "    test_embeddings = np.concatenate(test_embeddings)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee2c98f-173f-45d8-8181-33bc3a78469d",
   "metadata": {},
   "source": [
    "# Gaussian Mixture Generator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4487015b-5099-4df5-adad-7181f82fcb80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProductDT\t83.00\n"
     ]
    }
   ],
   "source": [
    "from embedders import gaussian_mixture\n",
    "# Filter out warnings raised when sampling Wishart distribution in Gaussian mixtures\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "#Gaussian mixture generator\n",
    "pm = manifolds.ProductManifold(signature=[(-1, 2),(2, 3),(0, 5)])\n",
    "X, y = gaussian_mixture.gaussian_mixture(pm=pm, seed=42, cov_scale_means=1.0, cov_scale_points=1.0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "#Example of apply gaussian mixture to product space decision tree\n",
    "pdt = tree_new.ProductSpaceDT(pm=pm, max_depth=3, use_special_dims=True)\n",
    "pdt.fit(X_train, y_train)\n",
    "pdt_f1 = f1_score(y_test, pdt.predict(X_test),average=\"micro\")\n",
    "print(f\"ProductDT\\t{pdt_f1*100:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
